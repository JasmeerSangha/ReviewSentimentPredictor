{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9gyD47xXMf1dJV16QgPtP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karenbennis/Xy/blob/Data_ETL/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x2IxWo3wiqn",
        "colab_type": "text"
      },
      "source": [
        "<br><br>**ETL**<br><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nCS6homIgnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Java, Spark, and Findspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "#Interact with SQL\n",
        "#!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
        "\n",
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"uiewfhn\").getOrCreate()\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnjY5twq0s2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkFiles"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AWbraLzrilP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#url = \"https://raw.githubusercontent.com/karenbennis/Xy/Data_ETL/yelp.csv\"\n",
        "#spark.sparkContext.addFile(url)\n",
        "#data_df = spark.read.csv(SparkFiles.get(\"yelp.csv\"), sep=\",\", header=True)\n",
        "#data_df.show()\n",
        "import pandas as  pd\n",
        "\n",
        "data_df=pd.read_csv('https://raw.githubusercontent.com/karenbennis/Xy/Data_ETL/yelp.csv')\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6t7qKVgmtRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def good(x):\n",
        "    if x > 3:\n",
        "        return 1\n",
        "    if x < 3:\n",
        "        return 0\n",
        "\n",
        "data_df['class']=data_df['stars'].apply(good)\n",
        "\n",
        "\n",
        "data_df=data_df.drop(['business_id','date','review_id','stars','type','user_id','cool','useful','funny'],axis=1)\n",
        "data_df=data_df.dropna()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aca0s-O8moN9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "f7dec83f-3da6-45ee-d73c-bb028897a50c"
      },
      "source": [
        "df = spark.createDataFrame(data_df)\n",
        "df.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|                text|class|\n",
            "+--------------------+-----+\n",
            "|My wife took me h...|  1.0|\n",
            "|I have no idea wh...|  1.0|\n",
            "|love the gyro pla...|  1.0|\n",
            "|Rosie, Dakota, an...|  1.0|\n",
            "|General Manager S...|  1.0|\n",
            "|Quiessence is, si...|  1.0|\n",
            "|Drop what you're ...|  1.0|\n",
            "|Luckily, I didn't...|  1.0|\n",
            "|Definitely come f...|  1.0|\n",
            "|Nobuo shows his u...|  1.0|\n",
            "|The oldish man wh...|  1.0|\n",
            "|Wonderful Vietnam...|  1.0|\n",
            "|They have a limit...|  1.0|\n",
            "|Good tattoo shop....|  1.0|\n",
            "|I'm 2 weeks new t...|  1.0|\n",
            "|Was it worth the ...|  0.0|\n",
            "|okay this is the ...|  1.0|\n",
            "|They've gotten be...|  1.0|\n",
            "|This place should...|  1.0|\n",
            "|first time my fri...|  1.0|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x0XmXV9VBTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import functions\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSnyCPH-PUlD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "a71f2671-1e3b-46fb-d234-709e50ac7034"
      },
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature\n",
        "data_df = df.withColumn('length', length(df['text']))\n",
        "data_df.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+------+\n",
            "|                text|class|length|\n",
            "+--------------------+-----+------+\n",
            "|My wife took me h...|  1.0|   889|\n",
            "|I have no idea wh...|  1.0|  1345|\n",
            "|love the gyro pla...|  1.0|    76|\n",
            "|Rosie, Dakota, an...|  1.0|   419|\n",
            "|General Manager S...|  1.0|   469|\n",
            "|Quiessence is, si...|  1.0|  2094|\n",
            "|Drop what you're ...|  1.0|  1565|\n",
            "|Luckily, I didn't...|  1.0|   274|\n",
            "|Definitely come f...|  1.0|   349|\n",
            "|Nobuo shows his u...|  1.0|   186|\n",
            "|The oldish man wh...|  1.0|   298|\n",
            "|Wonderful Vietnam...|  1.0|   321|\n",
            "|They have a limit...|  1.0|   433|\n",
            "|Good tattoo shop....|  1.0|   593|\n",
            "|I'm 2 weeks new t...|  1.0|  1206|\n",
            "|Was it worth the ...|  0.0|   705|\n",
            "|okay this is the ...|  1.0|   363|\n",
            "|They've gotten be...|  1.0|   726|\n",
            "|This place should...|  1.0|   104|\n",
            "|first time my fri...|  1.0|   148|\n",
            "+--------------------+-----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VorHUGE_vta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create all the features to the data set\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-05EYS6Bold9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrqh24KqlJDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ_67nv5lKOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(data_df)\n",
        "cleaned = cleaner.transform(data_df)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiiHRYAxlKHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3], 21)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXene5PXlJ7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdZyvrGElUOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cdea823-236e-46c9-89b6-0a16325325cd"
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(predictor.transform(testing))\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.815244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EATIxkihlUKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aabfdBNYlUGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeAqfC5Kol8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://challenge.cde4fgpazxbm.ca-central-1.rds.amazonaws.com:5432/\"\n",
        "config = {\"user\":'postgres', \n",
        "          \"password\": '', \n",
        "          \"driver\":\"org.postgresql.Driver\"}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}