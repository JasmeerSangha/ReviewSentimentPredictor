{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karenbennis/Xy/blob/ml_model/ml_model_1_3_5_stars_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x2IxWo3wiqn",
        "colab_type": "text"
      },
      "source": [
        "## <br>**Connect to Database**<br><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nCS6homIgnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "ac9bd50e-3c35-4964-f8f3-aa2294844032"
      },
      "source": [
        "# Install Java, Spark, and Findspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "#Interact with SQL\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
        "\n",
        "# Start Spark Session(Creating spark application with name defined by appName()) ---IMPORTED WITH EVERY COLAB NOTEBOOK\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"database_transformation\").config(\"spark.driver.memory\",\"5g\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-26 15:58:27--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.9.jar.2’\n",
            "\n",
            "postgresql-42.2.9.j 100%[===================>] 892.61K  1.42MB/s    in 0.6s    \n",
            "\n",
            "2020-07-26 15:58:29 (1.42 MB/s) - ‘postgresql-42.2.9.jar.2’ saved [914037/914037]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVTkr-xleT8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb553ddf-339b-424b-c6be-d8119eb7b448"
      },
      "source": [
        "# gcloud login and check the DB\n",
        "!gcloud auth login\n",
        "!gcloud config set project 'xy-yelp'\n",
        "!gcloud sql instances describe 'xy-yelp'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&code_challenge=TGHQzzth5e5AMSwqAw6CpiH3wec9voSu-hui-MK-he0&code_challenge_method=S256&access_type=offline&response_type=code&prompt=select_account\n",
            "\n",
            "\n",
            "Enter verification code: 4/2QHe7YUZLypxZoQQ6PhcY2igPX1F0aY8znLdi8Pv6YIxOPyVrLPM_vU\n",
            "\n",
            "You are now logged in as [helenly25@gmail.com].\n",
            "Your current project is [xy-yelp].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n",
            "Updated property [core/project].\n",
            "backendType: SECOND_GEN\n",
            "connectionName: xy-yelp:northamerica-northeast1:xy-yelp\n",
            "databaseVersion: POSTGRES_12\n",
            "etag: bc66e3b4861eccb5afd42f9c257f2fb71f9c6273f5cfcb70659b019d99a17896\n",
            "gceZone: northamerica-northeast1-a\n",
            "instanceType: CLOUD_SQL_INSTANCE\n",
            "ipAddresses:\n",
            "- ipAddress: 34.95.0.17\n",
            "  type: PRIMARY\n",
            "kind: sql#instance\n",
            "name: xy-yelp\n",
            "project: xy-yelp\n",
            "region: northamerica-northeast1\n",
            "selfLink: https://sqladmin.googleapis.com/sql/v1beta4/projects/xy-yelp/instances/xy-yelp\n",
            "serverCaCert:\n",
            "  cert: |-\n",
            "    -----BEGIN CERTIFICATE-----\n",
            "    MIIDfzCCAmegAwIBAgIBADANBgkqhkiG9w0BAQsFADB3MS0wKwYDVQQuEyQzYTcz\n",
            "    ZmJhNS0xYTNlLTQwNmMtOWZhOC1hZGE1MDI3OGZkY2QxIzAhBgNVBAMTGkdvb2ds\n",
            "    ZSBDbG91ZCBTUUwgU2VydmVyIENBMRQwEgYDVQQKEwtHb29nbGUsIEluYzELMAkG\n",
            "    A1UEBhMCVVMwHhcNMjAwNzExMjAwMDA4WhcNMzAwNzA5MjAwMTA4WjB3MS0wKwYD\n",
            "    VQQuEyQzYTczZmJhNS0xYTNlLTQwNmMtOWZhOC1hZGE1MDI3OGZkY2QxIzAhBgNV\n",
            "    BAMTGkdvb2dsZSBDbG91ZCBTUUwgU2VydmVyIENBMRQwEgYDVQQKEwtHb29nbGUs\n",
            "    IEluYzELMAkGA1UEBhMCVVMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIB\n",
            "    AQDMLAiCVUS0u8JRUQSqXLNcXiDU4euUjKhmvbOnDCr2VNVX+dQoq8P+HmL4ruxr\n",
            "    lmLgtNKuhKjqISSzVKDxEf0mudWfOP+ygsXSP6XxLWplHn/N1A881+u+T33u5N0/\n",
            "    wreqH6suvi7Cu/SSEcmYUCnpIy5pSZzO63ww9M4p2HZnG/g/j7uqGdPUpdG4GbCk\n",
            "    jb8EskJiH0hU08ct+AySyc0mrgvfP9l/S5chz0j69uQX/yvWXWy4SSfJ3+wc45Se\n",
            "    8v7WYo+lcwsOu0lGCz53X9Nej0Av47aKUzXD4HlleeMTbkjgYEv2hRWKVoUhzugT\n",
            "    dJTsminBKtnYK1n2witgxNqVAgMBAAGjFjAUMBIGA1UdEwEB/wQIMAYBAf8CAQAw\n",
            "    DQYJKoZIhvcNAQELBQADggEBAB45K3XfFNL/Vkbj0f9daDji+cJHeUS3Y8Uxehog\n",
            "    2rf+rbmwfeH757NZT29o8rSMMfV05z3fuYvS67JvSIDx/I3UsxRGzRZY4EfXXhC9\n",
            "    Vke7AVtfxNgKk86V+JPEGQp52L+PFYdh33DigL8XrWpektxIxf7RAqFIvV0F+0FS\n",
            "    DhXWXkZ8ONFpMK6BCd4aZcKgD0LHafoAKv67+A8IE6b1fFJLh1nkuqZyv1kwLwTM\n",
            "    bLzSMmkgvxuv8d0dmVxWWr/V1kjc2U7oMqF+tgOE+hcF7fWRyRRZko1RtPwjUHlT\n",
            "    qzw5uqZUsxR8S4yyiaeePiF8YnDI72ypyY6FiRMlteAydJs=\n",
            "    -----END CERTIFICATE-----\n",
            "  certSerialNumber: '0'\n",
            "  commonName: C=US,O=Google\\, Inc,CN=Google Cloud SQL Server CA,dnQualifier=3a73fba5-1a3e-406c-9fa8-ada50278fdcd\n",
            "  createTime: '2020-07-11T20:00:08.018Z'\n",
            "  expirationTime: '2030-07-09T20:01:08.018Z'\n",
            "  instance: xy-yelp\n",
            "  kind: sql#sslCert\n",
            "  sha1Fingerprint: 2e2ffdd64d766e372537c174a3d4b91f59ee3e63\n",
            "serviceAccountEmailAddress: p8056368877-0mi1n8@gcp-sa-cloud-sql.iam.gserviceaccount.com\n",
            "settings:\n",
            "  activationPolicy: ALWAYS\n",
            "  availabilityType: ZONAL\n",
            "  backupConfiguration:\n",
            "    enabled: true\n",
            "    kind: sql#backupConfiguration\n",
            "    location: us\n",
            "    pointInTimeRecoveryEnabled: true\n",
            "    replicationLogArchivingEnabled: true\n",
            "    startTime: 13:00\n",
            "  dataDiskSizeGb: '43'\n",
            "  dataDiskType: PD_SSD\n",
            "  ipConfiguration:\n",
            "    authorizedNetworks:\n",
            "    - kind: sql#aclEntry\n",
            "      name: Karen's Residence\n",
            "      value: 173.32.183.48\n",
            "    - kind: sql#aclEntry\n",
            "      name: Helen's Residence\n",
            "      value: 72.142.66.43\n",
            "    - kind: sql#aclEntry\n",
            "      name: Blake Residence\n",
            "      value: 24.114.82.234\n",
            "    ipv4Enabled: true\n",
            "  kind: sql#settings\n",
            "  locationPreference:\n",
            "    kind: sql#locationPreference\n",
            "    zone: northamerica-northeast1-a\n",
            "  maintenanceWindow:\n",
            "    day: 0\n",
            "    hour: 0\n",
            "    kind: sql#maintenanceWindow\n",
            "  pricingPlan: PER_USE\n",
            "  replicationType: SYNCHRONOUS\n",
            "  settingsVersion: '35'\n",
            "  storageAutoResize: true\n",
            "  storageAutoResizeLimit: '0'\n",
            "  tier: db-f1-micro\n",
            "state: RUNNABLE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn_F729PexE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0fab4c63-7393-4262-9b8f-85bb74197391"
      },
      "source": [
        "# download and initialize the psql proxy\n",
        "!wget https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64 -O cloud_sql_proxy\n",
        "!chmod +x cloud_sql_proxy\n",
        "# \"connectionName\" is from the previous block\n",
        "!nohup ./cloud_sql_proxy -instances=\"xy-yelp:northamerica-northeast1:xy-yelp\"=tcp:5432 &\n",
        "!sleep 30s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cloud_sql_proxy: Text file busy\n",
            "nohup: appending output to 'nohup.out'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Ko5J-Ee7Ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db_password = 'kjhbyelpdb'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs2eCTjpfEd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://127.0.0.1:5432/xy_yelp_db\"\n",
        "config = {\"user\":\"postgres\", \n",
        "          \"password\": db_password, \n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQez-IxYJC_V",
        "colab_type": "text"
      },
      "source": [
        "## **Extract tables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYCeG56KqO75",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "90bfb12f-0caa-4059-e01b-ef83647072db"
      },
      "source": [
        "# convert to pandas\n",
        "import pandas as pd\n",
        "pandas_df = pd.read_csv(\"https://raw.githubusercontent.com/karenbennis/Xy/storyboard/uniform_yelp.csv\")\n",
        "\n",
        "# Set index\n",
        "# pandas_df = pandas_df.set_index('review_id')\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f5pGCpvkpRpJixZ0zA3hCg</td>\n",
              "      <td>8p2nss7UoZmIVZTr1IjR3w</td>\n",
              "      <td>caWUE0ItqsG51OaBVlr4Eg</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-11-13</td>\n",
              "      <td>We went here three more times for lunch and tw...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8lPKsNFBiLmVL5nbsUXaZw</td>\n",
              "      <td>O3pSxv1SyHpY4qi4Q16KzA</td>\n",
              "      <td>dc3uoAmNo5STqKV6mlD_aA</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-30</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CANhCLzOoZ0mkL3mpnUSNg</td>\n",
              "      <td>ffC9zmbY4pBOS9ByrWoXxQ</td>\n",
              "      <td>sR9hPrIaG-J-GLcl4yaiLw</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-11-19</td>\n",
              "      <td>Very Problematic\\nI'm gay, I'm not ashamed to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bZ02moAXlosgWPM3pXSHWw</td>\n",
              "      <td>zE49S2Em3l7vgIlvFzZFOw</td>\n",
              "      <td>NF6di6YcQxN0rDAleE7SyQ</td>\n",
              "      <td>3</td>\n",
              "      <td>2014-12-30</td>\n",
              "      <td>Today was the first time I sat down a table. I...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TmIla5Eh5SSLJ_bKgH4Syg</td>\n",
              "      <td>xde2rO3XVt0Do8kLRIt2Dw</td>\n",
              "      <td>Wc9UpJhOcdSj7olZkz7SJA</td>\n",
              "      <td>2</td>\n",
              "      <td>2013-02-19</td>\n",
              "      <td>I ordered chicken tacos with no cheese to go. ...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id                 user_id  ... funny  cool\n",
              "0  f5pGCpvkpRpJixZ0zA3hCg  8p2nss7UoZmIVZTr1IjR3w  ...     0     0\n",
              "1  8lPKsNFBiLmVL5nbsUXaZw  O3pSxv1SyHpY4qi4Q16KzA  ...     1     1\n",
              "2  CANhCLzOoZ0mkL3mpnUSNg  ffC9zmbY4pBOS9ByrWoXxQ  ...     0     0\n",
              "3  bZ02moAXlosgWPM3pXSHWw  zE49S2Em3l7vgIlvFzZFOw  ...     0     0\n",
              "4  TmIla5Eh5SSLJ_bKgH4Syg  xde2rO3XVt0Do8kLRIt2Dw  ...     1     0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6k3WVfJM6cE",
        "colab_type": "text"
      },
      "source": [
        "## **Transformation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWkbgnM72jeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "edd9ab6d-8def-45ee-cdd9-05b54919d8a1"
      },
      "source": [
        "pandas_df = pandas_df.loc[(pandas_df['stars'] != 2) & (pandas_df['stars'] != 4)]\n",
        "pandas_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8lPKsNFBiLmVL5nbsUXaZw</td>\n",
              "      <td>O3pSxv1SyHpY4qi4Q16KzA</td>\n",
              "      <td>dc3uoAmNo5STqKV6mlD_aA</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-30</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CANhCLzOoZ0mkL3mpnUSNg</td>\n",
              "      <td>ffC9zmbY4pBOS9ByrWoXxQ</td>\n",
              "      <td>sR9hPrIaG-J-GLcl4yaiLw</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-11-19</td>\n",
              "      <td>Very Problematic\\nI'm gay, I'm not ashamed to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bZ02moAXlosgWPM3pXSHWw</td>\n",
              "      <td>zE49S2Em3l7vgIlvFzZFOw</td>\n",
              "      <td>NF6di6YcQxN0rDAleE7SyQ</td>\n",
              "      <td>3</td>\n",
              "      <td>2014-12-30</td>\n",
              "      <td>Today was the first time I sat down a table. I...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>zNXXGTnGOo9pKCN5JyKaPw</td>\n",
              "      <td>YT4FKLW7YiHDdlXZpqjMHg</td>\n",
              "      <td>y3bMutme81x4PUhb0zaC_A</td>\n",
              "      <td>3</td>\n",
              "      <td>2013-05-27</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Ez-8sHPrQdnyv5YZW26V4w</td>\n",
              "      <td>9Xmw_WcUCShPD0qGO1UD7w</td>\n",
              "      <td>77N3luh2YzfJFJGFIfqqbw</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-04-04</td>\n",
              "      <td>Beer baby!! Always love the selection Duke's o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id                 user_id  ... funny  cool\n",
              "1  8lPKsNFBiLmVL5nbsUXaZw  O3pSxv1SyHpY4qi4Q16KzA  ...     1     1\n",
              "2  CANhCLzOoZ0mkL3mpnUSNg  ffC9zmbY4pBOS9ByrWoXxQ  ...     0     0\n",
              "3  bZ02moAXlosgWPM3pXSHWw  zE49S2Em3l7vgIlvFzZFOw  ...     0     0\n",
              "6  zNXXGTnGOo9pKCN5JyKaPw  YT4FKLW7YiHDdlXZpqjMHg  ...     1     0\n",
              "7  Ez-8sHPrQdnyv5YZW26V4w  9Xmw_WcUCShPD0qGO1UD7w  ...     0     0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-oZ7ztJqPAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dependencies for nltk\n",
        "# https://towardsdatascience.com/natural-language-processing-nlp-for-machine-learning-d44498845d5b\n",
        "import nltk"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWjqAnpGsxtM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6ab7a09c-2dc8-491d-a947-9f4a555a6ea3"
      },
      "source": [
        "# Import string and punctuations\n",
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUy5O7uUsx3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "0da8fc60-5aa0-42a4-d245-464687678034"
      },
      "source": [
        "# Function to remove Punctuation\n",
        "def remove_punct(text):\n",
        "\n",
        "  # Discard all punctuations\n",
        "  text_nopunct = ''.join([char for char in text if char not in string.punctuation])\n",
        "  return text_nopunct\n",
        "\n",
        "pandas_df['body_text_clean'] = pandas_df['text'].apply(lambda x: remove_punct(x))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>body_text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8lPKsNFBiLmVL5nbsUXaZw</td>\n",
              "      <td>O3pSxv1SyHpY4qi4Q16KzA</td>\n",
              "      <td>dc3uoAmNo5STqKV6mlD_aA</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-30</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CANhCLzOoZ0mkL3mpnUSNg</td>\n",
              "      <td>ffC9zmbY4pBOS9ByrWoXxQ</td>\n",
              "      <td>sR9hPrIaG-J-GLcl4yaiLw</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-11-19</td>\n",
              "      <td>Very Problematic\\nI'm gay, I'm not ashamed to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Very Problematic\\nIm gay Im not ashamed to say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bZ02moAXlosgWPM3pXSHWw</td>\n",
              "      <td>zE49S2Em3l7vgIlvFzZFOw</td>\n",
              "      <td>NF6di6YcQxN0rDAleE7SyQ</td>\n",
              "      <td>3</td>\n",
              "      <td>2014-12-30</td>\n",
              "      <td>Today was the first time I sat down a table. I...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Today was the first time I sat down a table I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>zNXXGTnGOo9pKCN5JyKaPw</td>\n",
              "      <td>YT4FKLW7YiHDdlXZpqjMHg</td>\n",
              "      <td>y3bMutme81x4PUhb0zaC_A</td>\n",
              "      <td>3</td>\n",
              "      <td>2013-05-27</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Ez-8sHPrQdnyv5YZW26V4w</td>\n",
              "      <td>9Xmw_WcUCShPD0qGO1UD7w</td>\n",
              "      <td>77N3luh2YzfJFJGFIfqqbw</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-04-04</td>\n",
              "      <td>Beer baby!! Always love the selection Duke's o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Beer baby Always love the selection Dukes offe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id  ...                                    body_text_clean\n",
              "1  8lPKsNFBiLmVL5nbsUXaZw  ...  My husband and I went to the Drake for lunch t...\n",
              "2  CANhCLzOoZ0mkL3mpnUSNg  ...  Very Problematic\\nIm gay Im not ashamed to say...\n",
              "3  bZ02moAXlosgWPM3pXSHWw  ...  Today was the first time I sat down a table I ...\n",
              "6  zNXXGTnGOo9pKCN5JyKaPw  ...  Went to lunch Sunday of Memorial Day weekend T...\n",
              "7  Ez-8sHPrQdnyv5YZW26V4w  ...  Beer baby Always love the selection Dukes offe...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x1pQ29xsx-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "90caf478-3e42-4b3d-b06c-70872356609a"
      },
      "source": [
        "# Import re\n",
        "import re\n",
        "\n",
        "# Function to Tokenize words\n",
        "def tokenize(text):\n",
        "\n",
        "  # W+ means that either a word character (A-Za-z0-9) or a dash (-) can go there\n",
        "  tokens = re.split('\\W+', text)\n",
        "  return tokens\n",
        "\n",
        "# Convert to lowercase as Python is case-sensitive\n",
        "pandas_df['body_text_tokenized'] = pandas_df['body_text_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8lPKsNFBiLmVL5nbsUXaZw</td>\n",
              "      <td>O3pSxv1SyHpY4qi4Q16KzA</td>\n",
              "      <td>dc3uoAmNo5STqKV6mlD_aA</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-30</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>[my, husband, and, i, went, to, the, drake, fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CANhCLzOoZ0mkL3mpnUSNg</td>\n",
              "      <td>ffC9zmbY4pBOS9ByrWoXxQ</td>\n",
              "      <td>sR9hPrIaG-J-GLcl4yaiLw</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-11-19</td>\n",
              "      <td>Very Problematic\\nI'm gay, I'm not ashamed to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Very Problematic\\nIm gay Im not ashamed to say...</td>\n",
              "      <td>[very, problematic, im, gay, im, not, ashamed,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bZ02moAXlosgWPM3pXSHWw</td>\n",
              "      <td>zE49S2Em3l7vgIlvFzZFOw</td>\n",
              "      <td>NF6di6YcQxN0rDAleE7SyQ</td>\n",
              "      <td>3</td>\n",
              "      <td>2014-12-30</td>\n",
              "      <td>Today was the first time I sat down a table. I...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Today was the first time I sat down a table I ...</td>\n",
              "      <td>[today, was, the, first, time, i, sat, down, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>zNXXGTnGOo9pKCN5JyKaPw</td>\n",
              "      <td>YT4FKLW7YiHDdlXZpqjMHg</td>\n",
              "      <td>y3bMutme81x4PUhb0zaC_A</td>\n",
              "      <td>3</td>\n",
              "      <td>2013-05-27</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend T...</td>\n",
              "      <td>[went, to, lunch, sunday, of, memorial, day, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Ez-8sHPrQdnyv5YZW26V4w</td>\n",
              "      <td>9Xmw_WcUCShPD0qGO1UD7w</td>\n",
              "      <td>77N3luh2YzfJFJGFIfqqbw</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-04-04</td>\n",
              "      <td>Beer baby!! Always love the selection Duke's o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Beer baby Always love the selection Dukes offe...</td>\n",
              "      <td>[beer, baby, always, love, the, selection, duk...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id  ...                                body_text_tokenized\n",
              "1  8lPKsNFBiLmVL5nbsUXaZw  ...  [my, husband, and, i, went, to, the, drake, fo...\n",
              "2  CANhCLzOoZ0mkL3mpnUSNg  ...  [very, problematic, im, gay, im, not, ashamed,...\n",
              "3  bZ02moAXlosgWPM3pXSHWw  ...  [today, was, the, first, time, i, sat, down, a...\n",
              "6  zNXXGTnGOo9pKCN5JyKaPw  ...  [went, to, lunch, sunday, of, memorial, day, w...\n",
              "7  Ez-8sHPrQdnyv5YZW26V4w  ...  [beer, baby, always, love, the, selection, duk...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER0d1Pb3ulKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f499fcaa-942a-43c9-a153-d9c4e93bf0ff"
      },
      "source": [
        "# Remove all English stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopword = nltk.corpus.stopwords.words('english') "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA4exlyhulOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "f3aa1627-9034-4213-ffae-28be83c136af"
      },
      "source": [
        "# Function to remove stopwords\n",
        "def remove_stopwords(tokenized_list):\n",
        "\n",
        "  # Remove all stopwords\n",
        "  text = [word for word in tokenized_list if word not in stopword]\n",
        "  return text\n",
        "\n",
        "pandas_df['body_text_nostop'] = pandas_df['body_text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8lPKsNFBiLmVL5nbsUXaZw</td>\n",
              "      <td>O3pSxv1SyHpY4qi4Q16KzA</td>\n",
              "      <td>dc3uoAmNo5STqKV6mlD_aA</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-30</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>[my, husband, and, i, went, to, the, drake, fo...</td>\n",
              "      <td>[husband, went, drake, lunch, today, sat, pati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CANhCLzOoZ0mkL3mpnUSNg</td>\n",
              "      <td>ffC9zmbY4pBOS9ByrWoXxQ</td>\n",
              "      <td>sR9hPrIaG-J-GLcl4yaiLw</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-11-19</td>\n",
              "      <td>Very Problematic\\nI'm gay, I'm not ashamed to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Very Problematic\\nIm gay Im not ashamed to say...</td>\n",
              "      <td>[very, problematic, im, gay, im, not, ashamed,...</td>\n",
              "      <td>[problematic, im, gay, im, ashamed, say, felt,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bZ02moAXlosgWPM3pXSHWw</td>\n",
              "      <td>zE49S2Em3l7vgIlvFzZFOw</td>\n",
              "      <td>NF6di6YcQxN0rDAleE7SyQ</td>\n",
              "      <td>3</td>\n",
              "      <td>2014-12-30</td>\n",
              "      <td>Today was the first time I sat down a table. I...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Today was the first time I sat down a table I ...</td>\n",
              "      <td>[today, was, the, first, time, i, sat, down, a...</td>\n",
              "      <td>[today, first, time, sat, table, like, wait, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>zNXXGTnGOo9pKCN5JyKaPw</td>\n",
              "      <td>YT4FKLW7YiHDdlXZpqjMHg</td>\n",
              "      <td>y3bMutme81x4PUhb0zaC_A</td>\n",
              "      <td>3</td>\n",
              "      <td>2013-05-27</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend T...</td>\n",
              "      <td>[went, to, lunch, sunday, of, memorial, day, w...</td>\n",
              "      <td>[went, lunch, sunday, memorial, day, weekend, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Ez-8sHPrQdnyv5YZW26V4w</td>\n",
              "      <td>9Xmw_WcUCShPD0qGO1UD7w</td>\n",
              "      <td>77N3luh2YzfJFJGFIfqqbw</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-04-04</td>\n",
              "      <td>Beer baby!! Always love the selection Duke's o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Beer baby Always love the selection Dukes offe...</td>\n",
              "      <td>[beer, baby, always, love, the, selection, duk...</td>\n",
              "      <td>[beer, baby, always, love, selection, dukes, o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id  ...                                   body_text_nostop\n",
              "1  8lPKsNFBiLmVL5nbsUXaZw  ...  [husband, went, drake, lunch, today, sat, pati...\n",
              "2  CANhCLzOoZ0mkL3mpnUSNg  ...  [problematic, im, gay, im, ashamed, say, felt,...\n",
              "3  bZ02moAXlosgWPM3pXSHWw  ...  [today, first, time, sat, table, like, wait, w...\n",
              "6  zNXXGTnGOo9pKCN5JyKaPw  ...  [went, lunch, sunday, memorial, day, weekend, ...\n",
              "7  Ez-8sHPrQdnyv5YZW26V4w  ...  [beer, baby, always, love, selection, dukes, o...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XOi9l2zulSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "57441487-eda2-4c35-9316-29dc6cdfef7b"
      },
      "source": [
        "# Import PorterStemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Create an instance for stemmer\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "# Function for stemming\n",
        "def stemming(tokenized_text):\n",
        "\n",
        "  text = [ps.stem(word) for word in tokenized_text]\n",
        "  return text\n",
        "\n",
        "pandas_df['body_text_stemmed'] = pandas_df['body_text_nostop'].apply(lambda x: stemming(x))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "      <th>body_text_stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8lPKsNFBiLmVL5nbsUXaZw</td>\n",
              "      <td>O3pSxv1SyHpY4qi4Q16KzA</td>\n",
              "      <td>dc3uoAmNo5STqKV6mlD_aA</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-30</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>[my, husband, and, i, went, to, the, drake, fo...</td>\n",
              "      <td>[husband, went, drake, lunch, today, sat, pati...</td>\n",
              "      <td>[husband, went, drake, lunch, today, sat, pati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CANhCLzOoZ0mkL3mpnUSNg</td>\n",
              "      <td>ffC9zmbY4pBOS9ByrWoXxQ</td>\n",
              "      <td>sR9hPrIaG-J-GLcl4yaiLw</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-11-19</td>\n",
              "      <td>Very Problematic\\nI'm gay, I'm not ashamed to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Very Problematic\\nIm gay Im not ashamed to say...</td>\n",
              "      <td>[very, problematic, im, gay, im, not, ashamed,...</td>\n",
              "      <td>[problematic, im, gay, im, ashamed, say, felt,...</td>\n",
              "      <td>[problemat, im, gay, im, asham, say, felt, ash...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bZ02moAXlosgWPM3pXSHWw</td>\n",
              "      <td>zE49S2Em3l7vgIlvFzZFOw</td>\n",
              "      <td>NF6di6YcQxN0rDAleE7SyQ</td>\n",
              "      <td>3</td>\n",
              "      <td>2014-12-30</td>\n",
              "      <td>Today was the first time I sat down a table. I...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Today was the first time I sat down a table I ...</td>\n",
              "      <td>[today, was, the, first, time, i, sat, down, a...</td>\n",
              "      <td>[today, first, time, sat, table, like, wait, w...</td>\n",
              "      <td>[today, first, time, sat, tabl, like, wait, we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>zNXXGTnGOo9pKCN5JyKaPw</td>\n",
              "      <td>YT4FKLW7YiHDdlXZpqjMHg</td>\n",
              "      <td>y3bMutme81x4PUhb0zaC_A</td>\n",
              "      <td>3</td>\n",
              "      <td>2013-05-27</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend T...</td>\n",
              "      <td>[went, to, lunch, sunday, of, memorial, day, w...</td>\n",
              "      <td>[went, lunch, sunday, memorial, day, weekend, ...</td>\n",
              "      <td>[went, lunch, sunday, memori, day, weekend, mu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Ez-8sHPrQdnyv5YZW26V4w</td>\n",
              "      <td>9Xmw_WcUCShPD0qGO1UD7w</td>\n",
              "      <td>77N3luh2YzfJFJGFIfqqbw</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-04-04</td>\n",
              "      <td>Beer baby!! Always love the selection Duke's o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Beer baby Always love the selection Dukes offe...</td>\n",
              "      <td>[beer, baby, always, love, the, selection, duk...</td>\n",
              "      <td>[beer, baby, always, love, selection, dukes, o...</td>\n",
              "      <td>[beer, babi, alway, love, select, duke, offer,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id  ...                                  body_text_stemmed\n",
              "1  8lPKsNFBiLmVL5nbsUXaZw  ...  [husband, went, drake, lunch, today, sat, pati...\n",
              "2  CANhCLzOoZ0mkL3mpnUSNg  ...  [problemat, im, gay, im, asham, say, felt, ash...\n",
              "3  bZ02moAXlosgWPM3pXSHWw  ...  [today, first, time, sat, tabl, like, wait, we...\n",
              "6  zNXXGTnGOo9pKCN5JyKaPw  ...  [went, lunch, sunday, memori, day, weekend, mu...\n",
              "7  Ez-8sHPrQdnyv5YZW26V4w  ...  [beer, babi, alway, love, select, duke, offer,...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NhasPSiuldn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "d8d27766-29dc-4099-cb73-6326eb190237"
      },
      "source": [
        "# import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "# Create an instance\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "\n",
        "# Function for lemmatization\n",
        "def lemmatizing(tokenized_text):\n",
        "\n",
        "  text = [wn.lemmatize(word) for word in tokenized_text]\n",
        "  return text\n",
        "\n",
        "pandas_df['body_text_lemmatized'] = pandas_df['body_text_nostop'].apply(lambda x: lemmatizing(x))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "      <th>body_text_stemmed</th>\n",
              "      <th>body_text_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8lPKsNFBiLmVL5nbsUXaZw</td>\n",
              "      <td>O3pSxv1SyHpY4qi4Q16KzA</td>\n",
              "      <td>dc3uoAmNo5STqKV6mlD_aA</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-30</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>[my, husband, and, i, went, to, the, drake, fo...</td>\n",
              "      <td>[husband, went, drake, lunch, today, sat, pati...</td>\n",
              "      <td>[husband, went, drake, lunch, today, sat, pati...</td>\n",
              "      <td>[husband, went, drake, lunch, today, sat, pati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CANhCLzOoZ0mkL3mpnUSNg</td>\n",
              "      <td>ffC9zmbY4pBOS9ByrWoXxQ</td>\n",
              "      <td>sR9hPrIaG-J-GLcl4yaiLw</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-11-19</td>\n",
              "      <td>Very Problematic\\nI'm gay, I'm not ashamed to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Very Problematic\\nIm gay Im not ashamed to say...</td>\n",
              "      <td>[very, problematic, im, gay, im, not, ashamed,...</td>\n",
              "      <td>[problematic, im, gay, im, ashamed, say, felt,...</td>\n",
              "      <td>[problemat, im, gay, im, asham, say, felt, ash...</td>\n",
              "      <td>[problematic, im, gay, im, ashamed, say, felt,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bZ02moAXlosgWPM3pXSHWw</td>\n",
              "      <td>zE49S2Em3l7vgIlvFzZFOw</td>\n",
              "      <td>NF6di6YcQxN0rDAleE7SyQ</td>\n",
              "      <td>3</td>\n",
              "      <td>2014-12-30</td>\n",
              "      <td>Today was the first time I sat down a table. I...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Today was the first time I sat down a table I ...</td>\n",
              "      <td>[today, was, the, first, time, i, sat, down, a...</td>\n",
              "      <td>[today, first, time, sat, table, like, wait, w...</td>\n",
              "      <td>[today, first, time, sat, tabl, like, wait, we...</td>\n",
              "      <td>[today, first, time, sat, table, like, wait, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>zNXXGTnGOo9pKCN5JyKaPw</td>\n",
              "      <td>YT4FKLW7YiHDdlXZpqjMHg</td>\n",
              "      <td>y3bMutme81x4PUhb0zaC_A</td>\n",
              "      <td>3</td>\n",
              "      <td>2013-05-27</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend T...</td>\n",
              "      <td>[went, to, lunch, sunday, of, memorial, day, w...</td>\n",
              "      <td>[went, lunch, sunday, memorial, day, weekend, ...</td>\n",
              "      <td>[went, lunch, sunday, memori, day, weekend, mu...</td>\n",
              "      <td>[went, lunch, sunday, memorial, day, weekend, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Ez-8sHPrQdnyv5YZW26V4w</td>\n",
              "      <td>9Xmw_WcUCShPD0qGO1UD7w</td>\n",
              "      <td>77N3luh2YzfJFJGFIfqqbw</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-04-04</td>\n",
              "      <td>Beer baby!! Always love the selection Duke's o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Beer baby Always love the selection Dukes offe...</td>\n",
              "      <td>[beer, baby, always, love, the, selection, duk...</td>\n",
              "      <td>[beer, baby, always, love, selection, dukes, o...</td>\n",
              "      <td>[beer, babi, alway, love, select, duke, offer,...</td>\n",
              "      <td>[beer, baby, always, love, selection, duke, of...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id  ...                               body_text_lemmatized\n",
              "1  8lPKsNFBiLmVL5nbsUXaZw  ...  [husband, went, drake, lunch, today, sat, pati...\n",
              "2  CANhCLzOoZ0mkL3mpnUSNg  ...  [problematic, im, gay, im, ashamed, say, felt,...\n",
              "3  bZ02moAXlosgWPM3pXSHWw  ...  [today, first, time, sat, table, like, wait, w...\n",
              "6  zNXXGTnGOo9pKCN5JyKaPw  ...  [went, lunch, sunday, memorial, day, weekend, ...\n",
              "7  Ez-8sHPrQdnyv5YZW26V4w  ...  [beer, baby, always, love, selection, duke, of...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMmolEh9Frk8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "b8bb5ae9-66e7-4dcc-902e-0d09df2414ef"
      },
      "source": [
        "# Add a length column to DataFrame\n",
        "pandas_df['length'] = pandas_df['text'].apply(len)\n",
        "pandas_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "      <th>body_text_stemmed</th>\n",
              "      <th>body_text_lemmatized</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8lPKsNFBiLmVL5nbsUXaZw</td>\n",
              "      <td>O3pSxv1SyHpY4qi4Q16KzA</td>\n",
              "      <td>dc3uoAmNo5STqKV6mlD_aA</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-30</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>My husband and I went to the Drake for lunch t...</td>\n",
              "      <td>[my, husband, and, i, went, to, the, drake, fo...</td>\n",
              "      <td>[husband, went, drake, lunch, today, sat, pati...</td>\n",
              "      <td>[husband, went, drake, lunch, today, sat, pati...</td>\n",
              "      <td>[husband, went, drake, lunch, today, sat, pati...</td>\n",
              "      <td>407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CANhCLzOoZ0mkL3mpnUSNg</td>\n",
              "      <td>ffC9zmbY4pBOS9ByrWoXxQ</td>\n",
              "      <td>sR9hPrIaG-J-GLcl4yaiLw</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-11-19</td>\n",
              "      <td>Very Problematic\\nI'm gay, I'm not ashamed to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Very Problematic\\nIm gay Im not ashamed to say...</td>\n",
              "      <td>[very, problematic, im, gay, im, not, ashamed,...</td>\n",
              "      <td>[problematic, im, gay, im, ashamed, say, felt,...</td>\n",
              "      <td>[problemat, im, gay, im, asham, say, felt, ash...</td>\n",
              "      <td>[problematic, im, gay, im, ashamed, say, felt,...</td>\n",
              "      <td>483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bZ02moAXlosgWPM3pXSHWw</td>\n",
              "      <td>zE49S2Em3l7vgIlvFzZFOw</td>\n",
              "      <td>NF6di6YcQxN0rDAleE7SyQ</td>\n",
              "      <td>3</td>\n",
              "      <td>2014-12-30</td>\n",
              "      <td>Today was the first time I sat down a table. I...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Today was the first time I sat down a table I ...</td>\n",
              "      <td>[today, was, the, first, time, i, sat, down, a...</td>\n",
              "      <td>[today, first, time, sat, table, like, wait, w...</td>\n",
              "      <td>[today, first, time, sat, tabl, like, wait, we...</td>\n",
              "      <td>[today, first, time, sat, table, like, wait, w...</td>\n",
              "      <td>1682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>zNXXGTnGOo9pKCN5JyKaPw</td>\n",
              "      <td>YT4FKLW7YiHDdlXZpqjMHg</td>\n",
              "      <td>y3bMutme81x4PUhb0zaC_A</td>\n",
              "      <td>3</td>\n",
              "      <td>2013-05-27</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Went to lunch Sunday of Memorial Day weekend T...</td>\n",
              "      <td>[went, to, lunch, sunday, of, memorial, day, w...</td>\n",
              "      <td>[went, lunch, sunday, memorial, day, weekend, ...</td>\n",
              "      <td>[went, lunch, sunday, memori, day, weekend, mu...</td>\n",
              "      <td>[went, lunch, sunday, memorial, day, weekend, ...</td>\n",
              "      <td>296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Ez-8sHPrQdnyv5YZW26V4w</td>\n",
              "      <td>9Xmw_WcUCShPD0qGO1UD7w</td>\n",
              "      <td>77N3luh2YzfJFJGFIfqqbw</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-04-04</td>\n",
              "      <td>Beer baby!! Always love the selection Duke's o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Beer baby Always love the selection Dukes offe...</td>\n",
              "      <td>[beer, baby, always, love, the, selection, duk...</td>\n",
              "      <td>[beer, baby, always, love, selection, dukes, o...</td>\n",
              "      <td>[beer, babi, alway, love, select, duke, offer,...</td>\n",
              "      <td>[beer, baby, always, love, selection, duke, of...</td>\n",
              "      <td>579</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id  ... length\n",
              "1  8lPKsNFBiLmVL5nbsUXaZw  ...    407\n",
              "2  CANhCLzOoZ0mkL3mpnUSNg  ...    483\n",
              "3  bZ02moAXlosgWPM3pXSHWw  ...   1682\n",
              "6  zNXXGTnGOo9pKCN5JyKaPw  ...    296\n",
              "7  Ez-8sHPrQdnyv5YZW26V4w  ...    579\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edBuycdkn10s",
        "colab_type": "text"
      },
      "source": [
        "## <br></br>**Pipeline**<br></br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vbt3mBbxzMW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "0fe24f07-552b-4ce8-e0eb-4f23b4c64b38"
      },
      "source": [
        "# Make a copy of data\n",
        "pandas_df_copy = pandas_df.copy()\n",
        "\n",
        "# Select columns for new DataFrame\n",
        "pandas_df_copy = pandas_df_copy[['review_id', 'text', 'stars', 'cool', 'useful', 'funny', 'date', 'business_id', 'user_id', 'length', 'body_text_nostop', 'body_text_stemmed', 'body_text_lemmatized']]\n",
        "\n",
        "# Convert pandas_df to sparks df\n",
        "spark_df = spark.createDataFrame(pandas_df_copy)\n",
        "spark_df.show(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+\n",
            "|           review_id|                text|stars|cool|useful|funny|      date|         business_id|             user_id|length|    body_text_nostop|   body_text_stemmed|body_text_lemmatized|\n",
            "+--------------------+--------------------+-----+----+------+-----+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+\n",
            "|8lPKsNFBiLmVL5nbs...|My husband and I ...|    1|   1|     2|    1|2017-05-30|dc3uoAmNo5STqKV6m...|O3pSxv1SyHpY4qi4Q...|   407|[husband, went, d...|[husband, went, d...|[husband, went, d...|\n",
            "|CANhCLzOoZ0mkL3mp...|Very Problematic\n",
            "...|    1|   0|     0|    0|2017-11-19|sR9hPrIaG-J-GLcl4...|ffC9zmbY4pBOS9Byr...|   483|[problematic, im,...|[problemat, im, g...|[problematic, im,...|\n",
            "|bZ02moAXlosgWPM3p...|Today was the fir...|    3|   0|     0|    0|2014-12-30|NF6di6YcQxN0rDAle...|zE49S2Em3l7vgIlvF...|  1682|[today, first, ti...|[today, first, ti...|[today, first, ti...|\n",
            "|zNXXGTnGOo9pKCN5J...|Went to lunch Sun...|    3|   0|     0|    1|2013-05-27|y3bMutme81x4PUhb0...|YT4FKLW7YiHDdlXZp...|   296|[went, lunch, sun...|[went, lunch, sun...|[went, lunch, sun...|\n",
            "|Ez-8sHPrQdnyv5YZW...|Beer baby!! Alway...|    5|   0|     0|    0|2017-04-04|77N3luh2YzfJFJGFI...|9Xmw_WcUCShPD0qGO...|   579|[beer, baby, alwa...|[beer, babi, alwa...|[beer, baby, alwa...|\n",
            "+--------------------+--------------------+-----+----+------+-----+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kiylt7xOxzVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import functions\n",
        "from pyspark.ml.feature import HashingTF, IDF, StringIndexer"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr4QTe4p4Qdm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "outputId": "c3043eb3-1b9a-400e-cdd1-e55549d00271"
      },
      "source": [
        "# Make stars values a list\n",
        "from pyspark.sql.functions import col, split\n",
        "spark_df = spark_df.withColumn(\"star_array\", split(col(\"stars\"), \" \"))\n",
        "spark_df.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+\n",
            "|           review_id|                text|stars|cool|useful|funny|      date|         business_id|             user_id|length|    body_text_nostop|   body_text_stemmed|body_text_lemmatized|star_array|\n",
            "+--------------------+--------------------+-----+----+------+-----+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+\n",
            "|8lPKsNFBiLmVL5nbs...|My husband and I ...|    1|   1|     2|    1|2017-05-30|dc3uoAmNo5STqKV6m...|O3pSxv1SyHpY4qi4Q...|   407|[husband, went, d...|[husband, went, d...|[husband, went, d...|       [1]|\n",
            "|CANhCLzOoZ0mkL3mp...|Very Problematic\n",
            "...|    1|   0|     0|    0|2017-11-19|sR9hPrIaG-J-GLcl4...|ffC9zmbY4pBOS9Byr...|   483|[problematic, im,...|[problemat, im, g...|[problematic, im,...|       [1]|\n",
            "|bZ02moAXlosgWPM3p...|Today was the fir...|    3|   0|     0|    0|2014-12-30|NF6di6YcQxN0rDAle...|zE49S2Em3l7vgIlvF...|  1682|[today, first, ti...|[today, first, ti...|[today, first, ti...|       [3]|\n",
            "|zNXXGTnGOo9pKCN5J...|Went to lunch Sun...|    3|   0|     0|    1|2013-05-27|y3bMutme81x4PUhb0...|YT4FKLW7YiHDdlXZp...|   296|[went, lunch, sun...|[went, lunch, sun...|[went, lunch, sun...|       [3]|\n",
            "|Ez-8sHPrQdnyv5YZW...|Beer baby!! Alway...|    5|   0|     0|    0|2017-04-04|77N3luh2YzfJFJGFI...|9Xmw_WcUCShPD0qGO...|   579|[beer, baby, alwa...|[beer, babi, alwa...|[beer, baby, alwa...|       [5]|\n",
            "|iLJtdnLX7b8jl-S7m...|The food was grea...|    3|   0|     0|    0|2011-05-20|N0apJkxIem2E8irTB...|fs6yFn_sa7bTaS2aD...|   496|[food, great, cae...|[food, great, cae...|[food, great, cae...|       [3]|\n",
            "|wybLZgnqmYcY1OWCb...|We ordered fish a...|    3|   0|     0|    0|2015-03-11|_lywz7Hllngj466MZ...|rcfKA8hblCsHPTVhK...|   187|[ordered, fish, c...|[order, fish, chi...|[ordered, fish, c...|       [3]|\n",
            "|Pqp8uryZiWBoE_oRO...|Cancelled service...|    1|   0|     2|    0|2016-09-25|uBNoyDrAr-6L5rxhU...|K5-bh_OVK1_FVclv9...|   280|[cancelled, servi...|[cancel, servic, ...|[cancelled, servi...|       [1]|\n",
            "|QsDBb9z3tPjzFt8Je...|Zipps is close to...|    3|   0|     0|    0|2017-06-26|rOKEgdzmhzT99Ob_O...|D_Wp2rzmeQ8Bj5S4W...|   568|[zipps, close, ho...|[zipp, close, hou...|[zipps, close, ho...|       [3]|\n",
            "|twJyqEY3MnQek1WBe...|Located inside th...|    3|   0|     4|    0|2006-03-10|51w8nETUAMrTNQtuH...|JlD8asiXfY1CoGy3V...|  1197|[located, inside,...|[locat, insid, la...|[located, inside,...|       [3]|\n",
            "|wt9aCpqTyO8YjGnAR...|Normally, we orde...|    3|   0|     0|    0|2017-10-30|YTyAiyMYjJrsLqf8E...|Vqlbl1bdOyWpBrUWs...|   493|[normally, order,...|[normal, order, i...|[normally, order,...|       [3]|\n",
            "|QvaAk2B7zLe-_P_Qx...|Finally made it i...|    5|   0|     0|    0|2014-03-22|GrwvBAEALujIOPQeO...|Fhmvs9iw0Jm3SlN0y...|   338|[finally, made, t...|[final, made, tim...|[finally, made, t...|       [5]|\n",
            "|d43_AtPyGUzhxjvZw...|I will not be ord...|    1|   3|     6|    3|2014-08-05|h5qBxa_L-pIdNSOBQ...|d-uzKbfoM8oISsJFP...|   624|[ordering, pizza,...|[order, pizza, av...|[ordering, pizza,...|       [1]|\n",
            "|Uh5pQ4BUo_DMMqalO...|Here are all the ...|    5|   1|     1|    0|2013-12-20|diThW1PH8u7q6DY8d...|up-mcezRNykPU1Rvf...|   459|[ways, place, gre...|[way, place, grea...|[way, place, grea...|       [5]|\n",
            "|1xJ5hoznIZ4_zqi7l...|Penetranter Wirt ...|    1|   0|     0|    0|2014-02-14|MAwzrO4CSSOZNYa7Y...|5QIcnTSeTZiwAvzk3...|   169|[penetranter, wir...|[penetrant, wirt,...|[penetranter, wir...|       [1]|\n",
            "|srH8KZkZiJDwg80yO...|Pros. \n",
            "Friendly w...|    3|   0|     1|    0|2014-11-22|02GctEso08hyhQpkq...|lFY1j36uRMNXzvuyF...|   710|[pros, friendly, ...|[pro, friendli, w...|[pro, friendly, w...|       [3]|\n",
            "|ls9AKZCOIuis85u2X...|My first experien...|    3|   0|     0|    0|2015-03-31|kgw8nBO9ZMRhukfnJ...|_2rRSDaeAmn3v4YOa...|   624|[first, experienc...|[first, experi, w...|[first, experienc...|       [3]|\n",
            "|qTMClsyknJo79IZ5T...|I cannot speak to...|    1|   1|    14|    0|2014-09-24|zhqurYCKYSCZmIEtu...|vz0sVMzFgPnk3t4a8...|  1129|[cannot, speak, s...|[cannot, speak, s...|[cannot, speak, s...|       [1]|\n",
            "|sQkETyapTTKCiArx7...|My friend and I g...|    5|   0|     2|    0|2014-10-12|nTSXoyceCM2E2ajAR...|dEDId4Rp2JpblIfYI...|   886|[friend, got, ple...|[friend, got, ple...|[friend, got, ple...|       [5]|\n",
            "|hDf8wB8GeMqU9VZcJ...|The three stars i...|    3|   1|     1|    1|2017-03-15|hhhHgSaSl6GLtuDoD...|GWcUI9CnrT7F5oHIk...|   796|[three, stars, ba...|[three, star, bas...|[three, star, bas...|       [3]|\n",
            "+--------------------+--------------------+-----+----+------+-----+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58Do7Vby4QkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize a CoutVectorizer\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "star_vectorizer = CountVectorizer(inputCol=\"star_array\", outputCol=\"stars_one_hot\", vocabSize=5, minDF=1.0)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WTHAZPK4QrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a vector model\n",
        "star_vector_model = star_vectorizer.fit(spark_df)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWwyaeRU4Q0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "13ce5b0f-18ba-44e3-d1b7-641529583270"
      },
      "source": [
        "# One hot encoded column\n",
        "df_ohe = star_vector_model.transform(spark_df)\n",
        "df_ohe.show(3)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+\n",
            "|           review_id|                text|stars|cool|useful|funny|      date|         business_id|             user_id|length|    body_text_nostop|   body_text_stemmed|body_text_lemmatized|star_array|stars_one_hot|\n",
            "+--------------------+--------------------+-----+----+------+-----+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+\n",
            "|8lPKsNFBiLmVL5nbs...|My husband and I ...|    1|   1|     2|    1|2017-05-30|dc3uoAmNo5STqKV6m...|O3pSxv1SyHpY4qi4Q...|   407|[husband, went, d...|[husband, went, d...|[husband, went, d...|       [1]|(3,[2],[1.0])|\n",
            "|CANhCLzOoZ0mkL3mp...|Very Problematic\n",
            "...|    1|   0|     0|    0|2017-11-19|sR9hPrIaG-J-GLcl4...|ffC9zmbY4pBOS9Byr...|   483|[problematic, im,...|[problemat, im, g...|[problematic, im,...|       [1]|(3,[2],[1.0])|\n",
            "|bZ02moAXlosgWPM3p...|Today was the fir...|    3|   0|     0|    0|2014-12-30|NF6di6YcQxN0rDAle...|zE49S2Em3l7vgIlvF...|  1682|[today, first, ti...|[today, first, ti...|[today, first, ti...|       [3]|(3,[0],[1.0])|\n",
            "+--------------------+--------------------+-----+----+------+-----+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNFHqcTA4Q9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create all the features to the data set\n",
        "star_rating = StringIndexer(inputCol='stars',outputCol='label')\n",
        "hashingTF = HashingTF(inputCol=\"body_text_stemmed\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO9K26k74sf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "# Create feature vector \n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7myETso4sk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[star_rating, hashingTF, idf, clean_up])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2iX37s_4spP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(df_ohe)\n",
        "cleaned = cleaner.transform(df_ohe)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhsYLkZe4RDV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "36d4f1cd-1505-41c9-85b2-41fcb9952961"
      },
      "source": [
        "cleaned.show(5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+-----+--------------------+--------------------+--------------------+\n",
            "|           review_id|                text|stars|cool|useful|funny|      date|         business_id|             user_id|length|    body_text_nostop|   body_text_stemmed|body_text_lemmatized|star_array|stars_one_hot|label|          hash_token|           idf_token|            features|\n",
            "+--------------------+--------------------+-----+----+------+-----+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+-----+--------------------+--------------------+--------------------+\n",
            "|8lPKsNFBiLmVL5nbs...|My husband and I ...|    1|   1|     2|    1|2017-05-30|dc3uoAmNo5STqKV6m...|O3pSxv1SyHpY4qi4Q...|   407|[husband, went, d...|[husband, went, d...|[husband, went, d...|       [1]|(3,[2],[1.0])|  2.0|(262144,[6872,156...|(262144,[6872,156...|(262145,[6872,156...|\n",
            "|CANhCLzOoZ0mkL3mp...|Very Problematic\n",
            "...|    1|   0|     0|    0|2017-11-19|sR9hPrIaG-J-GLcl4...|ffC9zmbY4pBOS9Byr...|   483|[problematic, im,...|[problemat, im, g...|[problematic, im,...|       [1]|(3,[2],[1.0])|  2.0|(262144,[3067,690...|(262144,[3067,690...|(262145,[3067,690...|\n",
            "|bZ02moAXlosgWPM3p...|Today was the fir...|    3|   0|     0|    0|2014-12-30|NF6di6YcQxN0rDAle...|zE49S2Em3l7vgIlvF...|  1682|[today, first, ti...|[today, first, ti...|[today, first, ti...|       [3]|(3,[0],[1.0])|  0.0|(262144,[1353,232...|(262144,[1353,232...|(262145,[1353,232...|\n",
            "|zNXXGTnGOo9pKCN5J...|Went to lunch Sun...|    3|   0|     0|    1|2013-05-27|y3bMutme81x4PUhb0...|YT4FKLW7YiHDdlXZp...|   296|[went, lunch, sun...|[went, lunch, sun...|[went, lunch, sun...|       [3]|(3,[0],[1.0])|  0.0|(262144,[1353,139...|(262144,[1353,139...|(262145,[1353,139...|\n",
            "|Ez-8sHPrQdnyv5YZW...|Beer baby!! Alway...|    5|   0|     0|    0|2017-04-04|77N3luh2YzfJFJGFI...|9Xmw_WcUCShPD0qGO...|   579|[beer, baby, alwa...|[beer, babi, alwa...|[beer, baby, alwa...|       [5]|(3,[1],[1.0])|  1.0|(262144,[22567,29...|(262144,[22567,29...|(262145,[22567,29...|\n",
            "+--------------------+--------------------+-----+----+------+-----+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+-----+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuHwRtRZKII6",
        "colab_type": "text"
      },
      "source": [
        "# **Machine Learning Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAhQ4n_XJokp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "93266325-9bce-4234-ad6f-5886c2a98b0f"
      },
      "source": [
        "#Drop intermediate columns\n",
        "x=cleaned.select('features', 'label')\n",
        "x.show(5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(262145,[6872,156...|  2.0|\n",
            "|(262145,[3067,690...|  2.0|\n",
            "|(262145,[1353,232...|  0.0|\n",
            "|(262145,[1353,139...|  0.0|\n",
            "|(262145,[22567,29...|  1.0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOw9lb8SL2ck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d7159378-4f26-4364-d2a4-f2c852cec20a"
      },
      "source": [
        "# Check dtypes\n",
        "x.dtypes"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('features', 'vector'), ('label', 'double')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpfYVKpKMKwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "19bc20b8-88a7-498a-d1a8-8886784e7f95"
      },
      "source": [
        "# Import col\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Change column DataType for stars\n",
        "x = x.withColumn('label', col('label').cast('int'))\n",
        "\n",
        "x.show(5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(262145,[6872,156...|    2|\n",
            "|(262145,[3067,690...|    2|\n",
            "|(262145,[1353,232...|    0|\n",
            "|(262145,[1353,139...|    0|\n",
            "|(262145,[22567,29...|    1|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgrfQolZ60kp",
        "colab_type": "text"
      },
      "source": [
        "**Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw4iHzHGJosY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Break data down into a training set and a testing set\n",
        "training, testing = x.randomSplit([0.8, 0.2], 21)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQg1u3srJoyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1sw6FiKJovu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ecf1f949-5864-4b5a-be82-4254ffa66a04"
      },
      "source": [
        "# Use the Class Evaluator for a cleaned description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(predictor.transform(testing))\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.504272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh7jpZOW6vQo",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgWbYha_xWHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Break data down into a training set and a testing set\n",
        "training, testing = x.randomSplit([0.8, 0.2], 21)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ph4zTLsJoqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "# Create a Naive Bayes model and fit training data\n",
        "lg = LogisticRegression()\n",
        "predictor = lg.fit(training)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC6ucu5KJooj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a3f90d15-e6f2-444c-fd3f-3aa4d179142a"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(predictor.transform(testing))\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.740741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f33IsJHRH39v",
        "colab_type": "text"
      },
      "source": [
        "**Multilayer Percepron**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXTWK85rH2xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sib4qnGSH8Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into train and test\n",
        "splits = x.randomSplit([0.8, 0.2], 1234)\n",
        "train = splits[0]\n",
        "test = splits[1]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "495u_f-LIc3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "ca53cbc6-9d02-45e7-860d-9567d0f3decb"
      },
      "source": [
        "train.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(262145,[97,13957...|    1|\n",
            "|(262145,[98,6646,...|    2|\n",
            "|(262145,[170,427,...|    2|\n",
            "|(262145,[170,976,...|    0|\n",
            "|(262145,[234,1395...|    2|\n",
            "|(262145,[234,1729...|    1|\n",
            "|(262145,[353,783,...|    0|\n",
            "|(262145,[353,976,...|    2|\n",
            "|(262145,[353,1353...|    0|\n",
            "|(262145,[353,1707...|    1|\n",
            "|(262145,[353,3028...|    2|\n",
            "|(262145,[353,1034...|    1|\n",
            "|(262145,[353,2234...|    1|\n",
            "|(262145,[382,2437...|    2|\n",
            "|(262145,[427,1560...|    0|\n",
            "|(262145,[427,2325...|    0|\n",
            "|(262145,[427,3811...|    0|\n",
            "|(262145,[535,2089...|    2|\n",
            "|(262145,[584,1353...|    2|\n",
            "|(262145,[604,6981...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzva90r5INFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify layers for the neural network:\n",
        "layers = [62000, 256, 3]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvuLEMTaINRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the trainer and set its parameters\n",
        "trainer = MultilayerPerceptronClassifier(maxIter=10, layers=layers, blockSize=128, seed=1234)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6qc2Z9iJRUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cfd9e287-e4e5-42d4-c791-14ac2f124058"
      },
      "source": [
        "# train the model\n",
        "model = trainer.fit(train)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-4f6cd2c6c383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o440.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 67.0 failed 1 times, most recent failure: Lost task 1.0 in stage 67.0 (TID 124, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:3236)\n\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:456)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1143)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1137)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1206)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1182)\n\tat org.apache.spark.mllib.optimization.LBFGS$CostFun.calculate(LBFGS.scala:261)\n\tat org.apache.spark.mllib.optimization.LBFGS$CostFun.calculate(LBFGS.scala:230)\n\tat breeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:23)\n\tat breeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:41)\n\tat breeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:30)\n\tat breeze.optimize.StrongWolfeLineSearch.breeze$optimize$StrongWolfeLineSearch$$phi$1(StrongWolfe.scala:76)\n\tat breeze.optimize.StrongWolfeLineSearch$$anonfun$minimizeWithBound$1.apply$mcVI$sp(StrongWolfe.scala:149)\n\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\tat breeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:148)\n\tat breeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\n\tat breeze.optimize.LBFGS.determineStepSize(LBFGS.scala:76)\n\tat breeze.optimize.LBFGS.determineStepSize(LBFGS.scala:39)\n\tat breeze.optimize.FirstOrderMinimizer$$anonfun$infiniteIterations$1.apply(FirstOrderMinimizer.scala:64)\n\tat breeze.optimize.FirstOrderMinimizer$$anonfun$infiniteIterations$1.apply(FirstOrderMinimizer.scala:62)\n\tat scala.collection.Iterator$$anon$7.next(Iterator.scala:129)\n\tat breeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:71)\n\tat org.apache.spark.mllib.optimization.LBFGS$.runLBFGS(LBFGS.scala:212)\n\tat org.apache.spark.mllib.optimization.LBFGS.optimize(LBFGS.scala:142)\n\tat org.apache.spark.ml.ann.FeedForwardTrainer.train(Layer.scala:854)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier$$anonfun$train$1.apply(MultilayerPerceptronClassifier.scala:249)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier$$anonfun$train$1.apply(MultilayerPerceptronClassifier.scala:205)\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier.train(MultilayerPerceptronClassifier.scala:205)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier.train(MultilayerPerceptronClassifier.scala:114)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:3236)\n\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:456)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
          ]
        }
      ]
    }
  ]
}