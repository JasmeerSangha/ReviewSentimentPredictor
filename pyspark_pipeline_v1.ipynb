{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karenbennis/Xy/blob/ml_model/pyspark_pipeline_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x2IxWo3wiqn",
        "colab_type": "text"
      },
      "source": [
        "<br>**Connect to Database**<br><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nCS6homIgnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "a7c65af3-b686-4105-ab9c-bdef6ca281c9"
      },
      "source": [
        "# Install Java, Spark, and Findspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "#Interact with SQL\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
        "\n",
        "# Start Spark Session(Creating spark application with name defined by appName()) ---IMPORTED WITH EVERY COLAB NOTEBOOK\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"database_transformation\").config(\"spark.driver.memory\",\"8g\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-24 00:25:21--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.9.jar.7’\n",
            "\n",
            "\rpostgresql-42.2.9.j   0%[                    ]       0  --.-KB/s               \rpostgresql-42.2.9.j 100%[===================>] 892.61K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-07-24 00:25:21 (9.00 MB/s) - ‘postgresql-42.2.9.jar.7’ saved [914037/914037]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVTkr-xleT8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb553ddf-339b-424b-c6be-d8119eb7b448"
      },
      "source": [
        "# gcloud login and check the DB\n",
        "!gcloud auth login\n",
        "!gcloud config set project 'xy-yelp'\n",
        "!gcloud sql instances describe 'xy-yelp'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&code_challenge=TGHQzzth5e5AMSwqAw6CpiH3wec9voSu-hui-MK-he0&code_challenge_method=S256&access_type=offline&response_type=code&prompt=select_account\n",
            "\n",
            "\n",
            "Enter verification code: 4/2QHe7YUZLypxZoQQ6PhcY2igPX1F0aY8znLdi8Pv6YIxOPyVrLPM_vU\n",
            "\n",
            "You are now logged in as [helenly25@gmail.com].\n",
            "Your current project is [xy-yelp].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n",
            "Updated property [core/project].\n",
            "backendType: SECOND_GEN\n",
            "connectionName: xy-yelp:northamerica-northeast1:xy-yelp\n",
            "databaseVersion: POSTGRES_12\n",
            "etag: bc66e3b4861eccb5afd42f9c257f2fb71f9c6273f5cfcb70659b019d99a17896\n",
            "gceZone: northamerica-northeast1-a\n",
            "instanceType: CLOUD_SQL_INSTANCE\n",
            "ipAddresses:\n",
            "- ipAddress: 34.95.0.17\n",
            "  type: PRIMARY\n",
            "kind: sql#instance\n",
            "name: xy-yelp\n",
            "project: xy-yelp\n",
            "region: northamerica-northeast1\n",
            "selfLink: https://sqladmin.googleapis.com/sql/v1beta4/projects/xy-yelp/instances/xy-yelp\n",
            "serverCaCert:\n",
            "  cert: |-\n",
            "    -----BEGIN CERTIFICATE-----\n",
            "    MIIDfzCCAmegAwIBAgIBADANBgkqhkiG9w0BAQsFADB3MS0wKwYDVQQuEyQzYTcz\n",
            "    ZmJhNS0xYTNlLTQwNmMtOWZhOC1hZGE1MDI3OGZkY2QxIzAhBgNVBAMTGkdvb2ds\n",
            "    ZSBDbG91ZCBTUUwgU2VydmVyIENBMRQwEgYDVQQKEwtHb29nbGUsIEluYzELMAkG\n",
            "    A1UEBhMCVVMwHhcNMjAwNzExMjAwMDA4WhcNMzAwNzA5MjAwMTA4WjB3MS0wKwYD\n",
            "    VQQuEyQzYTczZmJhNS0xYTNlLTQwNmMtOWZhOC1hZGE1MDI3OGZkY2QxIzAhBgNV\n",
            "    BAMTGkdvb2dsZSBDbG91ZCBTUUwgU2VydmVyIENBMRQwEgYDVQQKEwtHb29nbGUs\n",
            "    IEluYzELMAkGA1UEBhMCVVMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIB\n",
            "    AQDMLAiCVUS0u8JRUQSqXLNcXiDU4euUjKhmvbOnDCr2VNVX+dQoq8P+HmL4ruxr\n",
            "    lmLgtNKuhKjqISSzVKDxEf0mudWfOP+ygsXSP6XxLWplHn/N1A881+u+T33u5N0/\n",
            "    wreqH6suvi7Cu/SSEcmYUCnpIy5pSZzO63ww9M4p2HZnG/g/j7uqGdPUpdG4GbCk\n",
            "    jb8EskJiH0hU08ct+AySyc0mrgvfP9l/S5chz0j69uQX/yvWXWy4SSfJ3+wc45Se\n",
            "    8v7WYo+lcwsOu0lGCz53X9Nej0Av47aKUzXD4HlleeMTbkjgYEv2hRWKVoUhzugT\n",
            "    dJTsminBKtnYK1n2witgxNqVAgMBAAGjFjAUMBIGA1UdEwEB/wQIMAYBAf8CAQAw\n",
            "    DQYJKoZIhvcNAQELBQADggEBAB45K3XfFNL/Vkbj0f9daDji+cJHeUS3Y8Uxehog\n",
            "    2rf+rbmwfeH757NZT29o8rSMMfV05z3fuYvS67JvSIDx/I3UsxRGzRZY4EfXXhC9\n",
            "    Vke7AVtfxNgKk86V+JPEGQp52L+PFYdh33DigL8XrWpektxIxf7RAqFIvV0F+0FS\n",
            "    DhXWXkZ8ONFpMK6BCd4aZcKgD0LHafoAKv67+A8IE6b1fFJLh1nkuqZyv1kwLwTM\n",
            "    bLzSMmkgvxuv8d0dmVxWWr/V1kjc2U7oMqF+tgOE+hcF7fWRyRRZko1RtPwjUHlT\n",
            "    qzw5uqZUsxR8S4yyiaeePiF8YnDI72ypyY6FiRMlteAydJs=\n",
            "    -----END CERTIFICATE-----\n",
            "  certSerialNumber: '0'\n",
            "  commonName: C=US,O=Google\\, Inc,CN=Google Cloud SQL Server CA,dnQualifier=3a73fba5-1a3e-406c-9fa8-ada50278fdcd\n",
            "  createTime: '2020-07-11T20:00:08.018Z'\n",
            "  expirationTime: '2030-07-09T20:01:08.018Z'\n",
            "  instance: xy-yelp\n",
            "  kind: sql#sslCert\n",
            "  sha1Fingerprint: 2e2ffdd64d766e372537c174a3d4b91f59ee3e63\n",
            "serviceAccountEmailAddress: p8056368877-0mi1n8@gcp-sa-cloud-sql.iam.gserviceaccount.com\n",
            "settings:\n",
            "  activationPolicy: ALWAYS\n",
            "  availabilityType: ZONAL\n",
            "  backupConfiguration:\n",
            "    enabled: true\n",
            "    kind: sql#backupConfiguration\n",
            "    location: us\n",
            "    pointInTimeRecoveryEnabled: true\n",
            "    replicationLogArchivingEnabled: true\n",
            "    startTime: 13:00\n",
            "  dataDiskSizeGb: '43'\n",
            "  dataDiskType: PD_SSD\n",
            "  ipConfiguration:\n",
            "    authorizedNetworks:\n",
            "    - kind: sql#aclEntry\n",
            "      name: Karen's Residence\n",
            "      value: 173.32.183.48\n",
            "    - kind: sql#aclEntry\n",
            "      name: Helen's Residence\n",
            "      value: 72.142.66.43\n",
            "    - kind: sql#aclEntry\n",
            "      name: Blake Residence\n",
            "      value: 24.114.82.234\n",
            "    ipv4Enabled: true\n",
            "  kind: sql#settings\n",
            "  locationPreference:\n",
            "    kind: sql#locationPreference\n",
            "    zone: northamerica-northeast1-a\n",
            "  maintenanceWindow:\n",
            "    day: 0\n",
            "    hour: 0\n",
            "    kind: sql#maintenanceWindow\n",
            "  pricingPlan: PER_USE\n",
            "  replicationType: SYNCHRONOUS\n",
            "  settingsVersion: '35'\n",
            "  storageAutoResize: true\n",
            "  storageAutoResizeLimit: '0'\n",
            "  tier: db-f1-micro\n",
            "state: RUNNABLE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn_F729PexE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0fab4c63-7393-4262-9b8f-85bb74197391"
      },
      "source": [
        "# download and initialize the psql proxy\n",
        "!wget https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64 -O cloud_sql_proxy\n",
        "!chmod +x cloud_sql_proxy\n",
        "# \"connectionName\" is from the previous block\n",
        "!nohup ./cloud_sql_proxy -instances=\"xy-yelp:northamerica-northeast1:xy-yelp\"=tcp:5432 &\n",
        "!sleep 30s"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cloud_sql_proxy: Text file busy\n",
            "nohup: appending output to 'nohup.out'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Ko5J-Ee7Ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db_password = 'kjhbyelpdb'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs2eCTjpfEd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://127.0.0.1:5432/xy_yelp_db\"\n",
        "config = {\"user\":\"postgres\", \n",
        "          \"password\": db_password, \n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQez-IxYJC_V",
        "colab_type": "text"
      },
      "source": [
        "**Extract tables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uudQwo30fFA-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "925eb681-60c5-40f6-ebaf-4b24e963b43a"
      },
      "source": [
        "# Pull review table\n",
        "review_df2 = spark.read.jdbc(url=jdbc_url, table='review',properties=config)\n",
        "review_df2.show(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+-----------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|review_type|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+-----------+\n",
            "|cALYebKb5hygdKHql...|This is a very in...|    4|   0|     0|    0| 2011-01-12|     review|\n",
            "|SawdMXLYD5ytRmMFv...|I LOVE Chic Nails...|    5|   0|     2|    0| 2011-01-20|     review|\n",
            "|j-jMQdELr6AFkCcEH...|After the Padres ...|    5|   0|     0|    0| 2011-01-06|     review|\n",
            "|SmUMyCUNrT9HEo_DX...|I have to admit t...|    4|   0|     1|    0| 2010-01-17|     review|\n",
            "|oTB_mpCKcu-8wayQQ...|Best food, super ...|    5|   0|     1|    0| 2011-01-14|     review|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pmJIJiDfRb1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "5d09fbc3-2477-4f81-ccfc-ec26b3c67308"
      },
      "source": [
        "# Pull business table\n",
        "business_df2 = spark.read.jdbc(url=jdbc_url, table='business',properties=config)\n",
        "business_df2.show(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|           review_id|         business_id|\n",
            "+--------------------+--------------------+\n",
            "|fWKvX83p0-ka4JS3d...|9yKzy9PApeiPPOUJE...|\n",
            "|IjZ33sJrzXqU-0X6U...|ZRJwVLyzEJq1VAihD...|\n",
            "|IESLBzqUCLdSzSqm0...|6oRAC4uyJCsJl1X0W...|\n",
            "|G-WvGaISbqqaMHlNn...|_1QQZuf4zZOyFCvXc...|\n",
            "|1uJFq2r5QfJG_6ExM...|6ozycU1RpktNG2-1B...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFb2iKvOfRh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "e346f8a3-87b4-4a9d-d632-9b0829b0bdf7"
      },
      "source": [
        "# Pull yelp_user table\n",
        "user_df2 = spark.read.jdbc(url=jdbc_url, table='yelp_user',properties=config)\n",
        "user_df2.show(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|           review_id|             user_id|\n",
            "+--------------------+--------------------+\n",
            "|GJGUHAAONtBSBj53c...|Z3c7xGRfeV-uMkSbA...|\n",
            "|nQH2KAvAeOJOYKX99...|ryjqXdp68i2I9JPOp...|\n",
            "|-yKcbjWSlmKC1zTMT...|5W-ruHmpkwLyI6Lla...|\n",
            "|20aES_-g5Vyqfzojn...|vhxFLqRok6r-D_aQz...|\n",
            "|W_d9w7yr3koSUXHco...|aBnKTxZzdhabTXfzt...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTo3oLx-fRoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "4563c439-ccec-4d8f-8fe5-66db32f293e9"
      },
      "source": [
        "# Join tables\n",
        "spark_df = review_df2.join(business_df2, on=\"review_id\", how=\"inner\")\n",
        "spark_df = spark_df.join(user_df2, on=\"review_id\", how=\"inner\")\n",
        "spark_df.show(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+-----------+--------------------+--------------------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|review_type|         business_id|             user_id|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+-----------+--------------------+--------------------+\n",
            "|-7yxrdY13ay15rGB7...|I have been going...|    5|   0|     0|    0| 2010-01-16|     review|Lh9nz0KYyzE-YRbKu...|ayKW9eWwGFcrtJaHc...|\n",
            "|-Be0UUGYuiDJVAM_Y...|Since Im big into...|    4|   0|     2|    2| 2011-01-25|     review|pa6K7DGByxBXxcVJ5...|_4lqpCYCqOQzbB6xQ...|\n",
            "|-nQHHXi-d_yuW301_...|A pleasant place ...|    2|   0|     0|    0| 2011-01-12|     review|GIGI8bJfN6HyPzmEW...|4QORbyhfN01oKR_Gg...|\n",
            "|2L30O7G8IQ6HILpR0...|part of a social ...|    5|   0|     0|    0| 2010-01-24|     review|qiwajZigq_2twTmYo...|ST8Yzlk2MqKlcaLqL...|\n",
            "|4x5yLG7_yGLuN-w6f...|I love every plac...|    4|   0|     1|    0| 2011-01-02|     review|9yKzy9PApeiPPOUJE...|Vk-hJ1i5ZagPM87Kv...|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+-----------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6k3WVfJM6cE",
        "colab_type": "text"
      },
      "source": [
        "**Transformation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6_h62s7vUEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark_df=spark_df.withColumn('length',F.length('review_text'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5UOtjZNA0BR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "9b439d37-fe7f-4b7e-ea8f-4cd28d910c2b"
      },
      "source": [
        "spark_df = spark_df.filter((spark_df.stars != 2) & (spark_df.stars != 4))\n",
        "spark_df.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+-----------+--------------------+--------------------+------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|review_type|         business_id|             user_id|length|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+-----------+--------------------+--------------------+------+\n",
            "|-7yxrdY13ay15rGB7...|I have been going...|    5|   0|     0|    0| 2010-01-16|     review|Lh9nz0KYyzE-YRbKu...|ayKW9eWwGFcrtJaHc...|   670|\n",
            "|2L30O7G8IQ6HILpR0...|part of a social ...|    5|   0|     0|    0| 2010-01-24|     review|qiwajZigq_2twTmYo...|ST8Yzlk2MqKlcaLqL...|   415|\n",
            "|5h0EVAee-RDbbKfhd...|A great value for...|    5|   2|     1|    0| 2012-01-21|     review|4VzaYvZntWBRbr8Vm...|feQpvbp8jGBWMuG5u...|   284|\n",
            "|6jV77Bs_Vu_rHkdUx...|This review is fo...|    3|   1|     2|    1| 2011-01-23|     review|kwq3bK7BzPKLwXKqV...|RwVaQNP1Ag-Seu3U9...|  1092|\n",
            "|8uV26l7-ktb4tZ5gR...|The new Harkins C...|    5|   0|     1|    0| 2007-01-23|     review|1pGC-0jvQ6vN5rzmC...|nWouNfZD3Pw08RYiz...|   355|\n",
            "|AfDVtSpM6GvkqS1wJ...|This is one of my...|    5|   0|     0|    0| 2010-01-07|     review|nvaAUTTl7oqiJDhui...|LvAr6xG-A40PGk1qu...|   185|\n",
            "|CdAkiPi_KKLjHo5l2...|OK, I went based ...|    5|   1|     5|    1| 2008-01-11|     review|NB6o73F05lw23zpC7...|AdEy5KAIlMAy8xHyu...|  1712|\n",
            "|EnAdKZ_u_wj9ifTRw...|I highly reccomen...|    5|   0|     1|    0| 2012-01-12|     review|rncjoVoEFUJGCUoC1...|HK35ai8frY75iMYBV...|   308|\n",
            "|FBw_MLyO9eduoDfs-...|I was severely mi...|    1|   3|     5|   20| 2011-01-22|     review|MPsCdY0Bwv2G0JXtw...|lhf22sqBafQv6CXu2...|   203|\n",
            "|HPJHQKDVttoNjsnlC...|Where else can yo...|    5|   1|     1|    0| 2012-01-29|     review|5KG0A3WlC7K3DAXtr...|ZRQdOIIhzrzE6sc3e...|   460|\n",
            "|MEdGp-pkf6DAxAsgU...|Awesome food and ...|    5|   0|     0|    0| 2012-01-15|     review|I4bSn5gXsHuSPu7L-...|JfezQ-BqHOE7pnW2D...|    25|\n",
            "|PINoAXjJQpl3yobdD...|Today I went in f...|    3|   0|     0|    0| 2011-01-16|     review|v6zRA0WqOODJjmpvs...|Iycf9KNRhxvR187Qu...|   342|\n",
            "|Q5tzwCvyTZBn6_5N1...|The novelty of th...|    3|   4|     4|    4| 2009-01-24|     review|Zg-C1aYcoR2L5OIrA...|DPMUGzrjTwX5uJtrm...|  1157|\n",
            "|VO1mJpGWPKRdGnJuw...|It does not get m...|    5|   3|     3|    3| 2008-01-15|     review|bcBMAa0UQpNLFvvdZ...|YavFbDG7DUOTXJBLx...|   664|\n",
            "|WNfddsdJW2u3Cd9Mq...|May I add \"family...|    5|   0|     0|    0| 2012-01-23|     review|UScgPn6pIHuOmQJTs...|7W4egS-WyR0hRHMfQ...|   628|\n",
            "|X7Z6rtSPvKOw2TvQx...|Eh, this place is...|    3|   2|     3|    0| 2007-01-26|     review|FUI-hWH_bpis7AKZT...|e4TQFVfepzHf--hnB...|   558|\n",
            "|ZQNhHraFM-ErSZdgh...|Fantastic.  Absol...|    5|   0|     0|    1| 2012-01-05|     review|wNsmt1hF1uv3YvbwX...|1CL12c9zuE36NGhx-...|   704|\n",
            "|aw3lJKaOQy7ayEQ3z...|Just like the oth...|    3|   0|     0|    0| 2012-01-16|     review|irVjrnurmB03bTaj9...|IjafRfMSAQpInLlw-...|   846|\n",
            "|h8wpsGAv2jMNLVk_g...|I am totally addi...|    5|   0|     0|    0| 2008-01-12|     review|Oz1w_3Ck8lalmtxPc...|toD5fpe7--5ljkAz1...|   181|\n",
            "|kX8e5NsQu7fHf221k...|Indiana Universit...|    5|  13|     4|    6| 2008-01-01|     review|hvg4NfkaV-aVqbMzK...|mOirLg2h76o-dPn97...|  1926|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+-----------+--------------------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIcXTo1KKDDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spark_df=spark_df.withColumn('class',F.when( (spark_df[\"stars\"]==1), 0).when((spark_df[\"stars\"]))\n",
        "# spark_df.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYCeG56KqO75",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f736ffd3-1065-42f3-b116-4d08d71f84fd"
      },
      "source": [
        "# convert to pandas\n",
        "pandas_df = spark_df.toPandas()\n",
        "\n",
        "# Set index\n",
        "# pandas_df = pandas_df.set_index('review_id')\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_text</th>\n",
              "      <th>stars</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_type</th>\n",
              "      <th>business_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-7yxrdY13ay15rGB7WibMA</td>\n",
              "      <td>I have been going to Arizona Auto Care since a...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-16</td>\n",
              "      <td>review</td>\n",
              "      <td>Lh9nz0KYyzE-YRbKuCYeUw</td>\n",
              "      <td>ayKW9eWwGFcrtJaHcwZUCw</td>\n",
              "      <td>670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2L30O7G8IQ6HILpR0t5RFA</td>\n",
              "      <td>part of a social event, we only had app's here...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-24</td>\n",
              "      <td>review</td>\n",
              "      <td>qiwajZigq_2twTmYofPmDQ</td>\n",
              "      <td>ST8Yzlk2MqKlcaLqL2djBg</td>\n",
              "      <td>415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5h0EVAee-RDbbKfhd6FB0g</td>\n",
              "      <td>A great value for a far superior hair cut than...</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-01-21</td>\n",
              "      <td>review</td>\n",
              "      <td>4VzaYvZntWBRbr8VmwCiWg</td>\n",
              "      <td>feQpvbp8jGBWMuG5uqbk3Q</td>\n",
              "      <td>284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6jV77Bs_Vu_rHkdUxu9JLQ</td>\n",
              "      <td>This review is for the JCPenny portrait studio...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-23</td>\n",
              "      <td>review</td>\n",
              "      <td>kwq3bK7BzPKLwXKqVRztHg</td>\n",
              "      <td>RwVaQNP1Ag-Seu3U9quGAg</td>\n",
              "      <td>1092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8uV26l7-ktb4tZ5gRsIWWg</td>\n",
              "      <td>The new Harkins Cine Capri, one of the first t...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2007-01-23</td>\n",
              "      <td>review</td>\n",
              "      <td>1pGC-0jvQ6vN5rzmCHjmfg</td>\n",
              "      <td>nWouNfZD3Pw08RYizxkqcA</td>\n",
              "      <td>355</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id  ... length\n",
              "0  -7yxrdY13ay15rGB7WibMA  ...    670\n",
              "1  2L30O7G8IQ6HILpR0t5RFA  ...    415\n",
              "2  5h0EVAee-RDbbKfhd6FB0g  ...    284\n",
              "3  6jV77Bs_Vu_rHkdUxu9JLQ  ...   1092\n",
              "4  8uV26l7-ktb4tZ5gRsIWWg  ...    355\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-oZ7ztJqPAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dependencies for nltk\n",
        "# https://towardsdatascience.com/natural-language-processing-nlp-for-machine-learning-d44498845d5b\n",
        "import nltk"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWjqAnpGsxtM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "40744306-6df9-461b-d043-929409238116"
      },
      "source": [
        "# Import string and punctuations\n",
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUy5O7uUsx3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "de4e00f5-290c-4e96-c630-ac15e7e5dac7"
      },
      "source": [
        "# Function to remove Punctuation\n",
        "def remove_punct(text):\n",
        "\n",
        "  # Discard all punctuations\n",
        "  text_nopunct = ''.join([char for char in text if char not in string.punctuation])\n",
        "  return text_nopunct\n",
        "\n",
        "pandas_df['body_text_clean'] = pandas_df['review_text'].apply(lambda x: remove_punct(x))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_text</th>\n",
              "      <th>stars</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_type</th>\n",
              "      <th>business_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>length</th>\n",
              "      <th>body_text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-7yxrdY13ay15rGB7WibMA</td>\n",
              "      <td>I have been going to Arizona Auto Care since a...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-16</td>\n",
              "      <td>review</td>\n",
              "      <td>Lh9nz0KYyzE-YRbKuCYeUw</td>\n",
              "      <td>ayKW9eWwGFcrtJaHcwZUCw</td>\n",
              "      <td>670</td>\n",
              "      <td>I have been going to Arizona Auto Care since a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2L30O7G8IQ6HILpR0t5RFA</td>\n",
              "      <td>part of a social event, we only had app's here...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-24</td>\n",
              "      <td>review</td>\n",
              "      <td>qiwajZigq_2twTmYofPmDQ</td>\n",
              "      <td>ST8Yzlk2MqKlcaLqL2djBg</td>\n",
              "      <td>415</td>\n",
              "      <td>part of a social event we only had apps here q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5h0EVAee-RDbbKfhd6FB0g</td>\n",
              "      <td>A great value for a far superior hair cut than...</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-01-21</td>\n",
              "      <td>review</td>\n",
              "      <td>4VzaYvZntWBRbr8VmwCiWg</td>\n",
              "      <td>feQpvbp8jGBWMuG5uqbk3Q</td>\n",
              "      <td>284</td>\n",
              "      <td>A great value for a far superior hair cut than...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6jV77Bs_Vu_rHkdUxu9JLQ</td>\n",
              "      <td>This review is for the JCPenny portrait studio...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-23</td>\n",
              "      <td>review</td>\n",
              "      <td>kwq3bK7BzPKLwXKqVRztHg</td>\n",
              "      <td>RwVaQNP1Ag-Seu3U9quGAg</td>\n",
              "      <td>1092</td>\n",
              "      <td>This review is for the JCPenny portrait studio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8uV26l7-ktb4tZ5gRsIWWg</td>\n",
              "      <td>The new Harkins Cine Capri, one of the first t...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2007-01-23</td>\n",
              "      <td>review</td>\n",
              "      <td>1pGC-0jvQ6vN5rzmCHjmfg</td>\n",
              "      <td>nWouNfZD3Pw08RYizxkqcA</td>\n",
              "      <td>355</td>\n",
              "      <td>The new Harkins Cine Capri one of the first th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id  ...                                    body_text_clean\n",
              "0  -7yxrdY13ay15rGB7WibMA  ...  I have been going to Arizona Auto Care since a...\n",
              "1  2L30O7G8IQ6HILpR0t5RFA  ...  part of a social event we only had apps here q...\n",
              "2  5h0EVAee-RDbbKfhd6FB0g  ...  A great value for a far superior hair cut than...\n",
              "3  6jV77Bs_Vu_rHkdUxu9JLQ  ...  This review is for the JCPenny portrait studio...\n",
              "4  8uV26l7-ktb4tZ5gRsIWWg  ...  The new Harkins Cine Capri one of the first th...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x1pQ29xsx-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "f0dbf001-ed6e-44dd-bb73-e98ed82b07be"
      },
      "source": [
        "# Tokenization\n",
        "import re\n",
        "\n",
        "# Function to Tokenize words\n",
        "def tokenize(text):\n",
        "\n",
        "  # W+ means that either a word character (A-Za-z0-9) or a dash (-) can go there\n",
        "  tokens = re.split('\\W+', text)\n",
        "  return tokens\n",
        "\n",
        "# Convert to lowercase as Python is case-sensitive\n",
        "pandas_df['body_text_tokenized'] = pandas_df['body_text_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_text</th>\n",
              "      <th>stars</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_type</th>\n",
              "      <th>business_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>length</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-7yxrdY13ay15rGB7WibMA</td>\n",
              "      <td>I have been going to Arizona Auto Care since a...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-16</td>\n",
              "      <td>review</td>\n",
              "      <td>Lh9nz0KYyzE-YRbKuCYeUw</td>\n",
              "      <td>ayKW9eWwGFcrtJaHcwZUCw</td>\n",
              "      <td>670</td>\n",
              "      <td>I have been going to Arizona Auto Care since a...</td>\n",
              "      <td>[i, have, been, going, to, arizona, auto, care...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2L30O7G8IQ6HILpR0t5RFA</td>\n",
              "      <td>part of a social event, we only had app's here...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-24</td>\n",
              "      <td>review</td>\n",
              "      <td>qiwajZigq_2twTmYofPmDQ</td>\n",
              "      <td>ST8Yzlk2MqKlcaLqL2djBg</td>\n",
              "      <td>415</td>\n",
              "      <td>part of a social event we only had apps here q...</td>\n",
              "      <td>[part, of, a, social, event, we, only, had, ap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5h0EVAee-RDbbKfhd6FB0g</td>\n",
              "      <td>A great value for a far superior hair cut than...</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-01-21</td>\n",
              "      <td>review</td>\n",
              "      <td>4VzaYvZntWBRbr8VmwCiWg</td>\n",
              "      <td>feQpvbp8jGBWMuG5uqbk3Q</td>\n",
              "      <td>284</td>\n",
              "      <td>A great value for a far superior hair cut than...</td>\n",
              "      <td>[a, great, value, for, a, far, superior, hair,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6jV77Bs_Vu_rHkdUxu9JLQ</td>\n",
              "      <td>This review is for the JCPenny portrait studio...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-23</td>\n",
              "      <td>review</td>\n",
              "      <td>kwq3bK7BzPKLwXKqVRztHg</td>\n",
              "      <td>RwVaQNP1Ag-Seu3U9quGAg</td>\n",
              "      <td>1092</td>\n",
              "      <td>This review is for the JCPenny portrait studio...</td>\n",
              "      <td>[this, review, is, for, the, jcpenny, portrait...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8uV26l7-ktb4tZ5gRsIWWg</td>\n",
              "      <td>The new Harkins Cine Capri, one of the first t...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2007-01-23</td>\n",
              "      <td>review</td>\n",
              "      <td>1pGC-0jvQ6vN5rzmCHjmfg</td>\n",
              "      <td>nWouNfZD3Pw08RYizxkqcA</td>\n",
              "      <td>355</td>\n",
              "      <td>The new Harkins Cine Capri one of the first th...</td>\n",
              "      <td>[the, new, harkins, cine, capri, one, of, the,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id  ...                                body_text_tokenized\n",
              "0  -7yxrdY13ay15rGB7WibMA  ...  [i, have, been, going, to, arizona, auto, care...\n",
              "1  2L30O7G8IQ6HILpR0t5RFA  ...  [part, of, a, social, event, we, only, had, ap...\n",
              "2  5h0EVAee-RDbbKfhd6FB0g  ...  [a, great, value, for, a, far, superior, hair,...\n",
              "3  6jV77Bs_Vu_rHkdUxu9JLQ  ...  [this, review, is, for, the, jcpenny, portrait...\n",
              "4  8uV26l7-ktb4tZ5gRsIWWg  ...  [the, new, harkins, cine, capri, one, of, the,...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER0d1Pb3ulKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ac5ce274-000f-42ce-87a2-c2b5e08e8049"
      },
      "source": [
        "# Remove all English stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopword = nltk.corpus.stopwords.words('english') "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA4exlyhulOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "7103ed8f-42d5-4874-fc85-7220bfb25881"
      },
      "source": [
        "# Function to remove stopwords\n",
        "def remove_stopwords(tokenized_list):\n",
        "\n",
        "  # Remove all stopwords\n",
        "  text = [word for word in tokenized_list if word not in stopword]\n",
        "  return text\n",
        "\n",
        "pandas_df['body_text_nostop'] = pandas_df['body_text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_text</th>\n",
              "      <th>stars</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_type</th>\n",
              "      <th>business_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>length</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-7yxrdY13ay15rGB7WibMA</td>\n",
              "      <td>I have been going to Arizona Auto Care since a...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-16</td>\n",
              "      <td>review</td>\n",
              "      <td>Lh9nz0KYyzE-YRbKuCYeUw</td>\n",
              "      <td>ayKW9eWwGFcrtJaHcwZUCw</td>\n",
              "      <td>670</td>\n",
              "      <td>I have been going to Arizona Auto Care since a...</td>\n",
              "      <td>[i, have, been, going, to, arizona, auto, care...</td>\n",
              "      <td>[going, arizona, auto, care, since, 2002, work...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2L30O7G8IQ6HILpR0t5RFA</td>\n",
              "      <td>part of a social event, we only had app's here...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-24</td>\n",
              "      <td>review</td>\n",
              "      <td>qiwajZigq_2twTmYofPmDQ</td>\n",
              "      <td>ST8Yzlk2MqKlcaLqL2djBg</td>\n",
              "      <td>415</td>\n",
              "      <td>part of a social event we only had apps here q...</td>\n",
              "      <td>[part, of, a, social, event, we, only, had, ap...</td>\n",
              "      <td>[part, social, event, apps, quite, delicious, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5h0EVAee-RDbbKfhd6FB0g</td>\n",
              "      <td>A great value for a far superior hair cut than...</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-01-21</td>\n",
              "      <td>review</td>\n",
              "      <td>4VzaYvZntWBRbr8VmwCiWg</td>\n",
              "      <td>feQpvbp8jGBWMuG5uqbk3Q</td>\n",
              "      <td>284</td>\n",
              "      <td>A great value for a far superior hair cut than...</td>\n",
              "      <td>[a, great, value, for, a, far, superior, hair,...</td>\n",
              "      <td>[great, value, far, superior, hair, cut, likel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6jV77Bs_Vu_rHkdUxu9JLQ</td>\n",
              "      <td>This review is for the JCPenny portrait studio...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-23</td>\n",
              "      <td>review</td>\n",
              "      <td>kwq3bK7BzPKLwXKqVRztHg</td>\n",
              "      <td>RwVaQNP1Ag-Seu3U9quGAg</td>\n",
              "      <td>1092</td>\n",
              "      <td>This review is for the JCPenny portrait studio...</td>\n",
              "      <td>[this, review, is, for, the, jcpenny, portrait...</td>\n",
              "      <td>[review, jcpenny, portrait, studio, responsibl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8uV26l7-ktb4tZ5gRsIWWg</td>\n",
              "      <td>The new Harkins Cine Capri, one of the first t...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2007-01-23</td>\n",
              "      <td>review</td>\n",
              "      <td>1pGC-0jvQ6vN5rzmCHjmfg</td>\n",
              "      <td>nWouNfZD3Pw08RYizxkqcA</td>\n",
              "      <td>355</td>\n",
              "      <td>The new Harkins Cine Capri one of the first th...</td>\n",
              "      <td>[the, new, harkins, cine, capri, one, of, the,...</td>\n",
              "      <td>[new, harkins, cine, capri, one, first, things...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id  ...                                   body_text_nostop\n",
              "0  -7yxrdY13ay15rGB7WibMA  ...  [going, arizona, auto, care, since, 2002, work...\n",
              "1  2L30O7G8IQ6HILpR0t5RFA  ...  [part, social, event, apps, quite, delicious, ...\n",
              "2  5h0EVAee-RDbbKfhd6FB0g  ...  [great, value, far, superior, hair, cut, likel...\n",
              "3  6jV77Bs_Vu_rHkdUxu9JLQ  ...  [review, jcpenny, portrait, studio, responsibl...\n",
              "4  8uV26l7-ktb4tZ5gRsIWWg  ...  [new, harkins, cine, capri, one, first, things...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XOi9l2zulSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "26076633-9127-4ef8-fbf1-f6c48cc41eac"
      },
      "source": [
        "# Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Create an instance for stemmer\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "# Function for stemming\n",
        "def stemming(tokenized_text):\n",
        "\n",
        "  text = [ps.stem(word) for word in tokenized_text]\n",
        "  return text\n",
        "\n",
        "pandas_df['body_text_stemmed'] = pandas_df['body_text_nostop'].apply(lambda x: stemming(x))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_text</th>\n",
              "      <th>stars</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_type</th>\n",
              "      <th>business_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>length</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "      <th>body_text_stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-7yxrdY13ay15rGB7WibMA</td>\n",
              "      <td>I have been going to Arizona Auto Care since a...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-16</td>\n",
              "      <td>review</td>\n",
              "      <td>Lh9nz0KYyzE-YRbKuCYeUw</td>\n",
              "      <td>ayKW9eWwGFcrtJaHcwZUCw</td>\n",
              "      <td>670</td>\n",
              "      <td>I have been going to Arizona Auto Care since a...</td>\n",
              "      <td>[i, have, been, going, to, arizona, auto, care...</td>\n",
              "      <td>[going, arizona, auto, care, since, 2002, work...</td>\n",
              "      <td>[go, arizona, auto, care, sinc, 2002, work, co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2L30O7G8IQ6HILpR0t5RFA</td>\n",
              "      <td>part of a social event, we only had app's here...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-24</td>\n",
              "      <td>review</td>\n",
              "      <td>qiwajZigq_2twTmYofPmDQ</td>\n",
              "      <td>ST8Yzlk2MqKlcaLqL2djBg</td>\n",
              "      <td>415</td>\n",
              "      <td>part of a social event we only had apps here q...</td>\n",
              "      <td>[part, of, a, social, event, we, only, had, ap...</td>\n",
              "      <td>[part, social, event, apps, quite, delicious, ...</td>\n",
              "      <td>[part, social, event, app, quit, delici, crab,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5h0EVAee-RDbbKfhd6FB0g</td>\n",
              "      <td>A great value for a far superior hair cut than...</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-01-21</td>\n",
              "      <td>review</td>\n",
              "      <td>4VzaYvZntWBRbr8VmwCiWg</td>\n",
              "      <td>feQpvbp8jGBWMuG5uqbk3Q</td>\n",
              "      <td>284</td>\n",
              "      <td>A great value for a far superior hair cut than...</td>\n",
              "      <td>[a, great, value, for, a, far, superior, hair,...</td>\n",
              "      <td>[great, value, far, superior, hair, cut, likel...</td>\n",
              "      <td>[great, valu, far, superior, hair, cut, like, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6jV77Bs_Vu_rHkdUxu9JLQ</td>\n",
              "      <td>This review is for the JCPenny portrait studio...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-23</td>\n",
              "      <td>review</td>\n",
              "      <td>kwq3bK7BzPKLwXKqVRztHg</td>\n",
              "      <td>RwVaQNP1Ag-Seu3U9quGAg</td>\n",
              "      <td>1092</td>\n",
              "      <td>This review is for the JCPenny portrait studio...</td>\n",
              "      <td>[this, review, is, for, the, jcpenny, portrait...</td>\n",
              "      <td>[review, jcpenny, portrait, studio, responsibl...</td>\n",
              "      <td>[review, jcpenni, portrait, studio, respons, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8uV26l7-ktb4tZ5gRsIWWg</td>\n",
              "      <td>The new Harkins Cine Capri, one of the first t...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2007-01-23</td>\n",
              "      <td>review</td>\n",
              "      <td>1pGC-0jvQ6vN5rzmCHjmfg</td>\n",
              "      <td>nWouNfZD3Pw08RYizxkqcA</td>\n",
              "      <td>355</td>\n",
              "      <td>The new Harkins Cine Capri one of the first th...</td>\n",
              "      <td>[the, new, harkins, cine, capri, one, of, the,...</td>\n",
              "      <td>[new, harkins, cine, capri, one, first, things...</td>\n",
              "      <td>[new, harkin, cine, capri, one, first, thing, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id  ...                                  body_text_stemmed\n",
              "0  -7yxrdY13ay15rGB7WibMA  ...  [go, arizona, auto, care, sinc, 2002, work, co...\n",
              "1  2L30O7G8IQ6HILpR0t5RFA  ...  [part, social, event, app, quit, delici, crab,...\n",
              "2  5h0EVAee-RDbbKfhd6FB0g  ...  [great, valu, far, superior, hair, cut, like, ...\n",
              "3  6jV77Bs_Vu_rHkdUxu9JLQ  ...  [review, jcpenni, portrait, studio, respons, c...\n",
              "4  8uV26l7-ktb4tZ5gRsIWWg  ...  [new, harkin, cine, capri, one, first, thing, ...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NhasPSiuldn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "6b61afec-1924-4e3b-d7fa-ed41042aba55"
      },
      "source": [
        "# Lemmatization\n",
        "# import these modules \n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "# Create an instance\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "\n",
        "def lemmatizing(tokenized_text):\n",
        "\n",
        "  text = [wn.lemmatize(word) for word in tokenized_text]\n",
        "  return text\n",
        "\n",
        "pandas_df['body_text_lemmatized'] = pandas_df['body_text_nostop'].apply(lambda x: lemmatizing(x))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_text</th>\n",
              "      <th>stars</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_type</th>\n",
              "      <th>business_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>length</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "      <th>body_text_stemmed</th>\n",
              "      <th>body_text_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-7yxrdY13ay15rGB7WibMA</td>\n",
              "      <td>I have been going to Arizona Auto Care since a...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-16</td>\n",
              "      <td>review</td>\n",
              "      <td>Lh9nz0KYyzE-YRbKuCYeUw</td>\n",
              "      <td>ayKW9eWwGFcrtJaHcwZUCw</td>\n",
              "      <td>670</td>\n",
              "      <td>I have been going to Arizona Auto Care since a...</td>\n",
              "      <td>[i, have, been, going, to, arizona, auto, care...</td>\n",
              "      <td>[going, arizona, auto, care, since, 2002, work...</td>\n",
              "      <td>[go, arizona, auto, care, sinc, 2002, work, co...</td>\n",
              "      <td>[going, arizona, auto, care, since, 2002, work...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2L30O7G8IQ6HILpR0t5RFA</td>\n",
              "      <td>part of a social event, we only had app's here...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-24</td>\n",
              "      <td>review</td>\n",
              "      <td>qiwajZigq_2twTmYofPmDQ</td>\n",
              "      <td>ST8Yzlk2MqKlcaLqL2djBg</td>\n",
              "      <td>415</td>\n",
              "      <td>part of a social event we only had apps here q...</td>\n",
              "      <td>[part, of, a, social, event, we, only, had, ap...</td>\n",
              "      <td>[part, social, event, apps, quite, delicious, ...</td>\n",
              "      <td>[part, social, event, app, quit, delici, crab,...</td>\n",
              "      <td>[part, social, event, apps, quite, delicious, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5h0EVAee-RDbbKfhd6FB0g</td>\n",
              "      <td>A great value for a far superior hair cut than...</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-01-21</td>\n",
              "      <td>review</td>\n",
              "      <td>4VzaYvZntWBRbr8VmwCiWg</td>\n",
              "      <td>feQpvbp8jGBWMuG5uqbk3Q</td>\n",
              "      <td>284</td>\n",
              "      <td>A great value for a far superior hair cut than...</td>\n",
              "      <td>[a, great, value, for, a, far, superior, hair,...</td>\n",
              "      <td>[great, value, far, superior, hair, cut, likel...</td>\n",
              "      <td>[great, valu, far, superior, hair, cut, like, ...</td>\n",
              "      <td>[great, value, far, superior, hair, cut, likel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6jV77Bs_Vu_rHkdUxu9JLQ</td>\n",
              "      <td>This review is for the JCPenny portrait studio...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-23</td>\n",
              "      <td>review</td>\n",
              "      <td>kwq3bK7BzPKLwXKqVRztHg</td>\n",
              "      <td>RwVaQNP1Ag-Seu3U9quGAg</td>\n",
              "      <td>1092</td>\n",
              "      <td>This review is for the JCPenny portrait studio...</td>\n",
              "      <td>[this, review, is, for, the, jcpenny, portrait...</td>\n",
              "      <td>[review, jcpenny, portrait, studio, responsibl...</td>\n",
              "      <td>[review, jcpenni, portrait, studio, respons, c...</td>\n",
              "      <td>[review, jcpenny, portrait, studio, responsibl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8uV26l7-ktb4tZ5gRsIWWg</td>\n",
              "      <td>The new Harkins Cine Capri, one of the first t...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2007-01-23</td>\n",
              "      <td>review</td>\n",
              "      <td>1pGC-0jvQ6vN5rzmCHjmfg</td>\n",
              "      <td>nWouNfZD3Pw08RYizxkqcA</td>\n",
              "      <td>355</td>\n",
              "      <td>The new Harkins Cine Capri one of the first th...</td>\n",
              "      <td>[the, new, harkins, cine, capri, one, of, the,...</td>\n",
              "      <td>[new, harkins, cine, capri, one, first, things...</td>\n",
              "      <td>[new, harkin, cine, capri, one, first, thing, ...</td>\n",
              "      <td>[new, harkins, cine, capri, one, first, thing,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id  ...                               body_text_lemmatized\n",
              "0  -7yxrdY13ay15rGB7WibMA  ...  [going, arizona, auto, care, since, 2002, work...\n",
              "1  2L30O7G8IQ6HILpR0t5RFA  ...  [part, social, event, apps, quite, delicious, ...\n",
              "2  5h0EVAee-RDbbKfhd6FB0g  ...  [great, value, far, superior, hair, cut, likel...\n",
              "3  6jV77Bs_Vu_rHkdUxu9JLQ  ...  [review, jcpenny, portrait, studio, responsibl...\n",
              "4  8uV26l7-ktb4tZ5gRsIWWg  ...  [new, harkins, cine, capri, one, first, thing,...\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-5BWzzTultW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "X_counts = count_vect.fit_transform(pandas_df['review_text'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_F1-5saxzIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# X_counts_df = pd.DataFrame(X_counts.toarray(), columns=count_vect.get_feature_names())\n",
        "# X_counts_df.head(10)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vbt3mBbxzMW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "2738872d-4758-4cee-fbcb-59544f5bb7ae"
      },
      "source": [
        "pandas_df_copy = pandas_df.copy()\n",
        "\n",
        "pandas_df_copy = pandas_df_copy[['review_id', 'review_text', 'stars', 'cool', 'useful', 'funny', 'review_date', 'business_id', 'user_id', 'length', 'body_text_nostop', 'body_text_stemmed', 'body_text_lemmatized']]\n",
        "\n",
        "# Convert pandas_df to sparks df\n",
        "spark_df = spark.createDataFrame(pandas_df_copy)\n",
        "spark_df.show(5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|         business_id|             user_id|length|    body_text_nostop|   body_text_stemmed|body_text_lemmatized|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+\n",
            "|-7yxrdY13ay15rGB7...|I have been going...|    5|   0|     0|    0| 2010-01-16|Lh9nz0KYyzE-YRbKu...|ayKW9eWwGFcrtJaHc...|   670|[going, arizona, ...|[go, arizona, aut...|[going, arizona, ...|\n",
            "|2L30O7G8IQ6HILpR0...|part of a social ...|    5|   0|     0|    0| 2010-01-24|qiwajZigq_2twTmYo...|ST8Yzlk2MqKlcaLqL...|   415|[part, social, ev...|[part, social, ev...|[part, social, ev...|\n",
            "|5h0EVAee-RDbbKfhd...|A great value for...|    5|   2|     1|    0| 2012-01-21|4VzaYvZntWBRbr8Vm...|feQpvbp8jGBWMuG5u...|   284|[great, value, fa...|[great, valu, far...|[great, value, fa...|\n",
            "|6jV77Bs_Vu_rHkdUx...|This review is fo...|    3|   1|     2|    1| 2011-01-23|kwq3bK7BzPKLwXKqV...|RwVaQNP1Ag-Seu3U9...|  1092|[review, jcpenny,...|[review, jcpenni,...|[review, jcpenny,...|\n",
            "|8uV26l7-ktb4tZ5gR...|The new Harkins C...|    5|   0|     1|    0| 2007-01-23|1pGC-0jvQ6vN5rzmC...|nWouNfZD3Pw08RYiz...|   355|[new, harkins, ci...|[new, harkin, cin...|[new, harkins, ci...|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kiylt7xOxzVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import functions\n",
        "from pyspark.ml.feature import HashingTF, IDF, StringIndexer"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr4QTe4p4Qdm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "92c1ba9b-6b51-435c-f4d4-368127b3825b"
      },
      "source": [
        "# Make stars values a list\n",
        "from pyspark.sql.functions import col, split\n",
        "spark_df = spark_df.withColumn(\"star_array\", split(col(\"stars\"), \" \"))\n",
        "spark_df.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|         business_id|             user_id|length|    body_text_nostop|   body_text_stemmed|body_text_lemmatized|star_array|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+\n",
            "|-7yxrdY13ay15rGB7...|I have been going...|    5|   0|     0|    0| 2010-01-16|Lh9nz0KYyzE-YRbKu...|ayKW9eWwGFcrtJaHc...|   670|[going, arizona, ...|[go, arizona, aut...|[going, arizona, ...|       [5]|\n",
            "|2L30O7G8IQ6HILpR0...|part of a social ...|    5|   0|     0|    0| 2010-01-24|qiwajZigq_2twTmYo...|ST8Yzlk2MqKlcaLqL...|   415|[part, social, ev...|[part, social, ev...|[part, social, ev...|       [5]|\n",
            "|5h0EVAee-RDbbKfhd...|A great value for...|    5|   2|     1|    0| 2012-01-21|4VzaYvZntWBRbr8Vm...|feQpvbp8jGBWMuG5u...|   284|[great, value, fa...|[great, valu, far...|[great, value, fa...|       [5]|\n",
            "|6jV77Bs_Vu_rHkdUx...|This review is fo...|    3|   1|     2|    1| 2011-01-23|kwq3bK7BzPKLwXKqV...|RwVaQNP1Ag-Seu3U9...|  1092|[review, jcpenny,...|[review, jcpenni,...|[review, jcpenny,...|       [3]|\n",
            "|8uV26l7-ktb4tZ5gR...|The new Harkins C...|    5|   0|     1|    0| 2007-01-23|1pGC-0jvQ6vN5rzmC...|nWouNfZD3Pw08RYiz...|   355|[new, harkins, ci...|[new, harkin, cin...|[new, harkins, ci...|       [5]|\n",
            "|AfDVtSpM6GvkqS1wJ...|This is one of my...|    5|   0|     0|    0| 2010-01-07|nvaAUTTl7oqiJDhui...|LvAr6xG-A40PGk1qu...|   185|[one, favorite, b...|[one, favorit, br...|[one, favorite, b...|       [5]|\n",
            "|CdAkiPi_KKLjHo5l2...|OK, I went based ...|    5|   1|     5|    1| 2008-01-11|NB6o73F05lw23zpC7...|AdEy5KAIlMAy8xHyu...|  1712|[ok, went, based,...|[ok, went, base, ...|[ok, went, based,...|       [5]|\n",
            "|EnAdKZ_u_wj9ifTRw...|I highly reccomen...|    5|   0|     1|    0| 2012-01-12|rncjoVoEFUJGCUoC1...|HK35ai8frY75iMYBV...|   308|[highly, reccomen...|[highli, reccomen...|[highly, reccomen...|       [5]|\n",
            "|FBw_MLyO9eduoDfs-...|I was severely mi...|    1|   3|     5|   20| 2011-01-22|MPsCdY0Bwv2G0JXtw...|lhf22sqBafQv6CXu2...|   203|[severely, mislea...|[sever, mislead, ...|[severely, mislea...|       [1]|\n",
            "|HPJHQKDVttoNjsnlC...|Where else can yo...|    5|   1|     1|    0| 2012-01-29|5KG0A3WlC7K3DAXtr...|ZRQdOIIhzrzE6sc3e...|   460|[else, go, chandl...|[els, go, chandle...|[else, go, chandl...|       [5]|\n",
            "|MEdGp-pkf6DAxAsgU...|Awesome food and ...|    5|   0|     0|    0| 2012-01-15|I4bSn5gXsHuSPu7L-...|JfezQ-BqHOE7pnW2D...|    25|[awesome, food, s...|[awesom, food, se...|[awesome, food, s...|       [5]|\n",
            "|PINoAXjJQpl3yobdD...|Today I went in f...|    3|   0|     0|    0| 2011-01-16|v6zRA0WqOODJjmpvs...|Iycf9KNRhxvR187Qu...|   342|[today, went, lun...|[today, went, lun...|[today, went, lun...|       [3]|\n",
            "|Q5tzwCvyTZBn6_5N1...|The novelty of th...|    3|   4|     4|    4| 2009-01-24|Zg-C1aYcoR2L5OIrA...|DPMUGzrjTwX5uJtrm...|  1157|[novelty, place, ...|[novelti, place, ...|[novelty, place, ...|       [3]|\n",
            "|VO1mJpGWPKRdGnJuw...|It does not get m...|    5|   3|     3|    3| 2008-01-15|bcBMAa0UQpNLFvvdZ...|YavFbDG7DUOTXJBLx...|   664|[get, much, bette...|[get, much, bette...|[get, much, bette...|       [5]|\n",
            "|WNfddsdJW2u3Cd9Mq...|May I add \"family...|    5|   0|     0|    0| 2012-01-23|UScgPn6pIHuOmQJTs...|7W4egS-WyR0hRHMfQ...|   628|[may, add, family...|[may, add, famili...|[may, add, family...|       [5]|\n",
            "|X7Z6rtSPvKOw2TvQx...|Eh, this place is...|    3|   2|     3|    0| 2007-01-26|FUI-hWH_bpis7AKZT...|e4TQFVfepzHf--hnB...|   558|[eh, place, okay,...|[eh, place, okay,...|[eh, place, okay,...|       [3]|\n",
            "|ZQNhHraFM-ErSZdgh...|Fantastic.  Absol...|    5|   0|     0|    1| 2012-01-05|wNsmt1hF1uv3YvbwX...|1CL12c9zuE36NGhx-...|   704|[fantastic, absol...|[fantast, absolut...|[fantastic, absol...|       [5]|\n",
            "|aw3lJKaOQy7ayEQ3z...|Just like the oth...|    3|   0|     0|    0| 2012-01-16|irVjrnurmB03bTaj9...|IjafRfMSAQpInLlw-...|   846|[like, yogurt, pl...|[like, yogurt, pl...|[like, yogurt, pl...|       [3]|\n",
            "|h8wpsGAv2jMNLVk_g...|I am totally addi...|    5|   0|     0|    0| 2008-01-12|Oz1w_3Ck8lalmtxPc...|toD5fpe7--5ljkAz1...|   181|[totally, addicte...|[total, addict, p...|[totally, addicte...|       [5]|\n",
            "|kX8e5NsQu7fHf221k...|Indiana Universit...|    5|  13|     4|    6| 2008-01-01|hvg4NfkaV-aVqbMzK...|mOirLg2h76o-dPn97...|  1926|[indiana, univers...|[indiana, univers...|[indiana, univers...|       [5]|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58Do7Vby4QkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize a CoutVectorizer\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "star_vectorizer = CountVectorizer(inputCol=\"star_array\", outputCol=\"stars_one_hot\", vocabSize=5, minDF=1.0)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WTHAZPK4QrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a vector model\n",
        "star_vector_model = star_vectorizer.fit(spark_df)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWwyaeRU4Q0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "175228aa-2b05-470f-988f-543e5e6c36ae"
      },
      "source": [
        "# One hot encoded column\n",
        "df_ohe = star_vector_model.transform(spark_df)\n",
        "df_ohe.show(3)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|         business_id|             user_id|length|    body_text_nostop|   body_text_stemmed|body_text_lemmatized|star_array|stars_one_hot|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+\n",
            "|-7yxrdY13ay15rGB7...|I have been going...|    5|   0|     0|    0| 2010-01-16|Lh9nz0KYyzE-YRbKu...|ayKW9eWwGFcrtJaHc...|   670|[going, arizona, ...|[go, arizona, aut...|[going, arizona, ...|       [5]|(3,[0],[1.0])|\n",
            "|2L30O7G8IQ6HILpR0...|part of a social ...|    5|   0|     0|    0| 2010-01-24|qiwajZigq_2twTmYo...|ST8Yzlk2MqKlcaLqL...|   415|[part, social, ev...|[part, social, ev...|[part, social, ev...|       [5]|(3,[0],[1.0])|\n",
            "|5h0EVAee-RDbbKfhd...|A great value for...|    5|   2|     1|    0| 2012-01-21|4VzaYvZntWBRbr8Vm...|feQpvbp8jGBWMuG5u...|   284|[great, value, fa...|[great, valu, far...|[great, value, fa...|       [5]|(3,[0],[1.0])|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNFHqcTA4Q9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create all the features to the data set\n",
        "star_rating = StringIndexer(inputCol='stars',outputCol='label')\n",
        "hashingTF = HashingTF(inputCol=\"body_text_stemmed\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO9K26k74sf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "# Create feature vector \n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7myETso4sk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[star_rating, hashingTF, idf, clean_up])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2iX37s_4spP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(df_ohe)\n",
        "cleaned = cleaner.transform(df_ohe)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhsYLkZe4RDV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "6aea2929-6c7a-428c-ac5d-9d8d313b456b"
      },
      "source": [
        "cleaned.show(5)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+-----+--------------------+--------------------+--------------------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|         business_id|             user_id|length|    body_text_nostop|   body_text_stemmed|body_text_lemmatized|star_array|stars_one_hot|label|          hash_token|           idf_token|            features|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+-----+--------------------+--------------------+--------------------+\n",
            "|-7yxrdY13ay15rGB7...|I have been going...|    5|   0|     0|    0| 2010-01-16|Lh9nz0KYyzE-YRbKu...|ayKW9eWwGFcrtJaHc...|   670|[going, arizona, ...|[go, arizona, aut...|[going, arizona, ...|       [5]|(3,[0],[1.0])|  0.0|(262144,[7327,133...|(262144,[7327,133...|(262145,[7327,133...|\n",
            "|2L30O7G8IQ6HILpR0...|part of a social ...|    5|   0|     0|    0| 2010-01-24|qiwajZigq_2twTmYo...|ST8Yzlk2MqKlcaLqL...|   415|[part, social, ev...|[part, social, ev...|[part, social, ev...|       [5]|(3,[0],[1.0])|  0.0|(262144,[8804,130...|(262144,[8804,130...|(262145,[8804,130...|\n",
            "|5h0EVAee-RDbbKfhd...|A great value for...|    5|   2|     1|    0| 2012-01-21|4VzaYvZntWBRbr8Vm...|feQpvbp8jGBWMuG5u...|   284|[great, value, fa...|[great, valu, far...|[great, value, fa...|       [5]|(3,[0],[1.0])|  0.0|(262144,[14934,30...|(262144,[14934,30...|(262145,[14934,30...|\n",
            "|6jV77Bs_Vu_rHkdUx...|This review is fo...|    3|   1|     2|    1| 2011-01-23|kwq3bK7BzPKLwXKqV...|RwVaQNP1Ag-Seu3U9...|  1092|[review, jcpenny,...|[review, jcpenni,...|[review, jcpenny,...|       [3]|(3,[1],[1.0])|  1.0|(262144,[5173,844...|(262144,[5173,844...|(262145,[5173,844...|\n",
            "|8uV26l7-ktb4tZ5gR...|The new Harkins C...|    5|   0|     1|    0| 2007-01-23|1pGC-0jvQ6vN5rzmC...|nWouNfZD3Pw08RYiz...|   355|[new, harkins, ci...|[new, harkin, cin...|[new, harkins, ci...|       [5]|(3,[0],[1.0])|  0.0|(262144,[750,1184...|(262144,[750,1184...|(262145,[750,1184...|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+-----+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edBuycdkn10s",
        "colab_type": "text"
      },
      "source": [
        "<br></br>**Pipeline**<br></br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x0XmXV9VBTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import functions\n",
        "# from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsIhoHGLh5OK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make stars values a list\n",
        "# from pyspark.sql.functions import col, split\n",
        "# spark_df = spark_df.withColumn(\"star_array\", split(col(\"stars\"), \" \"))\n",
        "# spark_df.show()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdpCEiGLf1Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize a CoutVectorizer\n",
        "# from pyspark.ml.feature import CountVectorizer\n",
        "# star_vectorizer = CountVectorizer(inputCol=\"star_array\", outputCol=\"stars_one_hot\", vocabSize=5, minDF=1.0)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHSxkv0LhLSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a vector model\n",
        "# star_vector_model = star_vectorizer.fit(spark_df)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PIyUjlWiwg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # One hot encoded column\n",
        "# df_ohe = star_vector_model.transform(spark_df)\n",
        "# df_ohe.show(3)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VorHUGE_vta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create all the features to the data set\n",
        "#star_rating = StringIndexer(inputCol='stars_one_hot',outputCol='label')\n",
        "# tokenizer = Tokenizer(inputCol=\"review_text\", outputCol=\"token_text\")\n",
        "# stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "# hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
        "# idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-05EYS6Bold9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pyspark.ml.feature import VectorAssembler\n",
        "# from pyspark.ml.linalg import Vector\n",
        "# # Create feature vector \n",
        "# clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrqh24KqlJDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create and run a data processing Pipeline\n",
        "# from pyspark.ml import Pipeline\n",
        "# data_prep_pipeline = Pipeline(stages=[tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ_67nv5lKOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "# cleaner = data_prep_pipeline.fit(df_ohe)\n",
        "# cleaned = cleaner.transform(df_ohe)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg-HKC5rqA4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cleaned.show()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f_yjR0QRVuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop redundant column\n",
        "# x=cleaned.drop('review_type')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuHwRtRZKII6",
        "colab_type": "text"
      },
      "source": [
        "# **Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAhQ4n_XJokp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "6d4649a9-28e1-44f9-fc31-d40fdb90f1a6"
      },
      "source": [
        "#Drop intermediate columns\n",
        "x=cleaned.select('features', 'label')\n",
        "x.show(5)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(262145,[7327,133...|  0.0|\n",
            "|(262145,[8804,130...|  0.0|\n",
            "|(262145,[14934,30...|  0.0|\n",
            "|(262145,[5173,844...|  1.0|\n",
            "|(262145,[750,1184...|  0.0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOw9lb8SL2ck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8ab146c4-a84b-4889-b60a-be7b8a212fec"
      },
      "source": [
        "x.dtypes"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('features', 'vector'), ('label', 'double')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpfYVKpKMKwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "d6e35a28-ef3c-44c5-f23a-68034483b7a3"
      },
      "source": [
        "# Import col\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Change column DataType for stars\n",
        "x = x.withColumn('label', col('label').cast('int'))\n",
        "\n",
        "x.show(5)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(262145,[7327,133...|    0|\n",
            "|(262145,[8804,130...|    0|\n",
            "|(262145,[14934,30...|    0|\n",
            "|(262145,[5173,844...|    1|\n",
            "|(262145,[750,1184...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBUVduBPLCad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rename class to label\n",
        "# x = x.withColumnRenamed('stars_one_hot', 'label')\n",
        "# x.show(5)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGwNrKeJVMWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pandas as pd\n",
        "# data_df = x.select('*').toPandas()\n",
        "# x = spark.createDataFrame(data_df)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw4iHzHGJosY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Break data down into a training set and a testing set\n",
        "training, testing = x.randomSplit([0.7, 0.3], 21)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgrfQolZ60kp",
        "colab_type": "text"
      },
      "source": [
        "**Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQg1u3srJoyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1sw6FiKJovu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "01dca5c2-6ae7-41fd-a495-8333a74af179"
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(predictor.transform(testing))\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.522249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh7jpZOW6vQo",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ph4zTLsJoqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "# Create a Naive Bayes model and fit training data\n",
        "lg = LogisticRegression()\n",
        "predictor = lg.fit(training)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC6ucu5KJooj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "23af22b3-977b-42da-f45f-a467553c7972"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(predictor.transform(testing))\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.701011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f33IsJHRH39v",
        "colab_type": "text"
      },
      "source": [
        "**Multilayer Percepron**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXTWK85rH2xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sib4qnGSH8Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into train and test\n",
        "splits = x.randomSplit([0.8, 0.2], 1234)\n",
        "train = splits[0]\n",
        "test = splits[1]"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "495u_f-LIc3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "2668becf-c6b3-4fcb-8fd3-6b3e88300222"
      },
      "source": [
        "train.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(262145,[39,353,3...|    0|\n",
            "|(262145,[47,1251,...|    1|\n",
            "|(262145,[47,1511,...|    0|\n",
            "|(262145,[47,2835,...|    1|\n",
            "|(262145,[58,353,1...|    0|\n",
            "|(262145,[67,1353,...|    0|\n",
            "|(262145,[74,2835,...|    0|\n",
            "|(262145,[74,11137...|    0|\n",
            "|(262145,[90,4096,...|    0|\n",
            "|(262145,[91,1176,...|    0|\n",
            "|(262145,[97,1353,...|    1|\n",
            "|(262145,[97,1810,...|    2|\n",
            "|(262145,[97,5381,...|    0|\n",
            "|(262145,[100,8804...|    1|\n",
            "|(262145,[106,170,...|    0|\n",
            "|(262145,[170,976,...|    1|\n",
            "|(262145,[170,1176...|    1|\n",
            "|(262145,[170,1353...|    0|\n",
            "|(262145,[198,535,...|    0|\n",
            "|(262145,[198,590,...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzva90r5INFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify layers for the neural network:\n",
        "# input layer of size 3 (features), two intermediate of size 5 and 4\n",
        "# and output of size 5 (classes)\n",
        "layers = [262145, 131073, 3]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvuLEMTaINRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the trainer and set its parameters\n",
        "trainer = MultilayerPerceptronClassifier(maxIter=10, layers=layers, blockSize=128, seed=1234)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6qc2Z9iJRUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f51309bc-55d4-4c07-ff8e-12baf931ed68"
      },
      "source": [
        "# train the model\n",
        "model = trainer.fit(train)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Exception happened during processing of request from ('127.0.0.1', 50226)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 351, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 364, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 724, in __init__\n",
            "    self.handle()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/accumulators.py\", line 269, in handle\n",
            "    poll(accum_updates)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
            "    if func():\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
            "    num_updates = read_int(self.rfile)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/serializers.py\", line 724, in read_int\n",
            "    raise EOFError\n",
            "EOFError\n",
            "----------------------------------------\n",
            "--- Logging error ---\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JJavaError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JJavaError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JJavaError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JJavaError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JJavaError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JJavaError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JJavaError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JJavaError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JJavaError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:root:Exception while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JJavaError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "ERROR:root:Exception while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JJavaError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
            "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
            "py4j.protocol.Py4JNetworkError: Error while receiving\n",
            "--- Logging error ---\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "--- Logging error ---\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2899, in run_code\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
            "    self._showtraceback(etype, value, stb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\", line 133, in _showtraceback\n",
            "    'evalue': py3compat.safe_unicode(evalue),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipython_genutils/py3compat.py\", line 65, in safe_unicode\n",
            "    return unicode_type(e)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 468, in __str__\n",
            "    answer = gateway_client.send_command(self.exception_cmd)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
            "    connection = self._get_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
            "    connection = self._create_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
            "    connection.start()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
            "    raise Py4JNetworkError(msg, e)\n",
            "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2899, in run_code\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
            "    self._showtraceback(etype, value, stb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\", line 133, in _showtraceback\n",
            "    'evalue': py3compat.safe_unicode(evalue),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipython_genutils/py3compat.py\", line 65, in safe_unicode\n",
            "    return unicode_type(e)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 468, in __str__\n",
            "    answer = gateway_client.send_command(self.exception_cmd)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
            "    connection = self._get_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
            "    connection = self._create_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
            "    connection.start()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
            "    raise Py4JNetworkError(msg, e)\n",
            "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2899, in run_code\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
            "    self._showtraceback(etype, value, stb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\", line 133, in _showtraceback\n",
            "    'evalue': py3compat.safe_unicode(evalue),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipython_genutils/py3compat.py\", line 65, in safe_unicode\n",
            "    return unicode_type(e)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 468, in __str__\n",
            "    answer = gateway_client.send_command(self.exception_cmd)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
            "    connection = self._get_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
            "    connection = self._create_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
            "    connection.start()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
            "    raise Py4JNetworkError(msg, e)\n",
            "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2899, in run_code\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
            "    self._showtraceback(etype, value, stb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\", line 133, in _showtraceback\n",
            "    'evalue': py3compat.safe_unicode(evalue),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipython_genutils/py3compat.py\", line 65, in safe_unicode\n",
            "    return unicode_type(e)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 468, in __str__\n",
            "    answer = gateway_client.send_command(self.exception_cmd)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
            "    connection = self._get_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
            "    connection = self._create_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
            "    connection.start()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
            "    raise Py4JNetworkError(msg, e)\n",
            "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2899, in run_code\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
            "    self._showtraceback(etype, value, stb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\", line 133, in _showtraceback\n",
            "    'evalue': py3compat.safe_unicode(evalue),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipython_genutils/py3compat.py\", line 65, in safe_unicode\n",
            "    return unicode_type(e)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 468, in __str__\n",
            "    answer = gateway_client.send_command(self.exception_cmd)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
            "    connection = self._get_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
            "    connection = self._create_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
            "    connection.start()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
            "    raise Py4JNetworkError(msg, e)\n",
            "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2899, in run_code\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
            "    self._showtraceback(etype, value, stb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\", line 133, in _showtraceback\n",
            "    'evalue': py3compat.safe_unicode(evalue),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipython_genutils/py3compat.py\", line 65, in safe_unicode\n",
            "    return unicode_type(e)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 468, in __str__\n",
            "    answer = gateway_client.send_command(self.exception_cmd)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
            "    connection = self._get_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
            "    connection = self._create_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
            "    connection.start()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
            "    raise Py4JNetworkError(msg, e)\n",
            "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2899, in run_code\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
            "    self._showtraceback(etype, value, stb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\", line 133, in _showtraceback\n",
            "    'evalue': py3compat.safe_unicode(evalue),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipython_genutils/py3compat.py\", line 65, in safe_unicode\n",
            "    return unicode_type(e)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 468, in __str__\n",
            "    answer = gateway_client.send_command(self.exception_cmd)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
            "    connection = self._get_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
            "    connection = self._create_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
            "    connection.start()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
            "    raise Py4JNetworkError(msg, e)\n",
            "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2899, in run_code\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
            "    self._showtraceback(etype, value, stb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\", line 133, in _showtraceback\n",
            "    'evalue': py3compat.safe_unicode(evalue),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipython_genutils/py3compat.py\", line 65, in safe_unicode\n",
            "    return unicode_type(e)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 468, in __str__\n",
            "    answer = gateway_client.send_command(self.exception_cmd)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
            "    connection = self._get_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
            "    connection = self._create_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
            "    connection.start()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
            "    raise Py4JNetworkError(msg, e)\n",
            "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2899, in run_code\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
            "    self._showtraceback(etype, value, stb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\", line 133, in _showtraceback\n",
            "    'evalue': py3compat.safe_unicode(evalue),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipython_genutils/py3compat.py\", line 65, in safe_unicode\n",
            "    return unicode_type(e)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 468, in __str__\n",
            "    answer = gateway_client.send_command(self.exception_cmd)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
            "    connection = self._get_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
            "    connection = self._create_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
            "    connection.start()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
            "    raise Py4JNetworkError(msg, e)\n",
            "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-61-4f6cd2c6c383>\", line 2, in <module>\n",
            "    model = trainer.fit(train)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\", line 132, in fit\n",
            "    return self._fit(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 295, in _fit\n",
            "    java_model = self._fit_java(dataset)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 292, in _fit_java\n",
            "    return self._java_obj.fit(dataset._jdf)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
            "    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
            "    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2899, in run_code\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
            "    self._showtraceback(etype, value, stb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\", line 133, in _showtraceback\n",
            "    'evalue': py3compat.safe_unicode(evalue),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipython_genutils/py3compat.py\", line 65, in safe_unicode\n",
            "    return unicode_type(e)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 468, in __str__\n",
            "    answer = gateway_client.send_command(self.exception_cmd)\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
            "    connection = self._get_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
            "    connection = self._create_connection()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
            "    connection.start()\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
            "    raise Py4JNetworkError(msg, e)\n",
            "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:40735)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
            "    connection = self.deque.pop()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
            "    self.socket.connect((self.address, self.port))\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "Py4JNetworkError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2881\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2882\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2883\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-4f6cd2c6c383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'py4j.protocol.Py4JNetworkError'>, Py4JNetworkError('An error occurred while trying to connect to the Java server (127.0.0.1:40735)',))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1826\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_pdb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m                         \u001b[0;31m# drop into debugger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36m_showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;34m'traceback'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;34m'ename'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpy3compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;34m'evalue'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpy3compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     }\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipython_genutils/py3compat.py\u001b[0m in \u001b[0;36msafe_unicode\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \"\"\"\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mgateway_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception_cmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_return_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"{0}: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    981\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \"\"\"\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    936\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:40735)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiYwbJB-JT0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBB8_97-JUDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8QrfnccAW8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Authenticate user\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbXgRphaAnNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set project id\n",
        "project_id = 'xy-yelp'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gZLSWomAd5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf45a75c-d78e-4f1e-fa15-91112c8beab8"
      },
      "source": [
        "# Set project\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7k0dj-vBVN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# File path to save json file to\n",
        "filepath = '/tmp/ml_j.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSlyIBEoAjcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save json file **** this will break if the file already exists, which it does at this point, therefore its commented out for now\n",
        "x.coalesce(1).write.format('json').save(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytv4w7eEEs_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bucket name\n",
        "bucket_name = 'xy-bucket'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb1-ZDoaDrGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3635e7d8-ebd1-4304-aeab-f926dac44d35"
      },
      "source": [
        "# Copy saved file from /tmp to bucket\n",
        "!gsutil cp -r /tmp/ml_j.json/ gs://{bucket_name}/json_files/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file:///tmp/ml_j.json/.part-00000-f8a8f21c-0ebe-434c-a8b3-a5c8988dd298-c000.json.crc [Content-Type=application/octet-stream]...\n",
            "Copying file:///tmp/ml_j.json/._SUCCESS.crc [Content-Type=application/octet-stream]...\n",
            "Copying file:///tmp/ml_j.json/_SUCCESS [Content-Type=application/octet-stream]...\n",
            "Copying file:///tmp/ml_j.json/part-00000-f8a8f21c-0ebe-434c-a8b3-a5c8988dd298-c000.json [Content-Type=application/json]...\n",
            "\\\n",
            "Operation completed over 4 objects/63.0 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}