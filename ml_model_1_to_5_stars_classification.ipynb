{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karenbennis/Xy/blob/ml_model/ml_model_1_to_5_stars_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x2IxWo3wiqn",
        "colab_type": "text"
      },
      "source": [
        "## <br>**Connect to Database**<br><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nCS6homIgnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "2eb8a15c-e0a7-4994-f487-1fcfad139e1e"
      },
      "source": [
        "# Install Java, Spark, and Findspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "#Interact with SQL\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
        "\n",
        "# Start Spark Session(Creating spark application with name defined by appName()) ---IMPORTED WITH EVERY COLAB NOTEBOOK\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"database_transformation\").config(\"spark.driver.memory\",\"5g\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-26 18:08:54--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.9.jar.1’\n",
            "\n",
            "postgresql-42.2.9.j 100%[===================>] 892.61K  3.59MB/s    in 0.2s    \n",
            "\n",
            "2020-07-26 18:08:55 (3.59 MB/s) - ‘postgresql-42.2.9.jar.1’ saved [914037/914037]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVTkr-xleT8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3c9baa2-ea89-4670-a958-d8056010289f"
      },
      "source": [
        "# gcloud login and check the DB\n",
        "!gcloud auth login\n",
        "!gcloud config set project 'xy-yelp'\n",
        "!gcloud sql instances describe 'xy-yelp'"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&code_challenge=O-OeXG4htoTCWgAhhK6k2Rtv0jVJzTmbORlo71blpFI&code_challenge_method=S256&access_type=offline&response_type=code&prompt=select_account\n",
            "\n",
            "\n",
            "Enter verification code: 4/2QHtlvfXniwFgxMy0DYG_PcBhAz8sq9kzI3ohGroC1Z5WMNIwaXkEes\n",
            "\n",
            "You are now logged in as [helenly25@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n",
            "\n",
            "\n",
            "To take a quick anonymous survey, run:\n",
            "  $ gcloud survey\n",
            "\n",
            "Updated property [core/project].\n",
            "backendType: SECOND_GEN\n",
            "connectionName: xy-yelp:northamerica-northeast1:xy-yelp\n",
            "databaseVersion: POSTGRES_12\n",
            "etag: 69807e614083e817cfefde96c896961cd31a3f86705c4b3db7e1219fe7ef7cfb\n",
            "gceZone: northamerica-northeast1-a\n",
            "instanceType: CLOUD_SQL_INSTANCE\n",
            "ipAddresses:\n",
            "- ipAddress: 34.95.0.17\n",
            "  type: PRIMARY\n",
            "kind: sql#instance\n",
            "name: xy-yelp\n",
            "project: xy-yelp\n",
            "region: northamerica-northeast1\n",
            "selfLink: https://sqladmin.googleapis.com/sql/v1beta4/projects/xy-yelp/instances/xy-yelp\n",
            "serverCaCert:\n",
            "  cert: |-\n",
            "    -----BEGIN CERTIFICATE-----\n",
            "    MIIDfzCCAmegAwIBAgIBADANBgkqhkiG9w0BAQsFADB3MS0wKwYDVQQuEyQzYTcz\n",
            "    ZmJhNS0xYTNlLTQwNmMtOWZhOC1hZGE1MDI3OGZkY2QxIzAhBgNVBAMTGkdvb2ds\n",
            "    ZSBDbG91ZCBTUUwgU2VydmVyIENBMRQwEgYDVQQKEwtHb29nbGUsIEluYzELMAkG\n",
            "    A1UEBhMCVVMwHhcNMjAwNzExMjAwMDA4WhcNMzAwNzA5MjAwMTA4WjB3MS0wKwYD\n",
            "    VQQuEyQzYTczZmJhNS0xYTNlLTQwNmMtOWZhOC1hZGE1MDI3OGZkY2QxIzAhBgNV\n",
            "    BAMTGkdvb2dsZSBDbG91ZCBTUUwgU2VydmVyIENBMRQwEgYDVQQKEwtHb29nbGUs\n",
            "    IEluYzELMAkGA1UEBhMCVVMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIB\n",
            "    AQDMLAiCVUS0u8JRUQSqXLNcXiDU4euUjKhmvbOnDCr2VNVX+dQoq8P+HmL4ruxr\n",
            "    lmLgtNKuhKjqISSzVKDxEf0mudWfOP+ygsXSP6XxLWplHn/N1A881+u+T33u5N0/\n",
            "    wreqH6suvi7Cu/SSEcmYUCnpIy5pSZzO63ww9M4p2HZnG/g/j7uqGdPUpdG4GbCk\n",
            "    jb8EskJiH0hU08ct+AySyc0mrgvfP9l/S5chz0j69uQX/yvWXWy4SSfJ3+wc45Se\n",
            "    8v7WYo+lcwsOu0lGCz53X9Nej0Av47aKUzXD4HlleeMTbkjgYEv2hRWKVoUhzugT\n",
            "    dJTsminBKtnYK1n2witgxNqVAgMBAAGjFjAUMBIGA1UdEwEB/wQIMAYBAf8CAQAw\n",
            "    DQYJKoZIhvcNAQELBQADggEBAB45K3XfFNL/Vkbj0f9daDji+cJHeUS3Y8Uxehog\n",
            "    2rf+rbmwfeH757NZT29o8rSMMfV05z3fuYvS67JvSIDx/I3UsxRGzRZY4EfXXhC9\n",
            "    Vke7AVtfxNgKk86V+JPEGQp52L+PFYdh33DigL8XrWpektxIxf7RAqFIvV0F+0FS\n",
            "    DhXWXkZ8ONFpMK6BCd4aZcKgD0LHafoAKv67+A8IE6b1fFJLh1nkuqZyv1kwLwTM\n",
            "    bLzSMmkgvxuv8d0dmVxWWr/V1kjc2U7oMqF+tgOE+hcF7fWRyRRZko1RtPwjUHlT\n",
            "    qzw5uqZUsxR8S4yyiaeePiF8YnDI72ypyY6FiRMlteAydJs=\n",
            "    -----END CERTIFICATE-----\n",
            "  certSerialNumber: '0'\n",
            "  commonName: C=US,O=Google\\, Inc,CN=Google Cloud SQL Server CA,dnQualifier=3a73fba5-1a3e-406c-9fa8-ada50278fdcd\n",
            "  createTime: '2020-07-11T20:00:08.018Z'\n",
            "  expirationTime: '2030-07-09T20:01:08.018Z'\n",
            "  instance: xy-yelp\n",
            "  kind: sql#sslCert\n",
            "  sha1Fingerprint: 2e2ffdd64d766e372537c174a3d4b91f59ee3e63\n",
            "serviceAccountEmailAddress: p8056368877-0mi1n8@gcp-sa-cloud-sql.iam.gserviceaccount.com\n",
            "settings:\n",
            "  activationPolicy: ALWAYS\n",
            "  availabilityType: ZONAL\n",
            "  backupConfiguration:\n",
            "    enabled: true\n",
            "    kind: sql#backupConfiguration\n",
            "    location: us\n",
            "    pointInTimeRecoveryEnabled: false\n",
            "    replicationLogArchivingEnabled: false\n",
            "    startTime: 13:00\n",
            "  dataDiskSizeGb: '43'\n",
            "  dataDiskType: PD_SSD\n",
            "  ipConfiguration:\n",
            "    authorizedNetworks:\n",
            "    - kind: sql#aclEntry\n",
            "      name: Blake Residence\n",
            "      value: 24.156.209.223\n",
            "    - kind: sql#aclEntry\n",
            "      name: Karen's Residence\n",
            "      value: 173.32.183.48\n",
            "    - kind: sql#aclEntry\n",
            "      name: Helen's Residence\n",
            "      value: 72.142.66.43\n",
            "    ipv4Enabled: true\n",
            "  kind: sql#settings\n",
            "  locationPreference:\n",
            "    kind: sql#locationPreference\n",
            "    zone: northamerica-northeast1-a\n",
            "  maintenanceWindow:\n",
            "    day: 0\n",
            "    hour: 0\n",
            "    kind: sql#maintenanceWindow\n",
            "  pricingPlan: PER_USE\n",
            "  replicationType: SYNCHRONOUS\n",
            "  settingsVersion: '38'\n",
            "  storageAutoResize: true\n",
            "  storageAutoResizeLimit: '0'\n",
            "  tier: db-f1-micro\n",
            "state: RUNNABLE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn_F729PexE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "cc4fd162-bc6f-4156-9a8e-ef1d57ac1521"
      },
      "source": [
        "# download and initialize the psql proxy\n",
        "!wget https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64 -O cloud_sql_proxy\n",
        "!chmod +x cloud_sql_proxy\n",
        "# \"connectionName\" is from the previous block\n",
        "!nohup ./cloud_sql_proxy -instances=\"xy-yelp:northamerica-northeast1:xy-yelp\"=tcp:5432 &\n",
        "!sleep 30s"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-26 18:09:31--  https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64\n",
            "Resolving dl.google.com (dl.google.com)... 74.125.20.93, 74.125.20.91, 74.125.20.190, ...\n",
            "Connecting to dl.google.com (dl.google.com)|74.125.20.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14492253 (14M) [application/octet-stream]\n",
            "Saving to: ‘cloud_sql_proxy’\n",
            "\n",
            "\rcloud_sql_proxy       0%[                    ]       0  --.-KB/s               \rcloud_sql_proxy     100%[===================>]  13.82M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-07-26 18:09:31 (262 MB/s) - ‘cloud_sql_proxy’ saved [14492253/14492253]\n",
            "\n",
            "nohup: appending output to 'nohup.out'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Ko5J-Ee7Ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db_password = 'kjhbyelpdb'"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs2eCTjpfEd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://127.0.0.1:5432/xy_yelp_db\"\n",
        "config = {\"user\":\"postgres\", \n",
        "          \"password\": db_password, \n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQez-IxYJC_V",
        "colab_type": "text"
      },
      "source": [
        "## **Extract tables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m_qMoGNSZtW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "27e9cfc3-5448-4c72-c25c-72ea744f3e4a"
      },
      "source": [
        "# Read data from database\n",
        "review_df2 = spark.read \\\n",
        "    .jdbc(url=jdbc_url, table='review_two',\n",
        "          properties=config)\n",
        "review_df2.show(5)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+\n",
            "|K8avYPWsh45v7VoZg...|another pie place...|    3|   0|     0|    0| 2008-01-23|\n",
            "|BkiZn5XSzAv9q7J7_...|I came with my si...|    4|   1|     1|    0| 2017-01-30|\n",
            "|L6kc7Nr7hWiqo7ZvW...|I am very disappo...|    1|   0|     0|    0| 2017-01-19|\n",
            "|y35xKzutHXT985mUp...|Stopped for lunch...|    4|   1|     0|    0| 2017-01-04|\n",
            "|UqQGtBDEfkYMLV-Fy...|DON'T DO IT!  You...|    1|   0|     1|    0| 2010-01-20|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIVNiSmMSZx0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "b94297ec-a1da-47d1-b4a9-be48dabc0f9c"
      },
      "source": [
        "# Pull data from business table\n",
        "business_df2 = spark.read \\\n",
        "    .jdbc(url=jdbc_url, table='business_two',\n",
        "          properties=config)\n",
        "business_df2.show(5)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|           review_id|         business_id|\n",
            "+--------------------+--------------------+\n",
            "|K8avYPWsh45v7VoZg...|UGyEr_PMA-v1cuim0...|\n",
            "|BkiZn5XSzAv9q7J7_...|N_2yEZ41g9zDW_gWA...|\n",
            "|L6kc7Nr7hWiqo7ZvW...|XhLM_OtYslzyd4Gyv...|\n",
            "|y35xKzutHXT985mUp...|ILa-Xv5-h23A9OMrY...|\n",
            "|UqQGtBDEfkYMLV-Fy...|gBfPyzPRmeOaj3Sdc...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RaM4bQESZ6a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "c6639d83-e097-4305-bb25-103839e66ff3"
      },
      "source": [
        "# Pull data from yelp_user table\n",
        "\n",
        "user_df2 = spark.read \\\n",
        "    .jdbc(url=jdbc_url, table='yelp_user_two',\n",
        "          properties=config)\n",
        "user_df2.show(5)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|           review_id|             user_id|\n",
            "+--------------------+--------------------+\n",
            "|4gHv8mFFL77vdr6_-...|suiXZ_6jjf9YriAEl...|\n",
            "|CHcdI_ZDxt2L7Ju5v...|Zoec9wehLFa8CV1Jn...|\n",
            "|W5Zkqs8RtShQK8u-m...|Iye9krZCjW79lB324...|\n",
            "|ZVoX65BkaRN0Sr349...|hJ2BkfY_iOhtIizGO...|\n",
            "|e1EEHis4eT6XwagD2...|7msjG0EeNnaef-tWD...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-rNAGJGSZ_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join review_df2 and business_df2\n",
        "review_df2 = review_df2.join(business_df2, on=\"review_id\", how=\"inner\")"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTcAaSk-SaEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "7ea0e69c-1ef7-4874-e6e2-ac6863d3fb6f"
      },
      "source": [
        "# Join review_df2 and user_df2\n",
        "review_df2 = review_df2.join(user_df2, on=\"review_id\", how=\"inner\")\n",
        "review_df2.show(5)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|         business_id|             user_id|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+\n",
            "|06FL63x1PSHK1IE3i...|An hour and a hal...|    1|   0|     0|    0| 2016-01-24|Z3ZSar8IVAR2qIupq...|1luyQBuF2iH1Tbqs3...|\n",
            "|1lGcbt9vMSWY5NLbW...|J'ai été séduite ...|    2|   0|     2|    0| 2015-01-27|frVru1HZYyGZ9sfbO...|AK4k713ocyWht0W47...|\n",
            "|1xXPggQNNBjkwxxwH...|I'm always game t...|    1|   0|     2|    0| 2014-01-22|6tY0tn39Mb8FCLYBA...|gaPf1qNX7PAf14wIP...|\n",
            "|37Ci4Q8bRm3PyYHZH...|Hmmm, it was okay...|    3|   1|     1|    0| 2010-01-17|Rj-7ymdw8aNZBRqGR...|uj4iopBWA0RjpqoJ5...|\n",
            "|37FEOT7W5jpApoad7...|My wife and I had...|    1|   0|     0|    0| 2017-01-25|TTDMJetAQKfxVzKZy...|x20piGQtvm8hOKe8E...|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V87jS7OwSaOn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "ccd56ccb-e1c3-4984-8e99-cae827291d9f"
      },
      "source": [
        "# Create DF with selected columns\n",
        "\n",
        "col_list = ['business_id', 'review_date', 'review_id', 'stars', 'review_text', 'user_id', 'cool', 'useful', 'funny']\n",
        "df = review_df2.select(col_list)\n",
        "df.show(5)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+--------------------+-----+--------------------+--------------------+----+------+-----+\n",
            "|         business_id|review_date|           review_id|stars|         review_text|             user_id|cool|useful|funny|\n",
            "+--------------------+-----------+--------------------+-----+--------------------+--------------------+----+------+-----+\n",
            "|Z3ZSar8IVAR2qIupq...| 2016-01-24|06FL63x1PSHK1IE3i...|    1|An hour and a hal...|1luyQBuF2iH1Tbqs3...|   0|     0|    0|\n",
            "|frVru1HZYyGZ9sfbO...| 2015-01-27|1lGcbt9vMSWY5NLbW...|    2|J'ai été séduite ...|AK4k713ocyWht0W47...|   0|     2|    0|\n",
            "|6tY0tn39Mb8FCLYBA...| 2014-01-22|1xXPggQNNBjkwxxwH...|    1|I'm always game t...|gaPf1qNX7PAf14wIP...|   0|     2|    0|\n",
            "|Rj-7ymdw8aNZBRqGR...| 2010-01-17|37Ci4Q8bRm3PyYHZH...|    3|Hmmm, it was okay...|uj4iopBWA0RjpqoJ5...|   1|     1|    0|\n",
            "|TTDMJetAQKfxVzKZy...| 2017-01-25|37FEOT7W5jpApoad7...|    1|My wife and I had...|x20piGQtvm8hOKe8E...|   0|     0|    0|\n",
            "+--------------------+-----------+--------------------+-----+--------------------+--------------------+----+------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1lx1pjMSZ2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2d9dd19f-1c38-48b6-adfd-008287526232"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert df to a pandas df\n",
        "pandas_df = df.select('*').toPandas()\n",
        "pandas_df.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_text</th>\n",
              "      <th>user_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Z3ZSar8IVAR2qIupqxMynA</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>06FL63x1PSHK1IE3iQ3yqg</td>\n",
              "      <td>1</td>\n",
              "      <td>An hour and a half waiting for a pizza!!!!!! T...</td>\n",
              "      <td>1luyQBuF2iH1Tbqs331uGA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frVru1HZYyGZ9sfbOchaXg</td>\n",
              "      <td>2015-01-27</td>\n",
              "      <td>1lGcbt9vMSWY5NLbW5jx3g</td>\n",
              "      <td>2</td>\n",
              "      <td>J'ai été séduite par l'originalité du lieu qui...</td>\n",
              "      <td>AK4k713ocyWht0W47DvV_g</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6tY0tn39Mb8FCLYBAXXOUw</td>\n",
              "      <td>2014-01-22</td>\n",
              "      <td>1xXPggQNNBjkwxxwHnSHfQ</td>\n",
              "      <td>1</td>\n",
              "      <td>I'm always game to trying all Chinese take-out...</td>\n",
              "      <td>gaPf1qNX7PAf14wIPBUmVg</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rj-7ymdw8aNZBRqGRAjR3Q</td>\n",
              "      <td>2010-01-17</td>\n",
              "      <td>37Ci4Q8bRm3PyYHZHwbFFQ</td>\n",
              "      <td>3</td>\n",
              "      <td>Hmmm, it was okay I guess. Nothing wrong, but ...</td>\n",
              "      <td>uj4iopBWA0RjpqoJ5xz_vQ</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TTDMJetAQKfxVzKZy4Z_2Q</td>\n",
              "      <td>2017-01-25</td>\n",
              "      <td>37FEOT7W5jpApoad7d-23Q</td>\n",
              "      <td>1</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "      <td>x20piGQtvm8hOKe8EkR0VQ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id review_date  ... useful  funny\n",
              "0  Z3ZSar8IVAR2qIupqxMynA  2016-01-24  ...      0      0\n",
              "1  frVru1HZYyGZ9sfbOchaXg  2015-01-27  ...      2      0\n",
              "2  6tY0tn39Mb8FCLYBAXXOUw  2014-01-22  ...      2      0\n",
              "3  Rj-7ymdw8aNZBRqGRAjR3Q  2010-01-17  ...      1      0\n",
              "4  TTDMJetAQKfxVzKZy4Z_2Q  2017-01-25  ...      0      0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6k3WVfJM6cE",
        "colab_type": "text"
      },
      "source": [
        "## **Transformation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-oZ7ztJqPAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dependencies for nltk\n",
        "# https://towardsdatascience.com/natural-language-processing-nlp-for-machine-learning-d44498845d5b\n",
        "import nltk"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWjqAnpGsxtM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dc9a1819-7135-4fb3-f637-3534326c5cc5"
      },
      "source": [
        "# Import string and punctuations\n",
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUy5O7uUsx3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "6684fc71-fdaf-4b2c-fc20-1f4c4796f6c4"
      },
      "source": [
        "# Function to remove Punctuation\n",
        "def remove_punct(text):\n",
        "\n",
        "  # Discard all punctuations\n",
        "  text_nopunct = ''.join([char for char in text if char not in string.punctuation])\n",
        "  return text_nopunct\n",
        "\n",
        "pandas_df['body_text_clean'] = pandas_df['review_text'].apply(lambda x: remove_punct(x))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_text</th>\n",
              "      <th>user_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>body_text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Z3ZSar8IVAR2qIupqxMynA</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>06FL63x1PSHK1IE3iQ3yqg</td>\n",
              "      <td>1</td>\n",
              "      <td>An hour and a half waiting for a pizza!!!!!! T...</td>\n",
              "      <td>1luyQBuF2iH1Tbqs331uGA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>An hour and a half waiting for a pizza This is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frVru1HZYyGZ9sfbOchaXg</td>\n",
              "      <td>2015-01-27</td>\n",
              "      <td>1lGcbt9vMSWY5NLbW5jx3g</td>\n",
              "      <td>2</td>\n",
              "      <td>J'ai été séduite par l'originalité du lieu qui...</td>\n",
              "      <td>AK4k713ocyWht0W47DvV_g</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Jai été séduite par loriginalité du lieu qui n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6tY0tn39Mb8FCLYBAXXOUw</td>\n",
              "      <td>2014-01-22</td>\n",
              "      <td>1xXPggQNNBjkwxxwHnSHfQ</td>\n",
              "      <td>1</td>\n",
              "      <td>I'm always game to trying all Chinese take-out...</td>\n",
              "      <td>gaPf1qNX7PAf14wIPBUmVg</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Im always game to trying all Chinese takeout p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rj-7ymdw8aNZBRqGRAjR3Q</td>\n",
              "      <td>2010-01-17</td>\n",
              "      <td>37Ci4Q8bRm3PyYHZHwbFFQ</td>\n",
              "      <td>3</td>\n",
              "      <td>Hmmm, it was okay I guess. Nothing wrong, but ...</td>\n",
              "      <td>uj4iopBWA0RjpqoJ5xz_vQ</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hmmm it was okay I guess Nothing wrong but not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TTDMJetAQKfxVzKZy4Z_2Q</td>\n",
              "      <td>2017-01-25</td>\n",
              "      <td>37FEOT7W5jpApoad7d-23Q</td>\n",
              "      <td>1</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "      <td>x20piGQtvm8hOKe8EkR0VQ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id  ...                                    body_text_clean\n",
              "0  Z3ZSar8IVAR2qIupqxMynA  ...  An hour and a half waiting for a pizza This is...\n",
              "1  frVru1HZYyGZ9sfbOchaXg  ...  Jai été séduite par loriginalité du lieu qui n...\n",
              "2  6tY0tn39Mb8FCLYBAXXOUw  ...  Im always game to trying all Chinese takeout p...\n",
              "3  Rj-7ymdw8aNZBRqGRAjR3Q  ...  Hmmm it was okay I guess Nothing wrong but not...\n",
              "4  TTDMJetAQKfxVzKZy4Z_2Q  ...  My wife and I had chosen to fly with your airl...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x1pQ29xsx-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "577d38c7-c3d0-420b-d369-5671ec3404f6"
      },
      "source": [
        "# Imort re\n",
        "import re\n",
        "\n",
        "# Function to Tokenize words\n",
        "def tokenize(text):\n",
        "\n",
        "  # W+ means that either a word character (A-Za-z0-9) or a dash (-) can go there\n",
        "  tokens = re.split('\\W+', text)\n",
        "  return tokens\n",
        "\n",
        "# Convert to lowercase as Python is case-sensitive\n",
        "pandas_df['body_text_tokenized'] = pandas_df['body_text_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_text</th>\n",
              "      <th>user_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Z3ZSar8IVAR2qIupqxMynA</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>06FL63x1PSHK1IE3iQ3yqg</td>\n",
              "      <td>1</td>\n",
              "      <td>An hour and a half waiting for a pizza!!!!!! T...</td>\n",
              "      <td>1luyQBuF2iH1Tbqs331uGA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>An hour and a half waiting for a pizza This is...</td>\n",
              "      <td>[an, hour, and, a, half, waiting, for, a, pizz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frVru1HZYyGZ9sfbOchaXg</td>\n",
              "      <td>2015-01-27</td>\n",
              "      <td>1lGcbt9vMSWY5NLbW5jx3g</td>\n",
              "      <td>2</td>\n",
              "      <td>J'ai été séduite par l'originalité du lieu qui...</td>\n",
              "      <td>AK4k713ocyWht0W47DvV_g</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Jai été séduite par loriginalité du lieu qui n...</td>\n",
              "      <td>[jai, été, séduite, par, loriginalité, du, lie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6tY0tn39Mb8FCLYBAXXOUw</td>\n",
              "      <td>2014-01-22</td>\n",
              "      <td>1xXPggQNNBjkwxxwHnSHfQ</td>\n",
              "      <td>1</td>\n",
              "      <td>I'm always game to trying all Chinese take-out...</td>\n",
              "      <td>gaPf1qNX7PAf14wIPBUmVg</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Im always game to trying all Chinese takeout p...</td>\n",
              "      <td>[im, always, game, to, trying, all, chinese, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rj-7ymdw8aNZBRqGRAjR3Q</td>\n",
              "      <td>2010-01-17</td>\n",
              "      <td>37Ci4Q8bRm3PyYHZHwbFFQ</td>\n",
              "      <td>3</td>\n",
              "      <td>Hmmm, it was okay I guess. Nothing wrong, but ...</td>\n",
              "      <td>uj4iopBWA0RjpqoJ5xz_vQ</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hmmm it was okay I guess Nothing wrong but not...</td>\n",
              "      <td>[hmmm, it, was, okay, i, guess, nothing, wrong...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TTDMJetAQKfxVzKZy4Z_2Q</td>\n",
              "      <td>2017-01-25</td>\n",
              "      <td>37FEOT7W5jpApoad7d-23Q</td>\n",
              "      <td>1</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "      <td>x20piGQtvm8hOKe8EkR0VQ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "      <td>[my, wife, and, i, had, chosen, to, fly, with,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id  ...                                body_text_tokenized\n",
              "0  Z3ZSar8IVAR2qIupqxMynA  ...  [an, hour, and, a, half, waiting, for, a, pizz...\n",
              "1  frVru1HZYyGZ9sfbOchaXg  ...  [jai, été, séduite, par, loriginalité, du, lie...\n",
              "2  6tY0tn39Mb8FCLYBAXXOUw  ...  [im, always, game, to, trying, all, chinese, t...\n",
              "3  Rj-7ymdw8aNZBRqGRAjR3Q  ...  [hmmm, it, was, okay, i, guess, nothing, wrong...\n",
              "4  TTDMJetAQKfxVzKZy4Z_2Q  ...  [my, wife, and, i, had, chosen, to, fly, with,...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER0d1Pb3ulKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ab5aa6f8-682d-40aa-f86e-20e5c8ccb04d"
      },
      "source": [
        "# Remove all English stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopword = nltk.corpus.stopwords.words('english') "
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA4exlyhulOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "6532f618-7a07-4c1f-a051-68a0c9c77196"
      },
      "source": [
        "# Function to remove stopwords\n",
        "def remove_stopwords(tokenized_list):\n",
        "\n",
        "  # Remove all stopwords\n",
        "  text = [word for word in tokenized_list if word not in stopword]\n",
        "  return text\n",
        "\n",
        "pandas_df['body_text_nostop'] = pandas_df['body_text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_text</th>\n",
              "      <th>user_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Z3ZSar8IVAR2qIupqxMynA</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>06FL63x1PSHK1IE3iQ3yqg</td>\n",
              "      <td>1</td>\n",
              "      <td>An hour and a half waiting for a pizza!!!!!! T...</td>\n",
              "      <td>1luyQBuF2iH1Tbqs331uGA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>An hour and a half waiting for a pizza This is...</td>\n",
              "      <td>[an, hour, and, a, half, waiting, for, a, pizz...</td>\n",
              "      <td>[hour, half, waiting, pizza, ridiculous, idea,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frVru1HZYyGZ9sfbOchaXg</td>\n",
              "      <td>2015-01-27</td>\n",
              "      <td>1lGcbt9vMSWY5NLbW5jx3g</td>\n",
              "      <td>2</td>\n",
              "      <td>J'ai été séduite par l'originalité du lieu qui...</td>\n",
              "      <td>AK4k713ocyWht0W47DvV_g</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Jai été séduite par loriginalité du lieu qui n...</td>\n",
              "      <td>[jai, été, séduite, par, loriginalité, du, lie...</td>\n",
              "      <td>[jai, été, séduite, par, loriginalité, du, lie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6tY0tn39Mb8FCLYBAXXOUw</td>\n",
              "      <td>2014-01-22</td>\n",
              "      <td>1xXPggQNNBjkwxxwHnSHfQ</td>\n",
              "      <td>1</td>\n",
              "      <td>I'm always game to trying all Chinese take-out...</td>\n",
              "      <td>gaPf1qNX7PAf14wIPBUmVg</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Im always game to trying all Chinese takeout p...</td>\n",
              "      <td>[im, always, game, to, trying, all, chinese, t...</td>\n",
              "      <td>[im, always, game, trying, chinese, takeout, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rj-7ymdw8aNZBRqGRAjR3Q</td>\n",
              "      <td>2010-01-17</td>\n",
              "      <td>37Ci4Q8bRm3PyYHZHwbFFQ</td>\n",
              "      <td>3</td>\n",
              "      <td>Hmmm, it was okay I guess. Nothing wrong, but ...</td>\n",
              "      <td>uj4iopBWA0RjpqoJ5xz_vQ</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hmmm it was okay I guess Nothing wrong but not...</td>\n",
              "      <td>[hmmm, it, was, okay, i, guess, nothing, wrong...</td>\n",
              "      <td>[hmmm, okay, guess, nothing, wrong, nothing, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TTDMJetAQKfxVzKZy4Z_2Q</td>\n",
              "      <td>2017-01-25</td>\n",
              "      <td>37FEOT7W5jpApoad7d-23Q</td>\n",
              "      <td>1</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "      <td>x20piGQtvm8hOKe8EkR0VQ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "      <td>[my, wife, and, i, had, chosen, to, fly, with,...</td>\n",
              "      <td>[wife, chosen, fly, airline, affordable, rates...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id  ...                                   body_text_nostop\n",
              "0  Z3ZSar8IVAR2qIupqxMynA  ...  [hour, half, waiting, pizza, ridiculous, idea,...\n",
              "1  frVru1HZYyGZ9sfbOchaXg  ...  [jai, été, séduite, par, loriginalité, du, lie...\n",
              "2  6tY0tn39Mb8FCLYBAXXOUw  ...  [im, always, game, trying, chinese, takeout, p...\n",
              "3  Rj-7ymdw8aNZBRqGRAjR3Q  ...  [hmmm, okay, guess, nothing, wrong, nothing, o...\n",
              "4  TTDMJetAQKfxVzKZy4Z_2Q  ...  [wife, chosen, fly, airline, affordable, rates...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XOi9l2zulSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "5c814734-e14b-44e6-bcbc-43d2d312063a"
      },
      "source": [
        "# Import PorterStemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Create an instance for stemmer\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "# Function for stemming\n",
        "def stemming(tokenized_text):\n",
        "\n",
        "  text = [ps.stem(word) for word in tokenized_text]\n",
        "  return text\n",
        "\n",
        "pandas_df['body_text_stemmed'] = pandas_df['body_text_nostop'].apply(lambda x: stemming(x))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_text</th>\n",
              "      <th>user_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "      <th>body_text_stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Z3ZSar8IVAR2qIupqxMynA</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>06FL63x1PSHK1IE3iQ3yqg</td>\n",
              "      <td>1</td>\n",
              "      <td>An hour and a half waiting for a pizza!!!!!! T...</td>\n",
              "      <td>1luyQBuF2iH1Tbqs331uGA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>An hour and a half waiting for a pizza This is...</td>\n",
              "      <td>[an, hour, and, a, half, waiting, for, a, pizz...</td>\n",
              "      <td>[hour, half, waiting, pizza, ridiculous, idea,...</td>\n",
              "      <td>[hour, half, wait, pizza, ridicul, idea, order...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frVru1HZYyGZ9sfbOchaXg</td>\n",
              "      <td>2015-01-27</td>\n",
              "      <td>1lGcbt9vMSWY5NLbW5jx3g</td>\n",
              "      <td>2</td>\n",
              "      <td>J'ai été séduite par l'originalité du lieu qui...</td>\n",
              "      <td>AK4k713ocyWht0W47DvV_g</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Jai été séduite par loriginalité du lieu qui n...</td>\n",
              "      <td>[jai, été, séduite, par, loriginalité, du, lie...</td>\n",
              "      <td>[jai, été, séduite, par, loriginalité, du, lie...</td>\n",
              "      <td>[jai, été, séduit, par, loriginalité, du, lieu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6tY0tn39Mb8FCLYBAXXOUw</td>\n",
              "      <td>2014-01-22</td>\n",
              "      <td>1xXPggQNNBjkwxxwHnSHfQ</td>\n",
              "      <td>1</td>\n",
              "      <td>I'm always game to trying all Chinese take-out...</td>\n",
              "      <td>gaPf1qNX7PAf14wIPBUmVg</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Im always game to trying all Chinese takeout p...</td>\n",
              "      <td>[im, always, game, to, trying, all, chinese, t...</td>\n",
              "      <td>[im, always, game, trying, chinese, takeout, p...</td>\n",
              "      <td>[im, alway, game, tri, chines, takeout, place,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rj-7ymdw8aNZBRqGRAjR3Q</td>\n",
              "      <td>2010-01-17</td>\n",
              "      <td>37Ci4Q8bRm3PyYHZHwbFFQ</td>\n",
              "      <td>3</td>\n",
              "      <td>Hmmm, it was okay I guess. Nothing wrong, but ...</td>\n",
              "      <td>uj4iopBWA0RjpqoJ5xz_vQ</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hmmm it was okay I guess Nothing wrong but not...</td>\n",
              "      <td>[hmmm, it, was, okay, i, guess, nothing, wrong...</td>\n",
              "      <td>[hmmm, okay, guess, nothing, wrong, nothing, o...</td>\n",
              "      <td>[hmmm, okay, guess, noth, wrong, noth, outstan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TTDMJetAQKfxVzKZy4Z_2Q</td>\n",
              "      <td>2017-01-25</td>\n",
              "      <td>37FEOT7W5jpApoad7d-23Q</td>\n",
              "      <td>1</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "      <td>x20piGQtvm8hOKe8EkR0VQ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "      <td>[my, wife, and, i, had, chosen, to, fly, with,...</td>\n",
              "      <td>[wife, chosen, fly, airline, affordable, rates...</td>\n",
              "      <td>[wife, chosen, fli, airlin, afford, rate, non,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id  ...                                  body_text_stemmed\n",
              "0  Z3ZSar8IVAR2qIupqxMynA  ...  [hour, half, wait, pizza, ridicul, idea, order...\n",
              "1  frVru1HZYyGZ9sfbOchaXg  ...  [jai, été, séduit, par, loriginalité, du, lieu...\n",
              "2  6tY0tn39Mb8FCLYBAXXOUw  ...  [im, alway, game, tri, chines, takeout, place,...\n",
              "3  Rj-7ymdw8aNZBRqGRAjR3Q  ...  [hmmm, okay, guess, noth, wrong, noth, outstan...\n",
              "4  TTDMJetAQKfxVzKZy4Z_2Q  ...  [wife, chosen, fli, airlin, afford, rate, non,...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NhasPSiuldn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "a9b276e4-6249-44be-e83d-f6fb6da42040"
      },
      "source": [
        "# Download and import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "# Create an instance\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "\n",
        "# Function for Lemmatization\n",
        "def lemmatizing(tokenized_text):\n",
        "\n",
        "  text = [wn.lemmatize(word) for word in tokenized_text]\n",
        "  return text\n",
        "\n",
        "pandas_df['body_text_lemmatized'] = pandas_df['body_text_nostop'].apply(lambda x: lemmatizing(x))\n",
        "\n",
        "pandas_df.head()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_text</th>\n",
              "      <th>user_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "      <th>body_text_stemmed</th>\n",
              "      <th>body_text_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Z3ZSar8IVAR2qIupqxMynA</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>06FL63x1PSHK1IE3iQ3yqg</td>\n",
              "      <td>1</td>\n",
              "      <td>An hour and a half waiting for a pizza!!!!!! T...</td>\n",
              "      <td>1luyQBuF2iH1Tbqs331uGA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>An hour and a half waiting for a pizza This is...</td>\n",
              "      <td>[an, hour, and, a, half, waiting, for, a, pizz...</td>\n",
              "      <td>[hour, half, waiting, pizza, ridiculous, idea,...</td>\n",
              "      <td>[hour, half, wait, pizza, ridicul, idea, order...</td>\n",
              "      <td>[hour, half, waiting, pizza, ridiculous, idea,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frVru1HZYyGZ9sfbOchaXg</td>\n",
              "      <td>2015-01-27</td>\n",
              "      <td>1lGcbt9vMSWY5NLbW5jx3g</td>\n",
              "      <td>2</td>\n",
              "      <td>J'ai été séduite par l'originalité du lieu qui...</td>\n",
              "      <td>AK4k713ocyWht0W47DvV_g</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Jai été séduite par loriginalité du lieu qui n...</td>\n",
              "      <td>[jai, été, séduite, par, loriginalité, du, lie...</td>\n",
              "      <td>[jai, été, séduite, par, loriginalité, du, lie...</td>\n",
              "      <td>[jai, été, séduit, par, loriginalité, du, lieu...</td>\n",
              "      <td>[jai, été, séduite, par, loriginalité, du, lie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6tY0tn39Mb8FCLYBAXXOUw</td>\n",
              "      <td>2014-01-22</td>\n",
              "      <td>1xXPggQNNBjkwxxwHnSHfQ</td>\n",
              "      <td>1</td>\n",
              "      <td>I'm always game to trying all Chinese take-out...</td>\n",
              "      <td>gaPf1qNX7PAf14wIPBUmVg</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Im always game to trying all Chinese takeout p...</td>\n",
              "      <td>[im, always, game, to, trying, all, chinese, t...</td>\n",
              "      <td>[im, always, game, trying, chinese, takeout, p...</td>\n",
              "      <td>[im, alway, game, tri, chines, takeout, place,...</td>\n",
              "      <td>[im, always, game, trying, chinese, takeout, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rj-7ymdw8aNZBRqGRAjR3Q</td>\n",
              "      <td>2010-01-17</td>\n",
              "      <td>37Ci4Q8bRm3PyYHZHwbFFQ</td>\n",
              "      <td>3</td>\n",
              "      <td>Hmmm, it was okay I guess. Nothing wrong, but ...</td>\n",
              "      <td>uj4iopBWA0RjpqoJ5xz_vQ</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hmmm it was okay I guess Nothing wrong but not...</td>\n",
              "      <td>[hmmm, it, was, okay, i, guess, nothing, wrong...</td>\n",
              "      <td>[hmmm, okay, guess, nothing, wrong, nothing, o...</td>\n",
              "      <td>[hmmm, okay, guess, noth, wrong, noth, outstan...</td>\n",
              "      <td>[hmmm, okay, guess, nothing, wrong, nothing, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TTDMJetAQKfxVzKZy4Z_2Q</td>\n",
              "      <td>2017-01-25</td>\n",
              "      <td>37FEOT7W5jpApoad7d-23Q</td>\n",
              "      <td>1</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "      <td>x20piGQtvm8hOKe8EkR0VQ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "      <td>[my, wife, and, i, had, chosen, to, fly, with,...</td>\n",
              "      <td>[wife, chosen, fly, airline, affordable, rates...</td>\n",
              "      <td>[wife, chosen, fli, airlin, afford, rate, non,...</td>\n",
              "      <td>[wife, chosen, fly, airline, affordable, rate,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id  ...                               body_text_lemmatized\n",
              "0  Z3ZSar8IVAR2qIupqxMynA  ...  [hour, half, waiting, pizza, ridiculous, idea,...\n",
              "1  frVru1HZYyGZ9sfbOchaXg  ...  [jai, été, séduite, par, loriginalité, du, lie...\n",
              "2  6tY0tn39Mb8FCLYBAXXOUw  ...  [im, always, game, trying, chinese, takeout, p...\n",
              "3  Rj-7ymdw8aNZBRqGRAjR3Q  ...  [hmmm, okay, guess, nothing, wrong, nothing, o...\n",
              "4  TTDMJetAQKfxVzKZy4Z_2Q  ...  [wife, chosen, fly, airline, affordable, rate,...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMmolEh9Frk8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "fc423180-3177-4098-9cbd-c815e5860a43"
      },
      "source": [
        "# Add a length column to dataset\n",
        "pandas_df['length'] = pandas_df['review_text'].apply(len)\n",
        "pandas_df.head()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_text</th>\n",
              "      <th>user_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "      <th>body_text_stemmed</th>\n",
              "      <th>body_text_lemmatized</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Z3ZSar8IVAR2qIupqxMynA</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>06FL63x1PSHK1IE3iQ3yqg</td>\n",
              "      <td>1</td>\n",
              "      <td>An hour and a half waiting for a pizza!!!!!! T...</td>\n",
              "      <td>1luyQBuF2iH1Tbqs331uGA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>An hour and a half waiting for a pizza This is...</td>\n",
              "      <td>[an, hour, and, a, half, waiting, for, a, pizz...</td>\n",
              "      <td>[hour, half, waiting, pizza, ridiculous, idea,...</td>\n",
              "      <td>[hour, half, wait, pizza, ridicul, idea, order...</td>\n",
              "      <td>[hour, half, waiting, pizza, ridiculous, idea,...</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frVru1HZYyGZ9sfbOchaXg</td>\n",
              "      <td>2015-01-27</td>\n",
              "      <td>1lGcbt9vMSWY5NLbW5jx3g</td>\n",
              "      <td>2</td>\n",
              "      <td>J'ai été séduite par l'originalité du lieu qui...</td>\n",
              "      <td>AK4k713ocyWht0W47DvV_g</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Jai été séduite par loriginalité du lieu qui n...</td>\n",
              "      <td>[jai, été, séduite, par, loriginalité, du, lie...</td>\n",
              "      <td>[jai, été, séduite, par, loriginalité, du, lie...</td>\n",
              "      <td>[jai, été, séduit, par, loriginalité, du, lieu...</td>\n",
              "      <td>[jai, été, séduite, par, loriginalité, du, lie...</td>\n",
              "      <td>582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6tY0tn39Mb8FCLYBAXXOUw</td>\n",
              "      <td>2014-01-22</td>\n",
              "      <td>1xXPggQNNBjkwxxwHnSHfQ</td>\n",
              "      <td>1</td>\n",
              "      <td>I'm always game to trying all Chinese take-out...</td>\n",
              "      <td>gaPf1qNX7PAf14wIPBUmVg</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Im always game to trying all Chinese takeout p...</td>\n",
              "      <td>[im, always, game, to, trying, all, chinese, t...</td>\n",
              "      <td>[im, always, game, trying, chinese, takeout, p...</td>\n",
              "      <td>[im, alway, game, tri, chines, takeout, place,...</td>\n",
              "      <td>[im, always, game, trying, chinese, takeout, p...</td>\n",
              "      <td>858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rj-7ymdw8aNZBRqGRAjR3Q</td>\n",
              "      <td>2010-01-17</td>\n",
              "      <td>37Ci4Q8bRm3PyYHZHwbFFQ</td>\n",
              "      <td>3</td>\n",
              "      <td>Hmmm, it was okay I guess. Nothing wrong, but ...</td>\n",
              "      <td>uj4iopBWA0RjpqoJ5xz_vQ</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hmmm it was okay I guess Nothing wrong but not...</td>\n",
              "      <td>[hmmm, it, was, okay, i, guess, nothing, wrong...</td>\n",
              "      <td>[hmmm, okay, guess, nothing, wrong, nothing, o...</td>\n",
              "      <td>[hmmm, okay, guess, noth, wrong, noth, outstan...</td>\n",
              "      <td>[hmmm, okay, guess, nothing, wrong, nothing, o...</td>\n",
              "      <td>1453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TTDMJetAQKfxVzKZy4Z_2Q</td>\n",
              "      <td>2017-01-25</td>\n",
              "      <td>37FEOT7W5jpApoad7d-23Q</td>\n",
              "      <td>1</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "      <td>x20piGQtvm8hOKe8EkR0VQ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>My wife and I had chosen to fly with your airl...</td>\n",
              "      <td>[my, wife, and, i, had, chosen, to, fly, with,...</td>\n",
              "      <td>[wife, chosen, fly, airline, affordable, rates...</td>\n",
              "      <td>[wife, chosen, fli, airlin, afford, rate, non,...</td>\n",
              "      <td>[wife, chosen, fly, airline, affordable, rate,...</td>\n",
              "      <td>2539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id  ... length\n",
              "0  Z3ZSar8IVAR2qIupqxMynA  ...    113\n",
              "1  frVru1HZYyGZ9sfbOchaXg  ...    582\n",
              "2  6tY0tn39Mb8FCLYBAXXOUw  ...    858\n",
              "3  Rj-7ymdw8aNZBRqGRAjR3Q  ...   1453\n",
              "4  TTDMJetAQKfxVzKZy4Z_2Q  ...   2539\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edBuycdkn10s",
        "colab_type": "text"
      },
      "source": [
        "## <br></br>**Pipeline**<br></br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vbt3mBbxzMW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "8341d3d4-bcac-4587-c20a-149aba2b8c33"
      },
      "source": [
        "# Make a copy of the data\n",
        "pandas_df_copy = pandas_df.copy()\n",
        "\n",
        "# Select columns for the DataFrame\n",
        "pandas_df_copy = pandas_df_copy[['review_id', 'review_text', 'stars', 'cool', 'useful', 'funny', 'review_date', 'business_id', 'user_id', 'length', 'body_text_nostop', 'body_text_stemmed', 'body_text_lemmatized']]\n",
        "\n",
        "# Convert pandas_df to sparks df\n",
        "spark_df = spark.createDataFrame(pandas_df_copy)\n",
        "spark_df.show(5)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|         business_id|             user_id|length|    body_text_nostop|   body_text_stemmed|body_text_lemmatized|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+\n",
            "|06FL63x1PSHK1IE3i...|An hour and a hal...|    1|   0|     0|    0| 2016-01-24|Z3ZSar8IVAR2qIupq...|1luyQBuF2iH1Tbqs3...|   113|[hour, half, wait...|[hour, half, wait...|[hour, half, wait...|\n",
            "|1lGcbt9vMSWY5NLbW...|J'ai été séduite ...|    2|   0|     2|    0| 2015-01-27|frVru1HZYyGZ9sfbO...|AK4k713ocyWht0W47...|   582|[jai, été, séduit...|[jai, été, séduit...|[jai, été, séduit...|\n",
            "|1xXPggQNNBjkwxxwH...|I'm always game t...|    1|   0|     2|    0| 2014-01-22|6tY0tn39Mb8FCLYBA...|gaPf1qNX7PAf14wIP...|   858|[im, always, game...|[im, alway, game,...|[im, always, game...|\n",
            "|37Ci4Q8bRm3PyYHZH...|Hmmm, it was okay...|    3|   1|     1|    0| 2010-01-17|Rj-7ymdw8aNZBRqGR...|uj4iopBWA0RjpqoJ5...|  1453|[hmmm, okay, gues...|[hmmm, okay, gues...|[hmmm, okay, gues...|\n",
            "|37FEOT7W5jpApoad7...|My wife and I had...|    1|   0|     0|    0| 2017-01-25|TTDMJetAQKfxVzKZy...|x20piGQtvm8hOKe8E...|  2539|[wife, chosen, fl...|[wife, chosen, fl...|[wife, chosen, fl...|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kiylt7xOxzVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import functions\n",
        "from pyspark.ml.feature import HashingTF, IDF, StringIndexer"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr4QTe4p4Qdm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "8a33ac73-02a3-4a42-9bb8-1ce53ae6276d"
      },
      "source": [
        "# Make stars values a list\n",
        "from pyspark.sql.functions import col, split\n",
        "spark_df = spark_df.withColumn(\"star_array\", split(col(\"stars\"), \" \"))\n",
        "spark_df.show()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|         business_id|             user_id|length|    body_text_nostop|   body_text_stemmed|body_text_lemmatized|star_array|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+\n",
            "|06FL63x1PSHK1IE3i...|An hour and a hal...|    1|   0|     0|    0| 2016-01-24|Z3ZSar8IVAR2qIupq...|1luyQBuF2iH1Tbqs3...|   113|[hour, half, wait...|[hour, half, wait...|[hour, half, wait...|       [1]|\n",
            "|1lGcbt9vMSWY5NLbW...|J'ai été séduite ...|    2|   0|     2|    0| 2015-01-27|frVru1HZYyGZ9sfbO...|AK4k713ocyWht0W47...|   582|[jai, été, séduit...|[jai, été, séduit...|[jai, été, séduit...|       [2]|\n",
            "|1xXPggQNNBjkwxxwH...|I'm always game t...|    1|   0|     2|    0| 2014-01-22|6tY0tn39Mb8FCLYBA...|gaPf1qNX7PAf14wIP...|   858|[im, always, game...|[im, alway, game,...|[im, always, game...|       [1]|\n",
            "|37Ci4Q8bRm3PyYHZH...|Hmmm, it was okay...|    3|   1|     1|    0| 2010-01-17|Rj-7ymdw8aNZBRqGR...|uj4iopBWA0RjpqoJ5...|  1453|[hmmm, okay, gues...|[hmmm, okay, gues...|[hmmm, okay, gues...|       [3]|\n",
            "|37FEOT7W5jpApoad7...|My wife and I had...|    1|   0|     0|    0| 2017-01-25|TTDMJetAQKfxVzKZy...|x20piGQtvm8hOKe8E...|  2539|[wife, chosen, fl...|[wife, chosen, fl...|[wife, chosen, fl...|       [1]|\n",
            "|6lQS-_8VbWtUkZ3ZS...|Love this place! ...|    5|   0|     0|    0| 2017-01-03|99TrGqU8ngQphSkvo...|vWlZqhUfeN8J0_k2N...|   206|[love, place, alw...|[love, place, alw...|[love, place, alw...|       [5]|\n",
            "|7B01plLvo_8KiC_iU...|This is Streetsvi...|    3|   0|     0|    0| 2015-01-31|D6UIhxSGysLlZK8Vc...|pMefTWo6gMdx8WhYS...|   482|[streetsvilles, a...|[streetsvil, answ...|[streetsvilles, a...|       [3]|\n",
            "|8OjQZD1AktGvHnaaF...|I ordered a very ...|    2|   0|     0|    0| 2017-01-11|sEdAKeMx23AGCbvpl...|xtGB9exG1OarRZDrH...|   368|[ordered, specifi...|[order, specif, c...|[ordered, specifi...|       [2]|\n",
            "|96vpm7fMXnn-J3OTC...|ein angenehmes ei...|    4|   0|     3|    0| 2015-01-23|DVxOGucZ3NpIeTtbk...|KSFxCcsYmSXpQBq3f...|   562|[ein, angenehmes,...|[ein, angenehm, e...|[ein, angenehmes,...|       [4]|\n",
            "|9HWOF_w94JkeunN9l...|Where to begin? I...|    1|   0|     0|    0| 2015-01-21|hYl2qT0fSae2EkLVc...|MsxMTu9URW_RSjYj9...|   771|[begin, hope, cri...|[begin, hope, cri...|[begin, hope, cri...|       [1]|\n",
            "|E7kb6PDF6yL-5x5qw...|Generally the pub...|    3|   1|     2|    2| 2012-01-10|WsdmzI2giWHcRN2pl...|MIyk7EehR0HUumHyJ...|   888|[generally, publi...|[gener, public, p...|[generally, publi...|       [3]|\n",
            "|FDSI1ftNji-qfMuJQ...|This place is one...|    4|   0|     3|    0| 2015-01-09|HWgz2YN0VKQzJ1Mlh...|Ogu0zr1kt6uxd8mEH...|   323|[place, one, favo...|[place, one, favo...|[place, one, favo...|       [4]|\n",
            "|IW3ghV7-y1lZOJTfZ...|This is by far th...|    1|   0|     1|    0| 2016-01-25|SZes7a-4hCkEpZJqJ...|syndqHiaZXD5Jjk4o...|   859|[far, dirtiest, h...|[far, dirtiest, h...|[far, dirtiest, h...|       [1]|\n",
            "|NYORkAfw4lwGIrTKT...|It's a bit out of...|    4|   0|     0|    0| 2013-01-02|EHulq2Qum9mx8AViD...|fbyGwQ0PhImYB5AgN...|   452|[bit, way, famili...|[bit, way, famili...|[bit, way, famili...|       [4]|\n",
            "|P7o_pIxClQfjJ9iVJ...|My friends had pi...|    3|   0|     0|    0| 2015-01-05|igHYkXZMLAc9UdV5V...|HcT3BZLc25R9eekoH...|  1384|[friends, picked,...|[friend, pick, pl...|[friend, picked, ...|       [3]|\n",
            "|QBj-Qjk0s4jseFt8g...|Had burgers and f...|    3|   0|     0|    1| 2016-01-04|GIfZNMP0oIJCje_Xp...|SaNPcBwdImw-634Q3...|   293|[burgers, fries, ...|[burger, fri, goo...|[burger, fry, goo...|       [3]|\n",
            "|Ro_PpjRddiy7b-r9l...|Only had grooming...|    1|   2|     0|    0| 2015-01-30|R9osrGLOriBmKbYwX...|6CaHgJpybsOyjm31f...|   770|[grooming, done, ...|[groom, done, hol...|[grooming, done, ...|       [1]|\n",
            "|WKgWUmvA0G2CmNJ0V...|Taste of the food...|    3|   0|     0|    2| 2016-01-10|_FXa_6j-6UDsxWo-K...|eaVJ0280qBF5WGirt...|    95|[taste, food, bes...|[tast, food, best...|[taste, food, bes...|       [3]|\n",
            "|Y5NzWVeapdU-yQYQq...|Excellent service...|    5|   1|     1|    1| 2015-01-16|w1fJzm0ladnhvT7Jc...|NF0NkrQQpAPIkmnmK...|   109|[excellent, servi...|[excel, servic, m...|[excellent, servi...|       [5]|\n",
            "|ZtSTe9t3NJY94dGZd...|This is a somewha...|    4|   0|     0|    0| 2016-01-24|z-OhppazxWfHnUCzF...|COO0J8CcfhU3SWPxq...|  1013|[somewhat, regula...|[somewhat, regula...|[somewhat, regula...|       [4]|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58Do7Vby4QkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize a CoutVectorizer\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "star_vectorizer = CountVectorizer(inputCol=\"star_array\", outputCol=\"stars_one_hot\", vocabSize=5, minDF=1.0)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WTHAZPK4QrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a vector model\n",
        "star_vector_model = star_vectorizer.fit(spark_df)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWwyaeRU4Q0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "e72db858-0769-4ff1-9f4c-325fb3c87069"
      },
      "source": [
        "# One hot encoded column\n",
        "df_ohe = star_vector_model.transform(spark_df)\n",
        "df_ohe.show(3)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|         business_id|             user_id|length|    body_text_nostop|   body_text_stemmed|body_text_lemmatized|star_array|stars_one_hot|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+\n",
            "|06FL63x1PSHK1IE3i...|An hour and a hal...|    1|   0|     0|    0| 2016-01-24|Z3ZSar8IVAR2qIupq...|1luyQBuF2iH1Tbqs3...|   113|[hour, half, wait...|[hour, half, wait...|[hour, half, wait...|       [1]|(5,[3],[1.0])|\n",
            "|1lGcbt9vMSWY5NLbW...|J'ai été séduite ...|    2|   0|     2|    0| 2015-01-27|frVru1HZYyGZ9sfbO...|AK4k713ocyWht0W47...|   582|[jai, été, séduit...|[jai, été, séduit...|[jai, été, séduit...|       [2]|(5,[4],[1.0])|\n",
            "|1xXPggQNNBjkwxxwH...|I'm always game t...|    1|   0|     2|    0| 2014-01-22|6tY0tn39Mb8FCLYBA...|gaPf1qNX7PAf14wIP...|   858|[im, always, game...|[im, alway, game,...|[im, always, game...|       [1]|(5,[3],[1.0])|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNFHqcTA4Q9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create all the features to the data set\n",
        "star_rating = StringIndexer(inputCol='stars',outputCol='label')\n",
        "hashingTF = HashingTF(inputCol=\"body_text_stemmed\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO9K26k74sf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "# Create feature vector \n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7myETso4sk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[star_rating, hashingTF, idf, clean_up])"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2iX37s_4spP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(df_ohe)\n",
        "cleaned = cleaner.transform(df_ohe)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhsYLkZe4RDV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "ee8feaaf-ac0a-4c9a-c17b-364ecb22a443"
      },
      "source": [
        "cleaned.show(5)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+-----+--------------------+--------------------+--------------------+\n",
            "|           review_id|         review_text|stars|cool|useful|funny|review_date|         business_id|             user_id|length|    body_text_nostop|   body_text_stemmed|body_text_lemmatized|star_array|stars_one_hot|label|          hash_token|           idf_token|            features|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+-----+--------------------+--------------------+--------------------+\n",
            "|06FL63x1PSHK1IE3i...|An hour and a hal...|    1|   0|     0|    0| 2016-01-24|Z3ZSar8IVAR2qIupq...|1luyQBuF2iH1Tbqs3...|   113|[hour, half, wait...|[hour, half, wait...|[hour, half, wait...|       [1]|(5,[3],[1.0])|  3.0|(262144,[17252,27...|(262144,[17252,27...|(262145,[17252,27...|\n",
            "|1lGcbt9vMSWY5NLbW...|J'ai été séduite ...|    2|   0|     2|    0| 2015-01-27|frVru1HZYyGZ9sfbO...|AK4k713ocyWht0W47...|   582|[jai, été, séduit...|[jai, été, séduit...|[jai, été, séduit...|       [2]|(5,[4],[1.0])|  4.0|(262144,[861,8304...|(262144,[861,8304...|(262145,[861,8304...|\n",
            "|1xXPggQNNBjkwxxwH...|I'm always game t...|    1|   0|     2|    0| 2014-01-22|6tY0tn39Mb8FCLYBA...|gaPf1qNX7PAf14wIP...|   858|[im, always, game...|[im, alway, game,...|[im, always, game...|       [1]|(5,[3],[1.0])|  3.0|(262144,[353,1353...|(262144,[353,1353...|(262145,[353,1353...|\n",
            "|37Ci4Q8bRm3PyYHZH...|Hmmm, it was okay...|    3|   1|     1|    0| 2010-01-17|Rj-7ymdw8aNZBRqGR...|uj4iopBWA0RjpqoJ5...|  1453|[hmmm, okay, gues...|[hmmm, okay, gues...|[hmmm, okay, gues...|       [3]|(5,[2],[1.0])|  2.0|(262144,[353,1353...|(262144,[353,1353...|(262145,[353,1353...|\n",
            "|37FEOT7W5jpApoad7...|My wife and I had...|    1|   0|     0|    0| 2017-01-25|TTDMJetAQKfxVzKZy...|x20piGQtvm8hOKe8E...|  2539|[wife, chosen, fl...|[wife, chosen, fl...|[wife, chosen, fl...|       [1]|(5,[3],[1.0])|  3.0|(262144,[1707,232...|(262144,[1707,232...|(262145,[1707,232...|\n",
            "+--------------------+--------------------+-----+----+------+-----+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+----------+-------------+-----+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuHwRtRZKII6",
        "colab_type": "text"
      },
      "source": [
        "# **Machine Learning Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAhQ4n_XJokp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "1bb2142b-7cb7-44fc-b63f-0eb92a1b0d06"
      },
      "source": [
        "#Drop intermediate columns\n",
        "x=cleaned.select('features', 'label')\n",
        "x.show(5)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(262145,[17252,27...|  3.0|\n",
            "|(262145,[861,8304...|  4.0|\n",
            "|(262145,[353,1353...|  3.0|\n",
            "|(262145,[353,1353...|  2.0|\n",
            "|(262145,[1707,232...|  3.0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOw9lb8SL2ck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dc5d78bf-67b0-4fc4-e568-5ef9a38baa3f"
      },
      "source": [
        "# Check dtypes \n",
        "x.dtypes"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('features', 'vector'), ('label', 'double')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpfYVKpKMKwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "793a1e81-408d-400f-f761-122108b41238"
      },
      "source": [
        "# Import col\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Change column DataType for stars\n",
        "x = x.withColumn('label', col('label').cast('int'))\n",
        "\n",
        "x.show(5)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(262145,[17252,27...|    3|\n",
            "|(262145,[861,8304...|    4|\n",
            "|(262145,[353,1353...|    3|\n",
            "|(262145,[353,1353...|    2|\n",
            "|(262145,[1707,232...|    3|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgrfQolZ60kp",
        "colab_type": "text"
      },
      "source": [
        "**Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw4iHzHGJosY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Break data down into a training set and a testing set\n",
        "training, testing = x.randomSplit([0.8, 0.2], 21)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQg1u3srJoyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1sw6FiKJovu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1f807745-a4b5-42cb-f1a3-61bbcb71f60b"
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(predictor.transform(testing))\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.373853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh7jpZOW6vQo",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgWbYha_xWHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Break data down into a training set and a testing set\n",
        "training, testing = x.randomSplit([0.8, 0.2], 21)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ph4zTLsJoqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "# Create a Naive Bayes model and fit training data\n",
        "lg = LogisticRegression()\n",
        "predictor = lg.fit(training)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC6ucu5KJooj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3a48d676-7bcb-42aa-ce64-39d64fd45df0"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(predictor.transform(testing))\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.435023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f33IsJHRH39v",
        "colab_type": "text"
      },
      "source": [
        "**Multilayer Percepron**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXTWK85rH2xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sib4qnGSH8Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into train and test\n",
        "splits = x.randomSplit([0.8, 0.2], 1234)\n",
        "train = splits[0]\n",
        "test = splits[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "495u_f-LIc3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "226fb0bc-99f9-425b-9ff2-ca439074cd93"
      },
      "source": [
        "train.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(262145,[47,1176,...|    0|\n",
            "|(262145,[97,1353,...|    4|\n",
            "|(262145,[97,3831,...|    0|\n",
            "|(262145,[97,4402,...|    3|\n",
            "|(262145,[97,5765,...|    1|\n",
            "|(262145,[97,13957...|    2|\n",
            "|(262145,[98,6646,...|    3|\n",
            "|(262145,[170,427,...|    3|\n",
            "|(262145,[170,976,...|    1|\n",
            "|(262145,[170,1353...|    4|\n",
            "|(262145,[198,427,...|    4|\n",
            "|(262145,[198,991,...|    0|\n",
            "|(262145,[234,1288...|    4|\n",
            "|(262145,[234,1395...|    3|\n",
            "|(262145,[234,1729...|    2|\n",
            "|(262145,[251,976,...|    4|\n",
            "|(262145,[320,1076...|    2|\n",
            "|(262145,[323,2544...|    0|\n",
            "|(262145,[323,2742...|    0|\n",
            "|(262145,[343,991,...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzva90r5INFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify layers for the neural network:\n",
        "# input layer of size 3 (features), two intermediate of size 5 and 4\n",
        "# and output of size 5 (classes)\n",
        "layers = [62000, 256, 5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvuLEMTaINRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the trainer and set its parameters\n",
        "trainer = MultilayerPerceptronClassifier(maxIter=10, layers=layers, blockSize=128, seed=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6qc2Z9iJRUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44ea195a-5894-4c5c-d2c6-527389eaba5c"
      },
      "source": [
        "# train the model\n",
        "model = trainer.fit(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-4f6cd2c6c383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o443.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 68.0 failed 1 times, most recent failure: Lost task 1.0 in stage 68.0 (TID 126, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:3236)\n\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:260)\n\tat org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply$mcV$sp(TaskResult.scala:50)\n\tat org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)\n\tat org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1326)\n\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:48)\n\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:517)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1143)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1137)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1206)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1182)\n\tat org.apache.spark.mllib.optimization.LBFGS$CostFun.calculate(LBFGS.scala:261)\n\tat org.apache.spark.mllib.optimization.LBFGS$CostFun.calculate(LBFGS.scala:230)\n\tat breeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:23)\n\tat breeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:41)\n\tat breeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:30)\n\tat breeze.optimize.StrongWolfeLineSearch.breeze$optimize$StrongWolfeLineSearch$$phi$1(StrongWolfe.scala:76)\n\tat breeze.optimize.StrongWolfeLineSearch$$anonfun$breeze$optimize$StrongWolfeLineSearch$$zoom$1$1.apply$mcVI$sp(StrongWolfe.scala:110)\n\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\tat breeze.optimize.StrongWolfeLineSearch.breeze$optimize$StrongWolfeLineSearch$$zoom$1(StrongWolfe.scala:105)\n\tat breeze.optimize.StrongWolfeLineSearch$$anonfun$minimizeWithBound$1.apply$mcVI$sp(StrongWolfe.scala:162)\n\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\tat breeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:148)\n\tat breeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\n\tat breeze.optimize.LBFGS.determineStepSize(LBFGS.scala:76)\n\tat breeze.optimize.LBFGS.determineStepSize(LBFGS.scala:39)\n\tat breeze.optimize.FirstOrderMinimizer$$anonfun$infiniteIterations$1.apply(FirstOrderMinimizer.scala:64)\n\tat breeze.optimize.FirstOrderMinimizer$$anonfun$infiniteIterations$1.apply(FirstOrderMinimizer.scala:62)\n\tat scala.collection.Iterator$$anon$7.next(Iterator.scala:129)\n\tat breeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:71)\n\tat org.apache.spark.mllib.optimization.LBFGS$.runLBFGS(LBFGS.scala:212)\n\tat org.apache.spark.mllib.optimization.LBFGS.optimize(LBFGS.scala:142)\n\tat org.apache.spark.ml.ann.FeedForwardTrainer.train(Layer.scala:854)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier$$anonfun$train$1.apply(MultilayerPerceptronClassifier.scala:249)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier$$anonfun$train$1.apply(MultilayerPerceptronClassifier.scala:205)\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier.train(MultilayerPerceptronClassifier.scala:205)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier.train(MultilayerPerceptronClassifier.scala:114)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:3236)\n\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:260)\n\tat org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply$mcV$sp(TaskResult.scala:50)\n\tat org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)\n\tat org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1326)\n\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:48)\n\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:517)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
          ]
        }
      ]
    }
  ]
}