{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_model_1-5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karenbennis/Xy/blob/mess_management/ml_model_1_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x2IxWo3wiqn",
        "colab_type": "text"
      },
      "source": [
        "## <br>**Connect to Database**<br><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nCS6homIgnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c715324e-2498-415f-a9f7-99720bad8b91"
      },
      "source": [
        "# Install Java, Spark, and Findspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "#Interact with SQL\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
        "\n",
        "# Start Spark Session(Creating spark application with name defined by appName()) ---IMPORTED WITH EVERY COLAB NOTEBOOK\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"database_transformation\").config(\"spark.driver.memory\",\"5g\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-31 03:03:24--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.9.jar.1’\n",
            "\n",
            "postgresql-42.2.9.j 100%[===================>] 892.61K  4.56MB/s    in 0.2s    \n",
            "\n",
            "2020-07-31 03:03:25 (4.56 MB/s) - ‘postgresql-42.2.9.jar.1’ saved [914037/914037]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVTkr-xleT8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0618f8e-df4d-4dc4-c87b-9051e7244143"
      },
      "source": [
        "# gcloud login and check the DB\n",
        "!gcloud auth login\n",
        "!gcloud config set project 'xy-yelp'\n",
        "!gcloud sql instances describe 'xy-yelp'"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&code_challenge=_KODDG4-sXbhqkRJw9tvJV9Mth4QS5KyGQUYY1RWRpY&code_challenge_method=S256&access_type=offline&response_type=code&prompt=select_account\n",
            "\n",
            "\n",
            "Enter verification code: 4/2gH5aLzW3YHQNfbaZ0UWID-Ajq-lhb9vGOIzudVIV4rEEW3-bLDkikI\n",
            "\n",
            "You are now logged in as [jasmeersangha@gmail.com].\n",
            "Your current project is [xy-yelp].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n",
            "Updated property [core/project].\n",
            "backendType: SECOND_GEN\n",
            "connectionName: xy-yelp:northamerica-northeast1:xy-yelp\n",
            "databaseVersion: POSTGRES_12\n",
            "etag: 72a90c76a0aaca74fa6c470ab4b8fafc8120924c153c7cbc13b30fcf47c78f77\n",
            "gceZone: northamerica-northeast1-a\n",
            "instanceType: CLOUD_SQL_INSTANCE\n",
            "ipAddresses:\n",
            "- ipAddress: 34.95.0.17\n",
            "  type: PRIMARY\n",
            "kind: sql#instance\n",
            "name: xy-yelp\n",
            "project: xy-yelp\n",
            "region: northamerica-northeast1\n",
            "selfLink: https://sqladmin.googleapis.com/sql/v1beta4/projects/xy-yelp/instances/xy-yelp\n",
            "serverCaCert:\n",
            "  cert: |-\n",
            "    -----BEGIN CERTIFICATE-----\n",
            "    MIIDfzCCAmegAwIBAgIBADANBgkqhkiG9w0BAQsFADB3MS0wKwYDVQQuEyQzYTcz\n",
            "    ZmJhNS0xYTNlLTQwNmMtOWZhOC1hZGE1MDI3OGZkY2QxIzAhBgNVBAMTGkdvb2ds\n",
            "    ZSBDbG91ZCBTUUwgU2VydmVyIENBMRQwEgYDVQQKEwtHb29nbGUsIEluYzELMAkG\n",
            "    A1UEBhMCVVMwHhcNMjAwNzExMjAwMDA4WhcNMzAwNzA5MjAwMTA4WjB3MS0wKwYD\n",
            "    VQQuEyQzYTczZmJhNS0xYTNlLTQwNmMtOWZhOC1hZGE1MDI3OGZkY2QxIzAhBgNV\n",
            "    BAMTGkdvb2dsZSBDbG91ZCBTUUwgU2VydmVyIENBMRQwEgYDVQQKEwtHb29nbGUs\n",
            "    IEluYzELMAkGA1UEBhMCVVMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIB\n",
            "    AQDMLAiCVUS0u8JRUQSqXLNcXiDU4euUjKhmvbOnDCr2VNVX+dQoq8P+HmL4ruxr\n",
            "    lmLgtNKuhKjqISSzVKDxEf0mudWfOP+ygsXSP6XxLWplHn/N1A881+u+T33u5N0/\n",
            "    wreqH6suvi7Cu/SSEcmYUCnpIy5pSZzO63ww9M4p2HZnG/g/j7uqGdPUpdG4GbCk\n",
            "    jb8EskJiH0hU08ct+AySyc0mrgvfP9l/S5chz0j69uQX/yvWXWy4SSfJ3+wc45Se\n",
            "    8v7WYo+lcwsOu0lGCz53X9Nej0Av47aKUzXD4HlleeMTbkjgYEv2hRWKVoUhzugT\n",
            "    dJTsminBKtnYK1n2witgxNqVAgMBAAGjFjAUMBIGA1UdEwEB/wQIMAYBAf8CAQAw\n",
            "    DQYJKoZIhvcNAQELBQADggEBAB45K3XfFNL/Vkbj0f9daDji+cJHeUS3Y8Uxehog\n",
            "    2rf+rbmwfeH757NZT29o8rSMMfV05z3fuYvS67JvSIDx/I3UsxRGzRZY4EfXXhC9\n",
            "    Vke7AVtfxNgKk86V+JPEGQp52L+PFYdh33DigL8XrWpektxIxf7RAqFIvV0F+0FS\n",
            "    DhXWXkZ8ONFpMK6BCd4aZcKgD0LHafoAKv67+A8IE6b1fFJLh1nkuqZyv1kwLwTM\n",
            "    bLzSMmkgvxuv8d0dmVxWWr/V1kjc2U7oMqF+tgOE+hcF7fWRyRRZko1RtPwjUHlT\n",
            "    qzw5uqZUsxR8S4yyiaeePiF8YnDI72ypyY6FiRMlteAydJs=\n",
            "    -----END CERTIFICATE-----\n",
            "  certSerialNumber: '0'\n",
            "  commonName: C=US,O=Google\\, Inc,CN=Google Cloud SQL Server CA,dnQualifier=3a73fba5-1a3e-406c-9fa8-ada50278fdcd\n",
            "  createTime: '2020-07-11T20:00:08.018Z'\n",
            "  expirationTime: '2030-07-09T20:01:08.018Z'\n",
            "  instance: xy-yelp\n",
            "  kind: sql#sslCert\n",
            "  sha1Fingerprint: 2e2ffdd64d766e372537c174a3d4b91f59ee3e63\n",
            "serviceAccountEmailAddress: p8056368877-0mi1n8@gcp-sa-cloud-sql.iam.gserviceaccount.com\n",
            "settings:\n",
            "  activationPolicy: ALWAYS\n",
            "  availabilityType: ZONAL\n",
            "  backupConfiguration:\n",
            "    enabled: true\n",
            "    kind: sql#backupConfiguration\n",
            "    location: us\n",
            "    pointInTimeRecoveryEnabled: false\n",
            "    replicationLogArchivingEnabled: false\n",
            "    startTime: 13:00\n",
            "  dataDiskSizeGb: '43'\n",
            "  dataDiskType: PD_SSD\n",
            "  ipConfiguration:\n",
            "    authorizedNetworks:\n",
            "    - kind: sql#aclEntry\n",
            "      name: Blake Residence\n",
            "      value: 24.114.84.61\n",
            "    - kind: sql#aclEntry\n",
            "      name: Karen's Residence\n",
            "      value: 173.32.183.48\n",
            "    - kind: sql#aclEntry\n",
            "      name: Helen's Residence\n",
            "      value: 72.142.66.43\n",
            "    ipv4Enabled: true\n",
            "  kind: sql#settings\n",
            "  locationPreference:\n",
            "    kind: sql#locationPreference\n",
            "    zone: northamerica-northeast1-a\n",
            "  maintenanceWindow:\n",
            "    day: 0\n",
            "    hour: 0\n",
            "    kind: sql#maintenanceWindow\n",
            "  pricingPlan: PER_USE\n",
            "  replicationType: SYNCHRONOUS\n",
            "  settingsVersion: '43'\n",
            "  storageAutoResize: true\n",
            "  storageAutoResizeLimit: '0'\n",
            "  tier: db-f1-micro\n",
            "state: RUNNABLE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn_F729PexE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "91565701-3aa9-44bf-dedb-e73574d93eb5"
      },
      "source": [
        "# download and initialize the psql proxy\n",
        "!wget https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64 -O cloud_sql_proxy\n",
        "!chmod +x cloud_sql_proxy\n",
        "# \"connectionName\" is from the previous block\n",
        "!nohup ./cloud_sql_proxy -instances=\"xy-yelp:northamerica-northeast1:xy-yelp\"=tcp:5432 &\n",
        "!sleep 30s"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-31 03:03:46--  https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64\n",
            "Resolving dl.google.com (dl.google.com)... 173.194.216.93, 173.194.216.136, 173.194.216.190, ...\n",
            "Connecting to dl.google.com (dl.google.com)|173.194.216.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14492253 (14M) [application/octet-stream]\n",
            "Saving to: ‘cloud_sql_proxy’\n",
            "\n",
            "\rcloud_sql_proxy       0%[                    ]       0  --.-KB/s               \rcloud_sql_proxy     100%[===================>]  13.82M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-07-31 03:03:46 (250 MB/s) - ‘cloud_sql_proxy’ saved [14492253/14492253]\n",
            "\n",
            "nohup: appending output to 'nohup.out'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Ko5J-Ee7Ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db_password = 'kjhbyelpdb'"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs2eCTjpfEd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://127.0.0.1:5432/xy_yelp_db\"\n",
        "config = {\"user\":\"postgres\", \n",
        "          \"password\": db_password, \n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQez-IxYJC_V",
        "colab_type": "text"
      },
      "source": [
        "## **Extract tables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsuqOjKQRNYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read data from database\n",
        "review_df2 = spark.read.jdbc(url=jdbc_url, table='review_two',properties=config)\n",
        "# review_df2.show(5)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ5Sj70ckAh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "import re\n",
        "\n",
        "#PySpark ml imports\n",
        "from pyspark.ml.feature import HashingTF, IDF, StringIndexer\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxBkpnfURN6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to a pandas df\n",
        "pandas_df = review_df2.toPandas()\n",
        "# pandas_df.head()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6k3WVfJM6cE",
        "colab_type": "text"
      },
      "source": [
        "## **Transformation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUy5O7uUsx3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "50589019-12ab-440a-e0d0-ba72816bc96d"
      },
      "source": [
        "# Function to remove Punctuation\n",
        "def remove_punct(text):\n",
        "  text_nopunct = ''.join([char for char in text if char not in string.punctuation])\n",
        "  return text_nopunct\n",
        "\n",
        "# Function to Tokenize words\n",
        "def tokenize(text):\n",
        "  tokens = re.split('\\W+', text)\n",
        "  return tokens\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopword = nltk.corpus.stopwords.words('english') \n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(tokenized_list):\n",
        "  text = [word for word in tokenized_list if word not in stopword]\n",
        "  return text\n",
        "\n",
        "# Create an instance for stemmer\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "# Function for stemming\n",
        "def stemming(tokenized_text):\n",
        "  text = [ps.stem(word) for word in tokenized_text]\n",
        "  return text"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x1pQ29xsx-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run NLP functions\n",
        "pandas_df['body_text_clean'] = pandas_df['review_text'].apply(lambda x: remove_punct(x))\n",
        "pandas_df['body_text_tokenized'] = pandas_df['body_text_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "pandas_df['body_text_nostop'] = pandas_df['body_text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "pandas_df['body_text_stemmed'] = pandas_df['body_text_nostop'].apply(lambda x: stemming(x))\n",
        "\n",
        "# Add a length column to DataFrame\n",
        "pandas_df['length'] = pandas_df['review_text'].apply(len)\n",
        "\n",
        "# pandas_df.head()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edBuycdkn10s",
        "colab_type": "text"
      },
      "source": [
        "## **Pipeline**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vbt3mBbxzMW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8ee6d0dd-65f6-4d1a-a1d7-46409aaa6130"
      },
      "source": [
        "# Select columns for new DataFrame\n",
        "pandas_df_useful = pandas_df[['review_id', 'review_text', 'stars',  'length', 'body_text_stemmed']]\n",
        "\n",
        "# Convert pandas_df to sparks df\n",
        "spark_df = spark.createDataFrame(pandas_df_useful)\n",
        "spark_df.show(5)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+------+--------------------+\n",
            "|           review_id|         review_text|stars|length|   body_text_stemmed|\n",
            "+--------------------+--------------------+-----+------+--------------------+\n",
            "|K8avYPWsh45v7VoZg...|another pie place...|    3|   256|[anoth, pie, plac...|\n",
            "|BkiZn5XSzAv9q7J7_...|I came with my si...|    4|   480|[came, sister, ex...|\n",
            "|L6kc7Nr7hWiqo7ZvW...|I am very disappo...|    1|   236|[disappoint, braz...|\n",
            "|y35xKzutHXT985mUp...|Stopped for lunch...|    4|   265|[stop, lunch, wif...|\n",
            "|UqQGtBDEfkYMLV-Fy...|DON'T DO IT!  You...|    1|  3123|[dont, your, vega...|\n",
            "+--------------------+--------------------+-----+------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNFHqcTA4Q9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create all the features to the data set\n",
        "star_rating = StringIndexer(inputCol='stars',outputCol='label')\n",
        "hashingTF = HashingTF(inputCol=\"body_text_stemmed\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7myETso4sk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create and run a data processing Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[star_rating, hashingTF, idf, clean_up])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2iX37s_4spP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(spark_df)\n",
        "cleaned = cleaner.transform(spark_df)\n",
        "\n",
        "# cleaned.show(5)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuHwRtRZKII6",
        "colab_type": "text"
      },
      "source": [
        "# **Machine Learning Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAhQ4n_XJokp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0c9fe817-ce19-454e-ac6e-223383a1477b"
      },
      "source": [
        "#Drop intermediate columns\n",
        "x=cleaned.select('features', 'label')\n",
        "x.show(5)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(262145,[22567,27...|  2.0|\n",
            "|(262145,[427,1253...|  0.0|\n",
            "|(262145,[17893,28...|  3.0|\n",
            "|(262145,[31463,65...|  0.0|\n",
            "|(262145,[2396,392...|  3.0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgrfQolZ60kp",
        "colab_type": "text"
      },
      "source": [
        "**Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw4iHzHGJosY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Break data down into a training set and a testing set\n",
        "training, testing = x.randomSplit([0.8, 0.2], 21)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQg1u3srJoyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1sw6FiKJovu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4995ff68-dff5-4b60-b6d7-c39920d052fc"
      },
      "source": [
        "# Use the Class Evaluator for a cleaned description\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(predictor.transform(testing))\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.391433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh7jpZOW6vQo",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ph4zTLsJoqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Logistic Regression model and fit training data\n",
        "lg = LogisticRegression()\n",
        "predictor = lg.fit(training)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC6ucu5KJooj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7770aec2-2e05-4a2c-f9a2-b4266449cd4f"
      },
      "source": [
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(predictor.transform(testing))\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.453939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f33IsJHRH39v",
        "colab_type": "text"
      },
      "source": [
        "**Multilayer Perceptron**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzva90r5INFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify layers for the neural network:\n",
        "layers = [62000, 256, 3]\n",
        "\n",
        "# create the trainer and set its parameters\n",
        "trainer = MultilayerPerceptronClassifier(maxIter=10, layers=layers, blockSize=128, seed=1234)\n",
        "\n",
        "# train the model\n",
        "# model = trainer.fit(training)\n",
        "\n",
        "# Proved to be too large of an input layer for our machines to handle "
      ],
      "execution_count": 37,
      "outputs": []
    }
  ]
}